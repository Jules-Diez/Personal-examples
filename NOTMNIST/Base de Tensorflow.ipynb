{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Base du fonctionnement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Le debut de ce notebook provient majoritairement de :\n",
    " - [La documentation officielle](https://www.tensorflow.org/) \n",
    " - [Xebia ep1](http://blog.xebia.fr/2017/03/01/tensorflow-deep-learning-episode-1-introduction/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Notebook créer à des fins d'utilisation personnelle "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## TensorFlow, mais qu’est-ce donc ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "TensorFlow est un framework de programmation pour le calcul numérique qui a été rendu Open Source par Google en Novembre 2015. Depuis sa release, TensorFlow n’a cessé de gagner en popularité, pour devenir très rapidement l’un des frameworks les plus utilisés pour le Deep Learning, comme le montrent les dernières comparaisons suivantes, faites par François Chollet (auteur de la librairie Keras)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://blog.xebia.fr/wp-content/uploads/2017/03/deeplearning-1-768x413.jpg\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"http://blog.xebia.fr/wp-content/uploads/2017/03/deeplearning-1-768x413.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Les raisons de cette popularité fracassante ?\n",
    "- Multi-plateformes (Linux, Mac OS, et même Android et iOS !)\n",
    "- APIs en Python, C++, Java et Go (l’API Python est plus complète cependant, c’est sur celle-ci que nous allons travailler)\n",
    "- Temps de compilation très courts dû au backend en C/C++\n",
    "- Supporte les calculs sur CPU, GPU et même le calcul distribué sur cluster\n",
    "- Une documentation extrêmement bien fournie avec de nombreux exemples et tutoriels\n",
    "- Last but not least: Le fait que le framework vienne de Google et que ce dernier ait annoncé avoir migré la quasi totalité de ses projets liés au Deep Learning en TensorFlow est quelque peu rassurant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Comment ça marche ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "La particularité de TensorFlow est qu’il représente les calculs sous la forme d’un graphe d’exécution: chaque noeud représente une Operation à réaliser, et chaque lien représente un Tensor. Une Operation peut aller d’une simple addition à une fonction complexe de différenciation matricielle.\n",
    "\n",
    "Chaque Operation prend en entrée zéro, un ou plusieurs Tensor, effectue un calcul, et retourne zéro, un ou plusieurs Tensor. Un exemple typique de Tensor est un batch d’images. Un batch d’images est représenté par un Tensor à 4 dimensions: taille du batch (nombre d’images dans le batch), hauteur, largeur et nombre de canaux de représentation (3 pour une image en couleurs représentée en RGB).\n",
    "\n",
    "La création du graphe est automatiquement gérée par TensorFlow une fois les Tensor et Operation implémentés et instanciés. Cela permet une optimisation et parallélisation du code et de l’exécution lors du lancement.\n",
    "\n",
    "TensorFlow possède de plus un support très vaste pour la création d’opérations spécifiques au Deep Learning, et il devient donc facile de construire un réseau de neurones et d’utiliser les opérations mathématiques couramment associées pour l’entraîner avec les bons optimiseurs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Comment les calculs sont-ils effectués ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### La Session\n",
    "\n",
    "Pour pouvoir exécuter quoi que ce soit, un graphe doit être lancé dans une Session. Une Session place les Operation du graphe dans des devices (CPU ou GPU) et met à disposition des méthodes pour les exécuter. Chaque Session peut avoir ses propres variables et readers, et il est possible d’instancier plusieurs Session afin d’entraîner plusieurs réseaux différents. Le lancement des opérations du graphe se fait via la méthode run() de la Session. Un graphe ne va exécuter les Operation qu’après la création d’une Session.\n",
    "\n",
    "Ce système d’exécution de graphe est une des propriétés fondamentales de TensorFlow. Cela permet d’éviter de retourner dans le monde Python à chaque étape (contrairement à ce qui est fait dans NumPy) et d’éxécuter toutes les opérations du graphe en une seule fois dans un même backend optimisé.\n",
    "\n",
    "L’utilisation d’une Session n’est pas ce qu’il y a de plus intuitif et simple, en particulier lorsque l’on utilise des notebooks et que l’on ne souhaite pas lancer le run de la Session à chaque fois que l’on veut tester une étape. Pour s’affranchir de ces contraintes lors d’une utilisation via des notebooks, on peut utiliser à la place une InteractiveSession, qui remplit les mêmes fonctions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Structure du code\n",
    "\n",
    "Généralement, le code associé à TensorFlow se divise donc en deux étapes principales:\n",
    " - Une phase de construction durant laquelle on décrit et assemble toutes les variables et opérations du graphe\n",
    " - Une phase d’exécution qui utilise une Session afin d’exécuter les opérations du graphe\n",
    " \n",
    "C’est cette séparation qui permet à TensorFlow d’optimiser l’enchaînement des étapes du graphe avant de les exécuter.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Les opérations courantes pour gérer les inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Constant\n",
    "**tf.constant()** pour créer un Tensor à partir d’une valeur que l’on souhaite garder fixe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Instanciation of a Constant\n",
    "const = tf.constant([2., 1.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 12.]]\n",
      "[[ 3.  3.]]\n"
     ]
    }
   ],
   "source": [
    "# Create a Constant op that produces a 1x2 matrix.\n",
    "matrix1 = tf.constant([[3., 3.]])\n",
    "\n",
    "# Create another Constant that produces a 2x1 matrix.\n",
    "matrix2 = tf.constant([[2.], [2.]])\n",
    "\n",
    "# Create a matmul op that performs the matrix multiplication of matrix1 by matrix2.\n",
    "product = tf.matmul(matrix1, matrix2)\n",
    "\n",
    "# Launch the default graph.\n",
    "sess = tf.Session()\n",
    "\n",
    "# Call the session run() method to run the matmul op.\n",
    "result = sess.run(product)\n",
    "print(result)\n",
    "\n",
    "# You can call multiple operations at the same time\n",
    "res_product, res_matrix1 = sess.run([product, matrix1])\n",
    "print(res_matrix1)\n",
    "\n",
    "# Close the session\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Variable\n",
    "**tf.Variable()** pour créer un Tensor que l'on souhaite modifier au cours de l'éxécution d'un graphe\n",
    "\n",
    "**tf.global_variables_initializer()** pour initializer les variables avant de les utiliser dans un graphe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Instanciation of a Variable\n",
    "counter = tf.Variable(0, name=\"counter\")  # Count the number of iterations\n",
    "\n",
    "# Initialization of a Variable as a Tensor full of zeros\n",
    "weights = tf.Variable(tf.zeros([image_pixels, num_classes]))\n",
    "\n",
    "# Initialization of a Variable as a Tensor with small random values\n",
    "weights = tf.Variable(tf.truncated_normal(shape=[num_pixels, num_classes], stddev=0.1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "# Counter Variable definition\n",
    "counter = tf.Variable(0, name=\"counter\")\n",
    "\n",
    "# Creation of a constant\n",
    "one = tf.constant(1)\n",
    "\n",
    "# Operations to perform in order to increment the variable value\n",
    "new_value = tf.add(counter, one)\n",
    "update = tf.assign(counter, new_value)\n",
    "\n",
    "# Initialize all variables\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "# Increment the value of the variable in a session\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init_op)\n",
    "    for _ in range(5):\n",
    "        sess.run(update)\n",
    "        print(sess.run(counter))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Placeholder\n",
    "**tf.placeholder()** pour créer un tensor sans valeur spécifique, sa valeur sera fixé lors d'un run grâce à l'argument **feed_dict**. Sert principalement pour les batchs de données successives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Instanciation of a Placeholder\n",
    "simple_placeholder = tf.placeholder(tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 14.]\n"
     ]
    }
   ],
   "source": [
    "# Instanciation of two Placeholders\n",
    "input1 = tf.placeholder(tf.float32)\n",
    "input2 = tf.placeholder(tf.float32)\n",
    "\n",
    "# Multiplication operation\n",
    "output = tf.multiply(input1, input2)\n",
    "\n",
    "# Graph execution, we need to feed the placeholders\n",
    "with tf.Session() as sess:\n",
    " result = sess.run(output, feed_dict={input1: [7.], input2: [2.]})\n",
    " print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Basics operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Const:0\", shape=(), dtype=float32) Tensor(\"Const_1:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "node1 = tf.constant(3.0, tf.float32)\n",
    "node2 = tf.constant(4.0) # also tf.float32 implicitly\n",
    "print(node1, node2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.0, 4.0]\n"
     ]
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "print(sess.run([node1, node2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "a = tf.placeholder(tf.float32)\n",
    "b = tf.placeholder(tf.float32)\n",
    "adder_node = a + b  # + provides a shortcut for tf.add(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.5\n",
      "[ 3.  7.]\n",
      "[ 3.  7.]\n"
     ]
    }
   ],
   "source": [
    "print(sess.run(adder_node, {a: 3, b:4.5}))\n",
    "print(sess.run(adder_node, {a: [1,3], b: [2, 4]}))\n",
    "print(adder_node.eval({a: [1,3], b: [2, 4]},sess))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "source": [
    "Showing somes basics operation and performing a simple regression with standard operations with TensorFlow Core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear_model: [ 0.          0.60000002  1.20000005  1.80000019]\n",
      "squared_deltas: [   1.            1.95999992    3.23999977  104.03999329]\n",
      "sum_loss: 110.24\n",
      "mean_loss: 27.56\n",
      "\n",
      "linear_model: [ 0. -2. -4. -6.]\n",
      "squared_deltas: [   1.   16.   49.  324.]\n",
      "sum_loss: 390.0\n",
      "mean_loss: 97.5\n",
      "\n",
      "linear_model: [-0.57022488  2.81557131  6.20136786  9.58716393]\n",
      "squared_deltas: [  2.46560621   0.66515654  10.24875641   5.82177782]\n",
      "sum_loss: 19.2013\n",
      "mean_loss: 4.80032\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classic way of seperation of the code into graph declaration and session\n",
    "\n",
    "# Input data\n",
    "x_train = [1,3,5,7]\n",
    "y_train = [1,2,3,12]\n",
    "\n",
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    \n",
    "    # Model parameters\n",
    "    W = tf.Variable([.3], tf.float32)\n",
    "    b = tf.Variable([-.3], tf.float32)\n",
    "    \n",
    "    # Model input and output\n",
    "    x = tf.placeholder(tf.float32)\n",
    "    y = tf.placeholder(tf.float32)\n",
    "    \n",
    "    # Operation\n",
    "    linear_model = W * x + b\n",
    "    squared_deltas = tf.square(linear_model - y)\n",
    "    \n",
    "    # Loss\n",
    "    sum_loss = tf.reduce_sum(squared_deltas) # Take the sum\n",
    "    mean_loss = tf.reduce_mean(squared_deltas) # Take the mean\n",
    "    \n",
    "    # Optimizer\n",
    "    optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
    "    train = optimizer.minimize(mean_loss)\n",
    "    \n",
    "with tf.Session(graph=graph) as session:\n",
    "    \n",
    "    # Initialized variables\n",
    "    init = tf.global_variables_initializer() # before no values is assign to them\n",
    "    session.run(init)\n",
    "    #tf.global_variables_initializer().run()\n",
    "    \n",
    "    # Using eval\n",
    "    print('linear_model:',linear_model.eval({x: x_train}))\n",
    "    print('squared_deltas:',squared_deltas.eval({x: x_train, y: y_train}))\n",
    "    print('sum_loss:',sum_loss.eval({x: x_train, y:y_train}))\n",
    "    print('mean_loss:',mean_loss.eval({x: x_train, y:y_train}))\n",
    "    print()\n",
    "    \n",
    "    # Re-assign value to W and b\n",
    "    fixW = tf.assign(W, [-1.]) \n",
    "    fixb = tf.assign(b, [1.])\n",
    "    session.run([fixW,fixb]) # Even if we give an another name the value will be assign to the ref variable after the run\n",
    "    \n",
    "    # Can do the same thing with one call of session.run()\n",
    "    linear_mod, squared_del, sum_los, mean_los = session.run([linear_model, squared_deltas, sum_loss, mean_loss], \n",
    "                                               feed_dict={x: x_train, y:y_train})\n",
    "    print('linear_model:', linear_mod)\n",
    "    print('squared_deltas:', squared_del)\n",
    "    print('sum_loss:', sum_los)\n",
    "    print('mean_loss:', mean_los)\n",
    "    print()\n",
    "    \n",
    "    # Training loop\n",
    "    for i in range(1000):\n",
    "        session.run(train, {x:x_train, y:y_train})\n",
    "    \n",
    "    # Evaluation of the results\n",
    "    linear_mod, squared_del, sum_los, mean_los = session.run([linear_model, squared_deltas, sum_loss, mean_loss], \n",
    "                                               feed_dict={x: x_train, y:y_train})\n",
    "    print('linear_model:', linear_mod)\n",
    "    print('squared_deltas:', squared_del)\n",
    "    print('sum_loss:', sum_los)\n",
    "    print('mean_loss:', mean_los)\n",
    "    print()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Simple regression with standard operations with the high-level TensorFlow library tf.contrib.learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\MASTER~1\\AppData\\Local\\Temp\\tmp5wlwctzo\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_num_ps_replicas': 0, '_tf_random_seed': None, '_evaluation_master': '', '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_save_checkpoints_steps': None, '_task_type': None, '_environment': 'local', '_is_chief': True, '_save_checkpoints_secs': 600, '_keep_checkpoint_every_n_hours': 10000, '_task_id': 0, '_save_summary_steps': 100, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x000000001D9A3F60>, '_master': ''}\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\MASTER~1\\AppData\\Local\\Temp\\tmp5wlwctzo\\model.ckpt.\n",
      "INFO:tensorflow:loss = 2.5, step = 1\n",
      "INFO:tensorflow:global_step/sec: 595.226\n",
      "INFO:tensorflow:loss = 0.0250372, step = 101\n",
      "INFO:tensorflow:global_step/sec: 617.271\n",
      "INFO:tensorflow:loss = 0.00291649, step = 201\n",
      "INFO:tensorflow:global_step/sec: 564.959\n",
      "INFO:tensorflow:loss = 0.000463935, step = 301\n",
      "INFO:tensorflow:global_step/sec: 584.785\n",
      "INFO:tensorflow:loss = 7.71555e-05, step = 401\n",
      "INFO:tensorflow:global_step/sec: 564.962\n",
      "INFO:tensorflow:loss = 2.59372e-05, step = 501\n",
      "INFO:tensorflow:global_step/sec: 632.899\n",
      "INFO:tensorflow:loss = 1.95246e-06, step = 601\n",
      "INFO:tensorflow:global_step/sec: 617.27\n",
      "INFO:tensorflow:loss = 2.81454e-07, step = 701\n",
      "INFO:tensorflow:global_step/sec: 555.547\n",
      "INFO:tensorflow:loss = 9.54046e-08, step = 801\n",
      "INFO:tensorflow:global_step/sec: 546.439\n",
      "INFO:tensorflow:loss = 1.23331e-08, step = 901\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into C:\\Users\\MASTER~1\\AppData\\Local\\Temp\\tmp5wlwctzo\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.63438e-09.\n",
      "WARNING:tensorflow:Rank of input Tensor (1) should be the same as output_rank (2) for column. Will attempt to expand dims. It is highly recommended that you resize your input, as this behavior may change.\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\estimators\\head.py:1362: scalar_summary (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2016-11-30.\n",
      "Instructions for updating:\n",
      "Please switch to tf.summary.scalar. Note that tf.summary.scalar uses the node name instead of the tag. This means that TensorFlow will automatically de-duplicate summary names based on the scope they are created in. Also, passing a tensor or list of tags to a scalar summary op is no longer supported.\n",
      "INFO:tensorflow:Starting evaluation at 2017-04-16-12:52:27\n",
      "INFO:tensorflow:Finished evaluation at 2017-04-16-12:52:28\n",
      "INFO:tensorflow:Saving dict for global step 1000: global_step = 1000, loss = 1.83838e-09\n",
      "WARNING:tensorflow:Skipping summary for global_step, must be a float or np.float32.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'global_step': 1000, 'loss': 1.838383e-09}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data input and output\n",
    "x = np.array([1., 2., 3., 4.])\n",
    "y = np.array([0., -1., -2., -3.])\n",
    "\n",
    "# Declare list of features.\n",
    "features = [tf.contrib.layers.real_valued_column(\"x\", dimension=1)]\n",
    "\n",
    "# Declare the estimator\n",
    "estimator = tf.contrib.learn.LinearRegressor(feature_columns=features)\n",
    "\n",
    "# Helper method to read and set up data sets, and tell the function how many batches\n",
    "# of data (num_epochs) we want and how big each batch should be\n",
    "input_fn = tf.contrib.learn.io.numpy_input_fn({\"x\":x}, y, batch_size=4,\n",
    "                                              num_epochs=1000)\n",
    "\n",
    "estimator.fit(input_fn=input_fn, steps=1000)\n",
    "\n",
    "estimator.evaluate(input_fn=input_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## TensorBoard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Nous allons très vite ressentir le besoin de visualiser le graphe créé, ainsi que de contrôler l’évolution de nos phases d’apprentissage (évolution du taux de prédiction, activités des neurones, etc.). Heureusement pour nous, TensorFlow met à disposition un outil, TensorBoard, qui répond à ces besoins. TensorBoard est une réelle force et constitue un vrai élément différenciant de TensorFlow par rapport aux autres frameworks de Deep Learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Lien: \n",
    "- https://github.com/tensorflow/tensorflow/blob/master/tensorflow/tensorboard/README.md\n",
    "- https://www.tensorflow.org/get_started/summaries_and_tensorboard\n",
    "- https://www.tensorflow.org/get_started/graph_viz\n",
    "- https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/tutorials/deepdream\n",
    "- https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb\n",
    "- https://medium.com/intuitionmachine/teasing-out-tensorflow-graph-mess-64cf5ece4b00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Comment utiliser TensorBoard ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Pour utiliser TensorBoard, il faut spécifier dans le code quelles sont les opérations dont on souhaite résumer l’activité. Une fois que c’est fait, il reste alors à créer un Summarizer qui va merger toutes les informations calculées. Une fois que le programme est lancé, il suffit de lancer la commande adéquate avec le chemin d’accès vers les logs pour que l’interface graphique associée se lance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# During the session part\n",
    "file_writer = tf.summary.FileWriter('path/to/logs', sess.graph)\n",
    "\n",
    "# In a terminal\n",
    "tensorboard --logdir='path/to/logs'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### From deep dream notebook, using Tensorboard insisde Ipython Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "# Helper function from Alex Mordvintsev deep dream notebook\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = \"<stripped %d bytes>\"%size\n",
    "    return strip_def\n",
    "\n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "\n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#Then to visualize current graph\n",
    "show_graph(tf.get_default_graph().as_graph_def())\n",
    "\n",
    "# If your graph is saved as pbtxt, you could do\n",
    "gdef = tf.GraphDef()\n",
    "from google.protobuf import text_format\n",
    "text_format.Merge(open(\"tf_persistent.pbtxt\").read(), gdef)\n",
    "show_graph(gdef)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "### Les modifications à apporter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Afin de pouvoir visualiser l’évolution de certains nœuds du graphe, il faut annoter l’opération correspondante via des Summary Operations. On trouve par exemple **tf.summary.scalar** (ex: visualisation d’un fonction de coût) ou des **tf.summary.histogram** (ex: visualisation de la distribution de l’activation des neurones d’une couche)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Comme on peut le voir dans l’exemple, le résumé des valeurs prises par la variable counter est géré par l’opération **tf.summary.scalar(‘counter’, counter)**. La création de la Variable ainsi que le résumé associé sont encapsulés dans un bloc with **tf.name_scope**. Cela permet de générer des grandes zones dans TensorBoard, ce qui nous sera très utile lorsque nous aurons beaucoup d’opérations enchainées.\n",
    "\n",
    "Une fois les summarizers créés, on ajoute une dernière opération chargée de tous les merger: **tf.summary.merge_all()**. \n",
    "\n",
    "L’étape suivante consiste à créer un summary_writer spécifiant où seront écrits les logs qui seront lus par TensorBoard: **tf.summary.FileWriter()**. Lors de l’éxécution du graphe, il suffit alors de rajouter à l’étape de run l’opération de merge, puis d’ajouter le summary au writer créé: **summary_writer.add_summary(summary, i)**.\n",
    "\n",
    "Ces quelques lignes de code supplémentaires nous permettent de faire appel à TensorBoard en ligne de commande pour lancer l’interface graphique associée. On observe alors plusieurs onglets, notamment « Scalars » et « Graph »."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "4\n",
      "8\n",
      "16\n",
      "32\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:1200px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.5369953665770125&quot;).pbtxt = 'node {\\n  name: &quot;counter/counter/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;counter/counter&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;counter/counter/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;counter/counter&quot;\\n  input: &quot;counter/counter/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@counter/counter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;counter/counter/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;counter/counter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@counter/counter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;counter/counter_1/tags&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;counter/counter_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;counter/counter_1&quot;\\n  op: &quot;ScalarSummary&quot;\\n  input: &quot;counter/counter_1/tags&quot;\\n  input: &quot;counter/counter/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;const&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mul&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;counter/counter/read&quot;\\n  input: &quot;const&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;counter/counter&quot;\\n  input: &quot;Mul&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@counter/counter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Merge/MergeSummary&quot;\\n  op: &quot;MergeSummary&quot;\\n  input: &quot;counter/counter_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 1\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^counter/counter/Assign&quot;\\n}\\nnode {\\n  name: &quot;counter_1/counter/initial_value&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 1\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;counter_1/counter&quot;\\n  op: &quot;VariableV2&quot;\\n  attr {\\n    key: &quot;container&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;shape&quot;\\n    value {\\n      shape {\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;shared_name&quot;\\n    value {\\n      s: &quot;&quot;\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;counter_1/counter/Assign&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;counter_1/counter&quot;\\n  input: &quot;counter_1/counter/initial_value&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@counter_1/counter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;counter_1/counter/read&quot;\\n  op: &quot;Identity&quot;\\n  input: &quot;counter_1/counter&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@counter_1/counter&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;counter_1/counter_1/tags&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_STRING\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_STRING\\n        tensor_shape {\\n        }\\n        string_val: &quot;counter_1/counter_1&quot;\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;counter_1/counter_1&quot;\\n  op: &quot;ScalarSummary&quot;\\n  input: &quot;counter_1/counter_1/tags&quot;\\n  input: &quot;counter_1/counter/read&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;const_1&quot;\\n  op: &quot;Const&quot;\\n  attr {\\n    key: &quot;dtype&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;value&quot;\\n    value {\\n      tensor {\\n        dtype: DT_INT32\\n        tensor_shape {\\n        }\\n        int_val: 2\\n      }\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Mul_1&quot;\\n  op: &quot;Mul&quot;\\n  input: &quot;counter_1/counter/read&quot;\\n  input: &quot;const_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Assign_1&quot;\\n  op: &quot;Assign&quot;\\n  input: &quot;counter_1/counter&quot;\\n  input: &quot;Mul_1&quot;\\n  attr {\\n    key: &quot;T&quot;\\n    value {\\n      type: DT_INT32\\n    }\\n  }\\n  attr {\\n    key: &quot;_class&quot;\\n    value {\\n      list {\\n        s: &quot;loc:@counter_1/counter&quot;\\n      }\\n    }\\n  }\\n  attr {\\n    key: &quot;use_locking&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n  attr {\\n    key: &quot;validate_shape&quot;\\n    value {\\n      b: true\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;Merge_1/MergeSummary&quot;\\n  op: &quot;MergeSummary&quot;\\n  input: &quot;counter/counter_1&quot;\\n  input: &quot;counter_1/counter_1&quot;\\n  attr {\\n    key: &quot;N&quot;\\n    value {\\n      i: 2\\n    }\\n  }\\n}\\nnode {\\n  name: &quot;init_1&quot;\\n  op: &quot;NoOp&quot;\\n  input: &quot;^counter/counter/Assign&quot;\\n  input: &quot;^counter_1/counter/Assign&quot;\\n}\\n';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.5369953665770125&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# creating TensorFlow session and loading the model\n",
    "graph = tf.Graph()\n",
    "#sess = tf.InteractiveSession(graph=graph)\n",
    "\n",
    "# Counter Variable definition\n",
    "with tf.name_scope('counter'):\n",
    "    counter = tf.Variable(1, name=\"counter\")\n",
    "    tf.summary.scalar('counter', counter)\n",
    "\n",
    "# Creation of a constant\n",
    "two_op = tf.constant(2, name=\"const\")\n",
    "\n",
    "# Operations to perform in order to increment the variable value\n",
    "new_value = tf.multiply(counter, two_op)\n",
    "update = tf.assign(counter, new_value)\n",
    "\n",
    "merged = tf.summary.merge_all()\n",
    "\n",
    "# Initialize all variables\n",
    "init_op = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Increment the value of the variable in a session\n",
    "    sess.run(init_op)\n",
    "\n",
    "    summary_writer = tf.summary.FileWriter(\"log\", sess.graph)\n",
    "\n",
    "    for i in range(5):\n",
    "        summary, _ = sess.run([merged, update])\n",
    "        summary_writer.add_summary(summary, i)\n",
    "        print(sess.run(counter))\n",
    "\n",
    "#Then to visualize current graph\n",
    "show_graph(tf.get_default_graph().as_graph_def())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n",
      "10\n",
      "Tensor(\"Variable/read:0\", shape=(10, 10), dtype=float64)\n"
     ]
    }
   ],
   "source": [
    "graph = tf.Graph()\n",
    "with graph.as_default():\n",
    "    # Instanciation of two Placeholders\n",
    "    input = tf.placeholder(tf.float32)\n",
    "    test = np.random.rand(10,10)\n",
    "    var = tf.Variable(test)\n",
    "\n",
    "# Graph execution, we need to feed the placeholders\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    result = sess.run(input, feed_dict={ input: test })\n",
    "    print(result.shape)\n",
    "    \n",
    "    print(var.get_shape()[0])\n",
    "    print(var.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
