{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict what sorts of people were likely to survive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspiration:\n",
    "   - https://www.kaggle.com/omarelgabry/titanic/a-journey-through-titanic\n",
    "   - https://www.kaggle.com/poonaml/titanic/titanic-survival-prediction-end-to-end-ml-pipeline\n",
    "   - https://www.kaggle.com/helgejo/titanic/an-interactive-data-science-tutorial\n",
    "   - https://www.kaggle.com/arthurlu/titanic/exploratory-tutorial-titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- [Description of the data set](#Description-of-the-data-set)\n",
    "- [First look at the data](#First-look-at-the-data)\n",
    "    - [Import Libraries](#Import-Libraries)\n",
    "    - [Load Data](#Load-Data)\n",
    "    - [Brief summaries](#Brief-summaries)\n",
    "- [Visualization](#Visualization)\n",
    "    - [Basic insight of the data](#Basic-insight-of-the-data)\n",
    "    - [Focus on the mean of survival](#Focus-on-the-mean-of-survival)\n",
    "- [Missing Values](#Missing-Values)\n",
    "    - [Embarked](#Embarked)\n",
    "    - [Fare](#Fare)\n",
    "    - [Age with Median](#Age-with-median)\n",
    "- [Features engineering](#Features-engineering)\n",
    "    - [Name](#Name)\n",
    "    - [Family](#Family)\n",
    "    - [Name](#Name)\n",
    "- [Visualization new Features](#Visualization-new-features)\n",
    "    - [Visualization Name](#Visualization-Name)\n",
    "    - [Visualization Family](#Visualization-Family)\n",
    "- [Features Encoding](#Features-Encoding)\n",
    "    - [Categorial features encoding](#Categorial features encoding)\n",
    "        - [Label Encoding](#Label-Encoding)\n",
    "        - [One Hot Encoding](#One-Hot-Encodingn)   \n",
    "    - [Feature Scalling](#Feature-Scalling)\n",
    "    - [Data Preparation](#Data-Preparation)\n",
    "- [Features Importance](#Features-Importance)\n",
    "    - [Correlation - Numerical label](#Correlation---Numerical-label)\n",
    "    - [Correlation - One Hot Encoder](#Correlation---One-Hot-Encoder)\n",
    "    - [LDA](#LDA)\n",
    "    - [Select K Best](#Select-K-Best)\n",
    "- [Model Selection](#Model-Selection)\n",
    "    - [Helper function](#Helper-function)\n",
    "    - [Gradient Boosting Classifier](#Gradient-Boosting-Classifier)\n",
    "    - [Random Forest Classifier](#Random-Forest-Classifier)\n",
    "    - [Adaboost](#Adaboost)\n",
    "    - [SVC](#SVC)\n",
    "    - [Logistic Regression](#Logistic-Regression)\n",
    "    - [Voting Classifier](#Voting-Classifier)\n",
    "- [Submission](#Submission)\n",
    "\n",
    "\n",
    "\n",
    "- [Feature Selection](#Feature-selection)\n",
    "- [Feature Selection](#Feature-selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the data set"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "VARIABLE DESCRIPTIONS:\n",
    "survival        Survival\n",
    "                (0 = No; 1 = Yes)\n",
    "pclass          Passenger Class\n",
    "                (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "name            Name\n",
    "sex             Sex\n",
    "age             Age\n",
    "sibsp           Number of Siblings/Spouses Aboard\n",
    "parch           Number of Parents/Children Aboard\n",
    "ticket          Ticket Number\n",
    "fare            Passenger Fare\n",
    "cabin           Cabin\n",
    "embarked        Port of Embarkation\n",
    "                (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "\n",
    "SPECIAL NOTES:\n",
    "Pclass is a proxy for socio-economic status (SES)\n",
    " 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower\n",
    "\n",
    "Age is in Years; Fractional if Age less than One (1)\n",
    " If the Age is Estimated, it is in the form xx.5\n",
    "\n",
    "With respect to the family relation variables (i.e. sibsp and parch)\n",
    "some relations were ignored.  The following are the definitions used\n",
    "for sibsp and parch.\n",
    "\n",
    "Sibling:  Brother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic\n",
    "Spouse:   Husband or Wife of Passenger Aboard Titanic (Mistresses and Fiances Ignored)\n",
    "Parent:   Mother or Father of Passenger Aboard Titanic\n",
    "Child:    Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic\n",
    "\n",
    "Other family relatives excluded from this study include cousins,\n",
    "nephews/nieces, aunts/uncles, and in-laws.  Some children travelled\n",
    "only with a nanny, therefore parch=0 for them.  As well, some\n",
    "travelled with very close friends or neighbors in a village, however,\n",
    "the definitions do not support such relations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dataframe\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Sklearn\n",
    "import sklearn as sk\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "# Features and model selection\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "# Metric\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (ExtraTreesClassifier, RandomForestClassifier, \n",
    "                              AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier)\n",
    "\n",
    "# Warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data directly into a dataframe\n",
    "df_train=pd.read_csv(\"Data/Titanic/train.csv\")\n",
    "df_test=pd.read_csv(\"Data/Titanic/test.csv\")\n",
    "\n",
    "# Get a look at the first rows\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable Description\n",
    "    - Survived: Survived (1) or died (0)\n",
    "    - Pclass: Passenger's class\n",
    "    - Name: Passenger's name\n",
    "    - Sex: Passenger's sex\n",
    "    - Age: Passenger's age\n",
    "    - SibSp: Number of siblings/spouses aboard\n",
    "    - Parch: Number of parents/children aboard\n",
    "    - Ticket: Ticket number\n",
    "    - Fare: Fare\n",
    "    - Cabin: Cabin\n",
    "    - Embarked: Port of embarkation\n",
    "    \n",
    "    Source of information : https://www.kaggle.com/c/titanic/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------Informations for the training set----------------------------------\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "\n",
      " PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "\n",
      "----------------------------------Informations for the testing set ----------------------------------\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "\n",
      " PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------Informations for the training set----------------------------------\\n\")\n",
    "df_train.info()\n",
    "print('\\n',df_train.isnull().sum())\n",
    "print(\"\\n----------------------------------Informations for the testing set ----------------------------------\\n\")\n",
    "df_test.info()\n",
    "print('\\n',df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that:\n",
    "    - No Survived feature on the testing set\n",
    "    - Cabin feature is mostly null --> Will be dropped\n",
    "    - Embarked feature has a few missing values\n",
    "    - Some Ages are missing --> Will need to be completed or drop the missing rows\n",
    "    - Survived and Pclass should be treated as object because they are qualitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dropping Cabin, Ticket and PassengerId\n",
    "df_train=df_train.drop(['Cabin','PassengerId','Ticket'], axis=1)\n",
    "\n",
    "df_test=df_test.drop(['Cabin','Ticket'], axis=1)\n",
    "PassengerId = df_test['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Changing the type of Pclass and Survived \n",
    "df_train['Pclass']=df_train['Pclass'].astype(object)\n",
    "df_train['Survived']=df_train['Survived'].astype(object)\n",
    "\n",
    "df_test['Pclass']=df_test['Pclass'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------Informations for the training set----------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age       SibSp       Parch        Fare\n",
       "count  714.000000  891.000000  891.000000  891.000000\n",
       "mean    29.699118    0.523008    0.381594   32.204208\n",
       "std     14.526497    1.102743    0.806057   49.693429\n",
       "min      0.420000    0.000000    0.000000    0.000000\n",
       "25%     20.125000    0.000000    0.000000    7.910400\n",
       "50%     28.000000    0.000000    0.000000   14.454200\n",
       "75%     38.000000    1.000000    0.000000   31.000000\n",
       "max     80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Coutts, Master. William Loch \"William\"</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>549</td>\n",
       "      <td>491</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Survived  Pclass                                    Name   Sex  \\\n",
       "count        891     891                                     891   891   \n",
       "unique         2       3                                     891     2   \n",
       "top            0       3  Coutts, Master. William Loch \"William\"  male   \n",
       "freq         549     491                                       1   577   \n",
       "\n",
       "       Embarked  \n",
       "count       889  \n",
       "unique        3  \n",
       "top           S  \n",
       "freq        644  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------Informations for the testing set----------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>30.272590</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.627188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.907576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId         Age       SibSp       Parch        Fare\n",
       "count   418.000000  332.000000  418.000000  418.000000  417.000000\n",
       "mean   1100.500000   30.272590    0.447368    0.392344   35.627188\n",
       "std     120.810458   14.181209    0.896760    0.981429   55.907576\n",
       "min     892.000000    0.170000    0.000000    0.000000    0.000000\n",
       "25%     996.250000   21.000000    0.000000    0.000000    7.895800\n",
       "50%    1100.500000   27.000000    0.000000    0.000000   14.454200\n",
       "75%    1204.750000   39.000000    1.000000    0.000000   31.500000\n",
       "max    1309.000000   76.000000    8.000000    9.000000  512.329200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418</td>\n",
       "      <td>418</td>\n",
       "      <td>418</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>418</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>3</td>\n",
       "      <td>Hays, Mr. Charles Melville</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Pclass                        Name   Sex Embarked\n",
       "count      418                         418   418      418\n",
       "unique       3                         418     2        3\n",
       "top          3  Hays, Mr. Charles Melville  male        S\n",
       "freq       218                           1   266      270"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Basic statistical information about quantitative and qualitative columns\n",
    "\n",
    "print(\"----------------------------------Informations for the training set----------------------------------\\n\")\n",
    "# Quantitative\n",
    "display(df_train.describe())\n",
    "# Qualitative\n",
    "display(df_train.describe(include=['object']))\n",
    "print(\"----------------------------------Informations for the testing set----------------------------------\\n\")\n",
    "# Quantitative\n",
    "display(df_test.describe())\n",
    "# Qualitative\n",
    "display(df_test.describe(include=['object']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic insight of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Qualitative Data : [Survived, Sex, Embarked, Pclass] \n",
    "fig, (axis1,axis2,axis3,axis4) = plt.subplots(1,4,figsize=(15,5))\n",
    "sns.countplot(x='Survived', data=df_train, ax=axis1)\n",
    "sns.countplot(x='Sex', data=df_train, ax=axis2)\n",
    "sns.countplot(x='Embarked', data=df_train, ax=axis3)\n",
    "sns.countplot(x='Pclass', data=df_train, ax=axis4)\n",
    "fig.suptitle(\"Basic representation of Qualitative data with count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discrete Quantitative Data : [SibSp, Parch] \n",
    "fig2, (axis1,axis2) = plt.subplots(1,2,figsize=(15,5))\n",
    "sns.countplot(df_train['SibSp'],ax=axis1)\n",
    "sns.countplot(df_train['Parch'],ax=axis2)\n",
    "fig2.suptitle(\"Basic representation of Discrete Quantitative data with count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Continuous Quantitative Data : [Age, Fare]\n",
    "fig3, (axis1,axis2) = plt.subplots(2,1,figsize=(15,10))\n",
    "sns.distplot(df_train['Age'].dropna(), bins=80, ax=axis1)\n",
    "sns.distplot(df_train['Fare'], ax=axis2)\n",
    "fig3.suptitle(\"Basic representation of Continuous Quantitative data with probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Age distribution within Sex and Pclass\n",
    "fig3, ((axis1),(axis2),(axis3)) = plt.subplots(3,1,figsize=(15,15))\n",
    "\n",
    "# Age distribution\n",
    "df_train.Age.plot(kind='kde',ax=axis1)\n",
    "axis1.set_xlabel(\"Age\")    \n",
    "axis1.set_title(\"Age Distribution\")\n",
    "\n",
    "# Age distribution within Sex\n",
    "df_train.Age[df_train.Sex == 'male'].plot(kind='kde',ax=axis2,)    \n",
    "df_train.Age[df_train.Sex == 'female'].plot(kind='kde',ax=axis2)\n",
    "axis2.set_xlabel(\"Age\")    \n",
    "axis2.set_title(\"Age Distribution within Sex\")\n",
    "axis2.legend(('Male', 'Female'))\n",
    "\n",
    "# Age distribution within Pclass\n",
    "df_train.Age[df_train.Pclass == 1].plot(kind='kde',ax=axis3)    \n",
    "df_train.Age[df_train.Pclass == 2].plot(kind='kde',ax=axis3)\n",
    "df_train.Age[df_train.Pclass == 3].plot(kind='kde',ax=axis3)\n",
    "axis3.set_xlabel(\"Age\")    \n",
    "axis3.set_title(\"Age Distribution within Classes\")\n",
    "axis3.legend(('1st Class', '2nd Class','3rd Class'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Focus on the mean of survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [Sex, Pclass, Embarked] by mean of survival\n",
    "fig4, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(15,5))\n",
    "sns.barplot(x='Sex',y='Survived', data=df_train, ax=axis1)\n",
    "sns.barplot(x='Embarked',y='Survived', data=df_train, ax=axis2)\n",
    "sns.barplot(x='Pclass',y='Survived', data=df_train, ax=axis3)\n",
    "fig4.suptitle(\"Representation of features linked to the target : Survived \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [SibSp, Parch] by mean of survival\n",
    "fig6, (axis1,axis2) = plt.subplots(1,2,figsize=(15,5))\n",
    "sns.barplot(x='SibSp',y='Survived', data=df_train, ax=axis1)\n",
    "sns.barplot(x='Parch',y='Survived', data=df_train, ax=axis2)\n",
    "fig6.suptitle(\"Representation of features linked to the target : Survived \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross relation betwen [Sex, Pclass, Embarked] by mean of survival\n",
    "fig5, ((axis1,axis2),(axis3,axis4),(axis5,axis6)) = plt.subplots(3,2,figsize=(15,15))\n",
    "sns.barplot(x='Sex',y='Survived',hue='Pclass', data=df_train, ax=axis1)\n",
    "sns.barplot(x='Sex',y='Survived',hue='Embarked', data=df_train, ax=axis2)\n",
    "\n",
    "sns.barplot(x='Pclass',y='Survived',hue='Sex', data=df_train, ax=axis3)\n",
    "sns.barplot(x='Pclass',y='Survived',hue='Embarked', data=df_train, ax=axis4)\n",
    "\n",
    "sns.barplot(x='Embarked',y='Survived',hue='Sex', data=df_train, ax=axis5)\n",
    "sns.barplot(x='Embarked',y='Survived',hue='Pclass', data=df_train, ax=axis6)\n",
    "\n",
    "fig5.suptitle(\"Cross Representation of the features linked to the target : Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Age by mean of survival\n",
    "fig=sns.barplot(x='Age', y='Survived', data=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Age\n",
    "\n",
    "# Kernel density of survivor and non survivor by Age\n",
    "g1 = sns.FacetGrid( df_train , hue='Survived' , aspect=4)\n",
    "g1.map( sns.kdeplot , 'Age' , shade= True )\n",
    "g1.add_legend()\n",
    "\n",
    "# Kernel density of survivor and non survivor by Age and Sex \n",
    "g2 = sns.FacetGrid( df_train , hue='Survived' , aspect=4 , row = 'Sex')\n",
    "g2.map( sns.kdeplot , 'Age' , shade= True )\n",
    "g2.add_legend()\n",
    "\n",
    "# Kernel density of survivor and non survivor by Age and Pclass\n",
    "g3 = sns.FacetGrid( df_train , hue='Survived' , aspect=4 , row = 'Pclass')\n",
    "g3.map( sns.kdeplot , 'Age' , shade= True )\n",
    "g3.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fare\n",
    "\n",
    "# Scatterplot Fare & Age\n",
    "g = sns.FacetGrid(df_train, hue=\"Survived\", size=6)\n",
    "g=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\n",
    "g.add_legend()\n",
    "g.set(xlim=(0, 550))\n",
    "\n",
    "# Scatterplot Fare & Age by Sex\n",
    "g = sns.FacetGrid(df_train, hue=\"Survived\", col=\"Sex\", margin_titles=True,\n",
    "                palette=\"Set1\",hue_kws=dict(marker=[\"^\", \"v\"]),size=6)\n",
    "g=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\n",
    "g.add_legend()\n",
    "g.set(xlim=(0, 300))\n",
    "\n",
    "# Scatterplot Fare & Age by Pclass\n",
    "g = sns.FacetGrid(df_train, col=\"Pclass\", hue=\"Survived\", size=4)\n",
    "g=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\n",
    "g.add_legend()\n",
    "g.set(xlim=(0, 300))\n",
    "\n",
    "# Scatterplot Fare & Age by Pclass & Sex\n",
    "g = sns.FacetGrid(df_train, hue=\"Survived\", col=\"Pclass\", row=\"Sex\" ,margin_titles=True,\n",
    "                  palette={1:\"red\", 0:\"grey\"},size=5)\n",
    "g=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\n",
    "g.set(xlim=(0, 300))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creation of a dataframe with train and test for Feature Engineering\n",
    "def get_combined_data():\n",
    "    # reading train data\n",
    "    train = pd.read_csv(\"Data/Titanic/train.csv\")\n",
    "    \n",
    "    # reading test data\n",
    "    test = pd.read_csv(\"Data/Titanic/test.csv\")\n",
    "\n",
    "    # extracting and then removing the targets from the training data \n",
    "    targets = train.Survived\n",
    "    #train.drop('Survived',axis=1,inplace=True)\n",
    "\n",
    "    # merging train data and test data for future feature engineering\n",
    "    combined = train.append(test)\n",
    "    combined.reset_index(inplace=True)\n",
    "    combined.drop('index',axis=1,inplace=True)\n",
    "    \n",
    "    return combined\n",
    "\n",
    "def recover_train_test_target(combined):\n",
    "    \n",
    "    train0 = pd.read_csv(\"Data/Titanic/train.csv\")\n",
    "    \n",
    "    targets = train0.Survived\n",
    "    train = combined.ix[0:890]\n",
    "    test = combined.ix[891:]\n",
    "    \n",
    "    return train,test,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = get_combined_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Name\n",
    "\n",
    "#Create feature for the length of name \n",
    "combined[\"Name_Length\"] = combined[\"Name\"].apply(lambda x: len(x))\n",
    "\n",
    "# Create a categorical feature Name_Size\n",
    "combined['Name_Size']=pd.cut(combined['Name_Length']\n",
    "                            ,bins=[0,20,40,60,90]\n",
    "                            ,labels=[\"Short\",\"Medium\",\"Long\",\"Very Long\"])\n",
    "\n",
    "# Extract the title from each name\n",
    "combined['Title'] = combined['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "\n",
    "# Map for aggregated titles\n",
    "Title_Dictionary = {\n",
    "                    \"Mme\":        \"Mrs\",\n",
    "                    \"Mlle\":       \"Miss\",\n",
    "                    \"Ms\":         \"Mrs\",\n",
    "                    \"Mr\" :        \"Mr\",\n",
    "                    \"Mrs\" :       \"Mrs\",\n",
    "                    \"Miss\" :      \"Miss\",\n",
    "                    \"Capt\":       \"Officer\",\n",
    "                    \"Col\":        \"Officer\",\n",
    "                    \"Major\":      \"Officer\",\n",
    "                    \"Dr\":         \"Officer\",\n",
    "                    \"Rev\":        \"Officer\",\n",
    "                    \"Master\" :    \"Master\",\n",
    "                    \"Lady\" :      \"Royalty\",\n",
    "                    \"Jonkheer\":   \"Royalty\",\n",
    "                    \"Don\":        \"Royalty\",\n",
    "                    \"Sir\" :       \"Royalty\",\n",
    "                    \"Dona\":       \"Royalty\",\n",
    "                    \"the Countess\":\"Royalty\"\n",
    "                    }\n",
    "    \n",
    "# Mapping\n",
    "combined['Title_aggr'] = combined.Title.map(Title_Dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Family\n",
    "\n",
    "# Creation of a feature Number_of_relatives = SibSp + Parch\n",
    "combined['Number_of_relatives']=combined['SibSp']+combined['Parch']\n",
    "\n",
    "# Creation of a categorical feature Size_Family\n",
    "combined.loc[combined['Number_of_relatives'] == 0, 'Size_Family'] = 'Alone'\n",
    "combined.loc[ (combined['Number_of_relatives'] > 0) \n",
    "            & (combined['Number_of_relatives'] < 4), 'Size_Family'] = 'Small'\n",
    "combined.loc[combined['Number_of_relatives'] > 3, 'Size_Family'] = 'Big'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create 3 categories : \n",
    "    - Alone = 0\n",
    "    - Small = [1,2,3]\n",
    "    - Big = > 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Fare  Pclass Embarked\n",
       "61   80.0       1      NaN\n",
       "829  80.0       1      NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAGTCAYAAAA8+/sRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlySpcP8fR8Rsd/AUvawAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f57aafc2d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Embarked\n",
    "\n",
    "# Get the null rows where Embarked is null\n",
    "display(combined[combined.Embarked.isnull()][['Fare', 'Pclass', 'Embarked']])\n",
    "\n",
    "# Embarked missing values\n",
    "combined.boxplot(column='Fare', by=['Embarked','Pclass'], figsize=(8,6))\n",
    "plt.axhline(y=80, color='blue')\n",
    "\n",
    "# Remplace null values by C because most people who are Pclass 1 and Fare 80 has Embarked from C\n",
    "combined = combined.set_value(combined.Embarked.isnull(), 'Embarked', 'C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFlCAYAAAA6QpuEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWXDEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f57aae8eba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fare\n",
    "\n",
    "# Visualization of the fare which is missing\n",
    "combined[combined.Fare.isnull()][['Pclass', 'Fare', 'Embarked']]\n",
    "#df_test[(df_test.Pclass==3)&(df_test.Embarked=='S')].Fare.hist(bins=100)\n",
    "combined.loc[(combined['Pclass']==3) & (combined['Embarked']=='S')].Fare.hist(bins=100,figsize=(8,6))\n",
    "\n",
    "# Get and affect the median to the missing value\n",
    "Fare_median=combined[(combined.Pclass==3) & (combined.Embarked=='S')].Fare.median()\n",
    "#df_test = df_test.set_value(df_test.Fare.isnull(), 'Fare', Fare_median)\n",
    "combined[\"Fare\"].fillna(Fare_median, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex     Pclass  Title_aggr\n",
       "female  1       Miss          30.0\n",
       "                Mrs           45.0\n",
       "                Officer       49.0\n",
       "                Royalty       39.0\n",
       "        2       Miss          20.0\n",
       "                Mrs           30.0\n",
       "        3       Miss          18.0\n",
       "                Mrs           31.0\n",
       "male    1       Master         6.0\n",
       "                Mr            41.5\n",
       "                Officer       52.0\n",
       "                Royalty       40.0\n",
       "        2       Master         2.0\n",
       "                Mr            30.0\n",
       "                Officer       41.5\n",
       "        3       Master         6.0\n",
       "                Mr            26.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simply fill the nan values with median using Sex, Pclass and Title\n",
    "grouped = combined.groupby(['Sex','Pclass','Title_aggr'])\n",
    "age_median = grouped['Age'].median()\n",
    "display(age_median)\n",
    "combined[\"Age\"] = combined.groupby(['Sex','Pclass','Title_aggr'])['Age'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verification of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                       0\n",
       "Cabin                  1014\n",
       "Embarked                  0\n",
       "Fare                      0\n",
       "Name                      0\n",
       "Parch                     0\n",
       "PassengerId               0\n",
       "Pclass                    0\n",
       "Sex                       0\n",
       "SibSp                     0\n",
       "Survived                418\n",
       "Ticket                    0\n",
       "Name_Length               0\n",
       "Name_Size                 0\n",
       "Title                     0\n",
       "Title_aggr                0\n",
       "Number_of_relatives       0\n",
       "Size_Family               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split\n",
    "df_train, df_test, targets = recover_train_test_target(combined)\n",
    "\n",
    "# Dropping Cabin, Ticket and PassengerId\n",
    "df_train = df_train.drop(['Cabin','PassengerId','Ticket'], axis=1)\n",
    "df_test = df_test.drop(['Cabin','Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 15)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Embarked', 'Fare', 'Name', 'Parch', 'Pclass', 'Sex', 'SibSp',\n",
       "       'Survived', 'Name_Length', 'Name_Size', 'Title', 'Title_aggr',\n",
       "       'Number_of_relatives', 'Size_Family'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization new Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for /: 'str' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-89-032e687c4df7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Plot Name_Size by mean of survival\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Name_Size'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Short\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Medium\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Long\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"Very Long\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# Plot Name_Size by mean of survival\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jules/anaconda3/lib/python3.6/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mbarplot\u001b[0;34m(x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, orient, color, palette, saturation, errcolor, errwidth, capsize, ax, **kwargs)\u001b[0m\n\u001b[1;32m   2897\u001b[0m                           \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2898\u001b[0m                           \u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2899\u001b[0;31m                           errcolor, errwidth, capsize)\n\u001b[0m\u001b[1;32m   2900\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2901\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0max\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jules/anaconda3/lib/python3.6/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, hue, data, order, hue_order, estimator, ci, n_boot, units, orient, color, palette, saturation, errcolor, errwidth, capsize)\u001b[0m\n\u001b[1;32m   1543\u001b[0m                                  order, hue_order, units)\n\u001b[1;32m   1544\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestablish_colors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1545\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_statistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1547\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merrcolor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merrcolor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jules/anaconda3/lib/python3.6/site-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mestimate_statistic\u001b[0;34m(self, estimator, ci, n_boot)\u001b[0m\n\u001b[1;32m   1438\u001b[0m                     \u001b[0mstatistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1439\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1440\u001b[0;31m                     \u001b[0mstatistic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstat_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1442\u001b[0m                 \u001b[0;31m# Get a confidence interval for this estimate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jules/anaconda3/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m   2940\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2941\u001b[0m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0;32m-> 2942\u001b[0;31m                             out=out, **kwargs)\n\u001b[0m\u001b[1;32m   2943\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/jules/anaconda3/lib/python3.6/site-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims)\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mret\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mrcount\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for /: 'str' and 'int'"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3oAAANOCAYAAABHuH7DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f57aae73128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Vrack v1 a faire marcher\n",
    "fig5, ((axis1,axis2),(axis3,axis4),(axis5,axis6),(axis7,axis8)) = plt.subplots(4,2,figsize=(15,15))\n",
    "\n",
    "# Plot Name_Length\n",
    "sns.countplot(x='Name_Length', data=df_train, ax=axis1)\n",
    "\n",
    "# Plot Name_Length by mean of survival\n",
    "sns.barplot(x='Name_Length', y='Survived', data=df_train, ax=axis2)\n",
    "\n",
    "# Plot Name_Size by mean of survival\n",
    "sns.barplot(x='Name_Size', data=df_train, order=[\"Short\",\"Medium\",\"Long\",\"Very Long\"], ax=axis3)\n",
    "\n",
    "# Plot Name_Size by mean of survival\n",
    "sns.barplot(x='Name_Size',y='Survived', data=df_train, order=[\"Short\",\"Medium\",\"Long\",\"Very Long\"], ax=axis4)\n",
    "\n",
    "# Plot Title aggregate\n",
    "sns.barplot(x='Title_aggr', data=df_train, ax=axis5)\n",
    "\n",
    "# Display Title aggregate by mean of survival\n",
    "sns.barplot(x='Title_aggr',y='Survived', data=df_train, ax=axis6)\n",
    "\n",
    "# Display Title aggregate and Name Size by mean of survival\n",
    "sns.barplot(x='Title_aggr',y='Survived', hue='Name_Size', data=df_train, ax=axis7)\n",
    "\n",
    "# Display Title aggregate and Name Size by mean of survival\n",
    "sns.barplot(x='Name_Size',y='Survived', hue='Title_aggr', data=df_train, ax=axis8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Vrack v2 a faire marcher\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "fig=sns.countplot(x='Name_Length', data=df_train)\n",
    "\n",
    "fig=sns.barplot(x='Name_Length', y='Survived', data=df_train)\n",
    "\n",
    "sns.barplot(x='Name_Size',y='Survived', data=df_train, order=[\"Short\",\"Medium\",\"Long\",\"Very Long\"])\n",
    "\n",
    "# Display aggregate title by survived probability\n",
    "fig1 = plt.figure(figsize=(15, 5))\n",
    "fig1=sns.barplot(x='Title_aggr',y='Survived', data=df_train)\n",
    "\n",
    "# Display aggregate title and Name Size by survived probability\n",
    "fig2 = plt.figure(figsize=(15, 5))\n",
    "fig2=sns.barplot(x='Title_aggr',y='Survived', hue='Name_Size', data=df_train)\n",
    "\n",
    "# Display aggregate title and Name Size by survived probability\n",
    "fig3 = plt.figure(figsize=(15, 5))\n",
    "fig3=sns.barplot(x='Name_Size',y='Survived', hue='Title_aggr', data=df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A afficher correctrement\n",
    "fig1 = plt.figure(figsize=(15, 5))\n",
    "fig1 = sns.countplot(x='Number_of_relatives', data=df_train)\n",
    "\n",
    "fig2 = plt.figure(figsize=(15, 5))\n",
    "fig2 = sns.barplot(x='Number_of_relatives',y='Survived', data=df_train)\n",
    "\n",
    "sns.barplot(x='Size_Family',y='Survived', data=df_train, order=['Alone', 'Small', 'Big'])\n",
    "\n",
    "# Number_of_relatives with Pclass, Sex, Embarked by mean of survival\n",
    "fig7, ((axis1),(axis2),(axis3)) = plt.subplots(3,1,figsize=(20,20))\n",
    "sns.barplot(x='Number_of_relatives',y='Survived',hue='Pclass', data=df_train, ax=axis1)\n",
    "sns.barplot(x='Number_of_relatives',y='Survived',hue='Sex', data=df_train, ax=axis2)\n",
    "sns.barplot(x='Number_of_relatives',y='Survived',hue='Embarked', data=df_train, ax=axis3)\n",
    "fig7.suptitle(\"Cross Representation of the features linked to the target : Survived\")\n",
    "\n",
    "# Size_Family with Pclass, Sex, Embarked by mean of survival\n",
    "fig8, ((axis1),(axis2),(axis3)) = plt.subplots(3,1,figsize=(20,20))\n",
    "sns.barplot(x='Size_Family',y='Survived',hue='Pclass', data=df_train, order=['Alone', 'Small', 'Big'], ax=axis1,)\n",
    "sns.barplot(x='Size_Family',y='Survived',hue='Sex', data=df_train, order=['Alone', 'Small', 'Big'], ax=axis2)\n",
    "sns.barplot(x='Size_Family',y='Survived',hue='Embarked', data=df_train, order=['Alone', 'Small', 'Big'], ax=axis3)\n",
    "fig8.suptitle(\"Cross Representation of the features linked to the target : Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "display(combined.columns)\n",
    "display(combined.isnull().sum())\n",
    "display(combined.shape)\n",
    "display(combined[[\"Embarked\",\"Sex\",\"Title_aggr\",\"Size_Family\",\"Name_Size\",\"Pclass\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorial features encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Dataframe with numerical categorical feature\n",
    "combined_num_cat = pd.DataFrame()\n",
    "\n",
    "# LabelEncoder\n",
    "labelEnc = LabelEncoder()\n",
    "\n",
    "# Columns to apply\n",
    "cat_vars=[\"Embarked\",\"Sex\",\"Title_aggr\",\"Size_Family\",\"Name_Size\"]\n",
    "\n",
    "for col in cat_vars:\n",
    "    labelEnc.fit(np.unique(list(combined[col].values)))\n",
    "    combined_num_cat[col]=labelEnc.transform(combined[col].astype('str'))\n",
    "    \n",
    "labelEnc.fit(np.unique(list(combined[\"Pclass\"].values)))\n",
    "combined_num_cat[\"Pclass\"]=labelEnc.transform(combined[\"Pclass\"].astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Title_aggr</th>\n",
       "      <th>Size_Family</th>\n",
       "      <th>Name_Size</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Embarked  Sex  Title_aggr  Size_Family  Name_Size  Pclass\n",
       "0         2    1           2            2          1       2\n",
       "1         0    0           3            2          0       0\n",
       "2         2    0           1            0          1       2\n",
       "3         2    0           3            2          0       0\n",
       "4         2    1           2            0          1       2"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_num_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One Hot  Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(df_in, cols):\n",
    "    df_out = pd.DataFrame()\n",
    "    for each in cols:\n",
    "        dummies = pd.get_dummies(df_in[each], prefix=each, drop_first=False)\n",
    "        df_out = pd.concat([df_out, dummies], axis=1)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataframe with binary categorical feature\n",
    "\n",
    "# Columns to apply\n",
    "cat_vars=['Embarked','Sex',\"Title_aggr\",\"Size_Family\",\"Name_Size\",\"Pclass\"]\n",
    "combined_One_Hot_Cat = one_hot(combined,cat_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Title_aggr_Master</th>\n",
       "      <th>Title_aggr_Miss</th>\n",
       "      <th>Title_aggr_Mr</th>\n",
       "      <th>Title_aggr_Mrs</th>\n",
       "      <th>Title_aggr_Officer</th>\n",
       "      <th>...</th>\n",
       "      <th>Size_Family_Alone</th>\n",
       "      <th>Size_Family_Big</th>\n",
       "      <th>Size_Family_Small</th>\n",
       "      <th>Name_Size_Short</th>\n",
       "      <th>Name_Size_Medium</th>\n",
       "      <th>Name_Size_Long</th>\n",
       "      <th>Name_Size_Very Long</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Embarked_C  Embarked_Q  Embarked_S  Sex_female  Sex_male  \\\n",
       "0           0           0           1           0         1   \n",
       "1           1           0           0           1         0   \n",
       "2           0           0           1           1         0   \n",
       "3           0           0           1           1         0   \n",
       "4           0           0           1           0         1   \n",
       "\n",
       "   Title_aggr_Master  Title_aggr_Miss  Title_aggr_Mr  Title_aggr_Mrs  \\\n",
       "0                  0                0              1               0   \n",
       "1                  0                0              0               1   \n",
       "2                  0                1              0               0   \n",
       "3                  0                0              0               1   \n",
       "4                  0                0              1               0   \n",
       "\n",
       "   Title_aggr_Officer    ...     Size_Family_Alone  Size_Family_Big  \\\n",
       "0                   0    ...                     0                0   \n",
       "1                   0    ...                     0                0   \n",
       "2                   0    ...                     1                0   \n",
       "3                   0    ...                     0                0   \n",
       "4                   0    ...                     1                0   \n",
       "\n",
       "   Size_Family_Small  Name_Size_Short  Name_Size_Medium  Name_Size_Long  \\\n",
       "0                  1                0                 1               0   \n",
       "1                  1                0                 0               1   \n",
       "2                  0                0                 1               0   \n",
       "3                  1                0                 0               1   \n",
       "4                  0                0                 1               0   \n",
       "\n",
       "   Name_Size_Very Long  Pclass_1  Pclass_2  Pclass_3  \n",
       "0                    0         0         0         1  \n",
       "1                    0         1         0         0  \n",
       "2                    0         0         0         1  \n",
       "3                    0         1         0         0  \n",
       "4                    0         0         0         1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_One_Hot_Cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age</th>\n",
       "      <th>Name_Length</th>\n",
       "      <th>Number_of_relatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2500</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.2833</td>\n",
       "      <td>38.0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.9250</td>\n",
       "      <td>26.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.1000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0500</td>\n",
       "      <td>35.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fare   Age  Name_Length  Number_of_relatives\n",
       "0   7.2500  22.0           23                    1\n",
       "1  71.2833  38.0           51                    1\n",
       "2   7.9250  26.0           22                    0\n",
       "3  53.1000  35.0           44                    1\n",
       "4   8.0500  35.0           24                    0"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[['Fare','Age','Name_Length','Number_of_relatives']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age</th>\n",
       "      <th>Name_Length</th>\n",
       "      <th>Number_of_relatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.503176</td>\n",
       "      <td>-0.541471</td>\n",
       "      <td>-0.434672</td>\n",
       "      <td>0.073352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.734809</td>\n",
       "      <td>0.648868</td>\n",
       "      <td>2.511806</td>\n",
       "      <td>0.073352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.490126</td>\n",
       "      <td>-0.243886</td>\n",
       "      <td>-0.539904</td>\n",
       "      <td>-0.558346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.383263</td>\n",
       "      <td>0.425680</td>\n",
       "      <td>1.775186</td>\n",
       "      <td>0.073352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.487709</td>\n",
       "      <td>0.425680</td>\n",
       "      <td>-0.329441</td>\n",
       "      <td>-0.558346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Fare       Age  Name_Length  Number_of_relatives\n",
       "0 -0.503176 -0.541471    -0.434672             0.073352\n",
       "1  0.734809  0.648868     2.511806             0.073352\n",
       "2 -0.490126 -0.243886    -0.539904            -0.558346\n",
       "3  0.383263  0.425680     1.775186             0.073352\n",
       "4 -0.487709  0.425680    -0.329441            -0.558346"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "combined_num_std = pd.DataFrame(combined[['Fare','Age','Name_Length','Number_of_relatives']])\n",
    "\n",
    "# StandardScaller process\n",
    "std_scale = preprocessing.StandardScaler()\n",
    "combined_num_std[['Fare','Age','Name_Length','Number_of_relatives']] = std_scale.fit_transform(combined[['Fare','Age','Name_Length','Number_of_relatives']].astype(float))\n",
    "\n",
    "combined_num_std[['Fare','Age','Name_Length','Number_of_relatives']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Available :\n",
    "combined_num_std\n",
    "combined_One_Hot_Cat\n",
    "combined_num_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concat\n",
    "combined_OH_Std = pd.concat([combined_num_std,combined_One_Hot_Cat],axis=1)\n",
    "combined_Num_Std = pd.concat([combined_num_std,combined_num_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 25)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1309, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display shape\n",
    "display(combined_OH_Std.shape)\n",
    "display(combined_Num_Std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into Train and Eval\n",
    "Train_OH_Std, Eval_OH_Std, Target_OH_Std = recover_train_test_target(combined_OH_Std)\n",
    "Train_Num_Std, Eval_Num_Std, Target_Num_Std = recover_train_test_target(combined_Num_Std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 25)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(418, 25)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(891,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display shape\n",
    "display(Train_OH_Std.shape)\n",
    "display(Eval_OH_Std.shape)\n",
    "display(Target_OH_Std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select Data\n",
    "data = Train_OH_Std\n",
    "test_data = Eval_OH_Std\n",
    "target = Target_OH_Std\n",
    "columns_name = list(Train_OH_Std)\n",
    "\n",
    "# Train & Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20)\n",
    "\n",
    "# Dataframe of prediction\n",
    "Prediction = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation - Numerical label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name_Length</th>\n",
       "      <td>0.332350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.257307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Size_Family</th>\n",
       "      <td>0.249714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number_of_relatives</th>\n",
       "      <td>0.016639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.059594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_aggr</th>\n",
       "      <td>-0.062916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>-0.174199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name_Size</th>\n",
       "      <td>-0.261576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>-0.543351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Corr\n",
       "Survived             1.000000\n",
       "Name_Length          0.332350\n",
       "Fare                 0.257307\n",
       "Size_Family          0.249714\n",
       "Number_of_relatives  0.016639\n",
       "Age                 -0.059594\n",
       "Title_aggr          -0.062916\n",
       "Embarked            -0.174199\n",
       "Name_Size           -0.261576\n",
       "Pclass              -0.338481\n",
       "Sex                 -0.543351"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concant data and target\n",
    "Features_with_target = pd.concat([Train_Num_Std,target],axis=1)\n",
    "# Correlation with target\n",
    "Corr = pd.DataFrame()\n",
    "Corr['Corr'] = Features_with_target.corr()[\"Survived\"]\n",
    "Corr.sort_values('Corr',ascending=False,inplace=True)\n",
    "display(Corr)\n",
    "# A réfléchir au sens en regardant la formule de corr pour les catégories le numerical label ordinales et non ordinales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation - One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_female</th>\n",
       "      <td>0.543351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_aggr_Mrs</th>\n",
       "      <td>0.344935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_aggr_Miss</th>\n",
       "      <td>0.332795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name_Length</th>\n",
       "      <td>0.332350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass_1</th>\n",
       "      <td>0.285904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Size_Family_Small</th>\n",
       "      <td>0.279855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name_Size_Long</th>\n",
       "      <td>0.273448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.257307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>0.174718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass_2</th>\n",
       "      <td>0.093349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_aggr_Master</th>\n",
       "      <td>0.085221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name_Size_Very Long</th>\n",
       "      <td>0.085083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_aggr_Royalty</th>\n",
       "      <td>0.033391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Number_of_relatives</th>\n",
       "      <td>0.016639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>0.003650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name_Size_Medium</th>\n",
       "      <td>-0.000867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_aggr_Officer</th>\n",
       "      <td>-0.031316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.059594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Size_Family_Big</th>\n",
       "      <td>-0.125147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>-0.155660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name_Size_Short</th>\n",
       "      <td>-0.193143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Size_Family_Alone</th>\n",
       "      <td>-0.203367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass_3</th>\n",
       "      <td>-0.322308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_male</th>\n",
       "      <td>-0.543351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_aggr_Mr</th>\n",
       "      <td>-0.549199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Corr\n",
       "Survived             1.000000\n",
       "Sex_female           0.543351\n",
       "Title_aggr_Mrs       0.344935\n",
       "Title_aggr_Miss      0.332795\n",
       "Name_Length          0.332350\n",
       "Pclass_1             0.285904\n",
       "Size_Family_Small    0.279855\n",
       "Name_Size_Long       0.273448\n",
       "Fare                 0.257307\n",
       "Embarked_C           0.174718\n",
       "Pclass_2             0.093349\n",
       "Title_aggr_Master    0.085221\n",
       "Name_Size_Very Long  0.085083\n",
       "Title_aggr_Royalty   0.033391\n",
       "Number_of_relatives  0.016639\n",
       "Embarked_Q           0.003650\n",
       "Name_Size_Medium    -0.000867\n",
       "Title_aggr_Officer  -0.031316\n",
       "Age                 -0.059594\n",
       "Size_Family_Big     -0.125147\n",
       "Embarked_S          -0.155660\n",
       "Name_Size_Short     -0.193143\n",
       "Size_Family_Alone   -0.203367\n",
       "Pclass_3            -0.322308\n",
       "Sex_male            -0.543351\n",
       "Title_aggr_Mr       -0.549199"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concant data and target\n",
    "Features_with_target = pd.concat([Train_OH_Std,target],axis=1)\n",
    "# Correlation with target\n",
    "Corr = pd.DataFrame()\n",
    "Corr['Corr'] = Features_with_target.corr()[\"Survived\"]\n",
    "Corr.sort_values('Corr',ascending=False,inplace=True)\n",
    "display(Corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set\n",
      "LDA Accuracy : 0.842696629213\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.91      0.88       436\n",
      "          1       0.84      0.74      0.78       276\n",
      "\n",
      "avg / total       0.84      0.84      0.84       712\n",
      "\n",
      "Confusion Matrix :\n",
      " [[396  40]\n",
      " [ 72 204]]\n",
      "Balance of classes [ 0.61235955  0.38764045]\n",
      "-----------------------------------------------------------------------------\n",
      "Testing set\n",
      "LDA Accuracy : 0.810055865922\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.84      0.85       113\n",
      "          1       0.74      0.76      0.75        66\n",
      "\n",
      "avg / total       0.81      0.81      0.81       179\n",
      "\n",
      "Confusion Matrix :\n",
      " [[95 18]\n",
      " [16 50]]\n",
      "Balance of classes [ 0.61235955  0.38764045]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jules/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Title_aggr_Master</td>\n",
       "      <td>3.725954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Sex_female</td>\n",
       "      <td>1.678109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Pclass_1</td>\n",
       "      <td>1.428481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Name_Size_Very Long</td>\n",
       "      <td>1.096566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Size_Family_Alone</td>\n",
       "      <td>0.907183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Name_Size_Long</td>\n",
       "      <td>0.843399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Size_Family_Small</td>\n",
       "      <td>0.297384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Number_of_relatives</td>\n",
       "      <td>0.234446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>0.233428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Title_aggr_Miss</td>\n",
       "      <td>0.194445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.163461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.099998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Title_aggr_Mrs</td>\n",
       "      <td>0.083369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Name_Length</td>\n",
       "      <td>0.022475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Name_Size_Medium</td>\n",
       "      <td>-0.051189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>-0.069906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>-0.245581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Name_Size_Short</td>\n",
       "      <td>-0.308402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>-0.401911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Title_aggr_Royalty</td>\n",
       "      <td>-0.516941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Title_aggr_Officer</td>\n",
       "      <td>-0.934822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Title_aggr_Mr</td>\n",
       "      <td>-0.983615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>-1.012883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Sex_male</td>\n",
       "      <td>-1.678109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Size_Family_Big</td>\n",
       "      <td>-4.150540</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Features      Coef\n",
       "9     Title_aggr_Master  3.725954\n",
       "7            Sex_female  1.678109\n",
       "22             Pclass_1  1.428481\n",
       "21  Name_Size_Very Long  1.096566\n",
       "15    Size_Family_Alone  0.907183\n",
       "20       Name_Size_Long  0.843399\n",
       "17    Size_Family_Small  0.297384\n",
       "3   Number_of_relatives  0.234446\n",
       "4            Embarked_C  0.233428\n",
       "10      Title_aggr_Miss  0.194445\n",
       "5            Embarked_Q  0.163461\n",
       "0                  Fare  0.099998\n",
       "12       Title_aggr_Mrs  0.083369\n",
       "2           Name_Length  0.022475\n",
       "19     Name_Size_Medium -0.051189\n",
       "23             Pclass_2 -0.069906\n",
       "6            Embarked_S -0.245581\n",
       "18      Name_Size_Short -0.308402\n",
       "1                   Age -0.401911\n",
       "14   Title_aggr_Royalty -0.516941\n",
       "13   Title_aggr_Officer -0.934822\n",
       "11        Title_aggr_Mr -0.983615\n",
       "24             Pclass_3 -1.012883\n",
       "8              Sex_male -1.678109\n",
       "16      Size_Family_Big -4.150540"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA\n",
    "# LDA with n = 2 solver svd --> score : 0.78947\n",
    "lda = LinearDiscriminantAnalysis(n_components = 2, solver='svd')\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred_lda = lda.predict(X_train)\n",
    "y_test_pred_lda = lda.predict(X_test)\n",
    "\n",
    "lda_acc = accuracy_score(y_test, y_test_pred_lda)\n",
    "lda_cr= classification_report(y_test, y_test_pred_lda)\n",
    "lda_cm = confusion_matrix(y_test, y_test_pred_lda)\n",
    "\n",
    "lda_acc_train = accuracy_score(y_train, y_train_pred_lda)\n",
    "lda_cr_train = classification_report(y_train, y_train_pred_lda)\n",
    "lda_cm_train = confusion_matrix(y_train, y_train_pred_lda)\n",
    "\n",
    "print(\"Training set\")\n",
    "print( \"LDA Accuracy :\", lda_acc_train)\n",
    "print(lda_cr_train)\n",
    "print(\"Confusion Matrix :\\n\",lda_cm_train)\n",
    "#print('Explained variance ratio :',lda.explained_variance_ratio_)\n",
    "print('Balance of classes',lda.priors_)\n",
    "\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "print(\"Testing set\")\n",
    "print( \"LDA Accuracy :\", lda_acc)\n",
    "print(lda_cr)\n",
    "print(\"Confusion Matrix :\\n\",lda_cm)\n",
    "#print('Explained variance ratio :',lda.explained_variance_ratio_)\n",
    "print('Balance of classes',lda.priors_)\n",
    "\n",
    "\n",
    "\n",
    "Prediction['LDA'] = lda.predict(Eval_OH_Std)\n",
    "\n",
    "\n",
    "Coef = pd.DataFrame()\n",
    "Coef['Features'] = list(X_train.columns)\n",
    "Coef['Coef'] = lda.coef_.transpose()\n",
    "Coef.sort_values('Coef',ascending=False,inplace=True)\n",
    "Coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From selectkbest\n",
    "import numpy as np\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.cross_validation import KFold\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "#predictors = [\"Pclass\", \"Sex\", \"Age\", \"Fare\",\n",
    " #             \"FsizeD\", \"Embarked\", \"NlengthD\",\"Deck\",\"TicketNumber\"]\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\",\n",
    "              \"Fare\",\"NlengthD\", \"FsizeD\",\"NameLength\",\"Deck\",\"Embarked\"]\n",
    "# Perform feature selection\n",
    "selector = SelectKBest(f_classif, k=5)\n",
    "selector.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "\n",
    "# Get the raw p-values for each feature, and transform from p-values into scores\n",
    "scores = -np.log10(selector.pvalues_)\n",
    "\n",
    "indices = np.argsort(scores)[::-1]\n",
    "\n",
    "sorted_important_features=[]\n",
    "for i in indices:\n",
    "    sorted_important_features.append(predictors[i])\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Feature Importances By SelectKBest\")\n",
    "plt.bar(range(np.size(predictors)), scores[indices],\n",
    "       color=\"seagreen\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(np.size(predictors)), sorted_important_features, rotation='vertical')\n",
    "\n",
    "plt.xlim([-1, np.size(predictors)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# From Random Forest\n",
    "importances=rf.feature_importances_\n",
    "std = np.std([rf.feature_importances_ for tree in rf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "sorted_important_features=[]\n",
    "for i in indices:\n",
    "    sorted_important_features.append(predictors[i])\n",
    "#predictors=titanic.columns\n",
    "plt.figure()\n",
    "plt.title(\"Feature Importances By Random Forest Model\")\n",
    "plt.bar(range(np.size(predictors)), importances[indices],\n",
    "       color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(np.size(predictors)), sorted_important_features, rotation='vertical')\n",
    "\n",
    "plt.xlim([-1, np.size(predictors)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper function to analyse and get result\n",
    "\n",
    "# Plot the confusion matrice \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "# Grid Score into a Pandas Dataframe\n",
    "def cv_results_to_df(cv_results):\n",
    "    \"\"\"\n",
    "    Convert a sklearn.model_selection.GridSearchCV.cv_results_ attribute to a tidy\n",
    "    pandas DataFrame where the output is filtered with only mean std and params.\n",
    "    \"\"\"\n",
    "    df=pd.DataFrame.from_dict(cv_results)\n",
    "    df=df[['mean_test_score', 'std_test_score', 'mean_train_score', 'std_train_score', 'params']]\n",
    "    df.sort_values('mean_test_score',ascending=False,inplace=True)\n",
    "    return df\n",
    "\n",
    "# Helper function for gridseach\n",
    "def grid_search_global(clas_reg, dict_pip, dict_param, class_names):\n",
    "\n",
    "    dict_of_res={}\n",
    "    dict_of_best={}\n",
    "    df_results_global=pd.DataFrame()\n",
    "    \n",
    "    print (\"Starting Gridsearch\")\n",
    "    \n",
    "    for key in dict_param.keys():\n",
    "        gs = GridSearchCV(dict_pip[key], dict_param[key], verbose=0, refit=True, n_jobs=-1, cv=5)\n",
    "        gs = gs.fit(X_train, y_train)\n",
    "        dict_of_res[key]=gs.grid_scores_\n",
    "        \n",
    "        print('\\n-------------------------------------------------------------------------------------------------------')\n",
    "        print (\"Gridsearch for %s \\n\" % dict_param[key])\n",
    "        print (\"Best score :\", gs.best_score_)\n",
    "        print (\"Best params :\",gs.best_params_)\n",
    "        dict_of_best[key]=[gs.best_score_,gs.best_params_]\n",
    "        \n",
    "        y_train_pred=gs.predict(X_train)\n",
    "        y_test_pred=gs.predict(X_test)\n",
    "        \n",
    "        if (clas_reg=='clas'):\n",
    "            \n",
    "            # Classification report\n",
    "            print('\\nClassification report on training set')\n",
    "            print(classification_report(y_train, y_train_pred))\n",
    "            print('\\nClassification report on testing set')\n",
    "            print(classification_report(y_test, y_test_pred))\n",
    "            \n",
    "            # Compute confusion matrix\n",
    "            #cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "            #np.set_printoptions(precision=2)\n",
    "\n",
    "            # Plot non-normalized confusion matrix\n",
    "            #plt.figure()\n",
    "            #plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "            #                      title='Confusion matrix, without normalization')\n",
    "            \n",
    "            # Plot normalized confusion matrix\n",
    "            #plt.figure()\n",
    "            #plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "            #                      title='Normalized confusion matrix')\n",
    "            \n",
    "            #plt.show()\n",
    "        \n",
    "        # Resultats deja présent dans : Grid Score #cv_results_ alégé\n",
    "        #print('\\nGrid Score #grid_scores_')\n",
    "        #pprint(gs.grid_scores_)\n",
    "        \n",
    "        # Obtention des résultats avec selection et réarrangement des attributs puis stockage\n",
    "        df_results=cv_results_to_df(gs.cv_results_)\n",
    "        df_results['Algo']=key\n",
    "        df_results=df_results[['Algo','mean_test_score', 'std_test_score', 'mean_train_score', 'std_train_score', 'params']]\n",
    "        df_results_global=df_results_global.append(df_results)\n",
    "        print(\"\\nGrid Score #cv_results_ alégé\")\n",
    "        display(df_results)\n",
    "        \n",
    "\n",
    "        \n",
    "    # Transformation de dict_of_best en dataframe\n",
    "    df_best=pd.DataFrame.from_dict(dict_of_best,'index')\n",
    "    df_best.columns=['Scores','Parameters']\n",
    "    df_best.sort_values('Scores',ascending=False,inplace=True)  \n",
    "\n",
    "    print('\\n -------------------------------------------------------------------------------------------------------')\n",
    "    print('\\nList of best score and parameters by pipeline')\n",
    "    display(df_best)\n",
    "    print('\\nSummary')\n",
    "    display(df_results_global)\n",
    "    print (\"Gridsearch Finished\")\n",
    "    print('\\n -------------------------------------------------------------------------------------------------------')    \n",
    "    return df_best, dict_of_best, df_results_global   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multipes Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pipeline setup\n",
    "models = { \n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'SVC': SVC()\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params = {\n",
    "    # Il faut mettre 'ExtraTreesClassifier__n_estimators' dans 'ExtraTreesClassifier' car on est sur un pipeline \n",
    "    # il est donc possible de préciser des parametres pour chacune des étapes\n",
    "    'RandomForestClassifier': { 'n_estimators': [5, 10, 15, 20, 25, 30, 35] },\n",
    "    'GradientBoostingClassifier': { 'n_estimators': [5, 10, 15, 20, 25, 30, 35], 'learning_rate': [0.8, 1.0] },\n",
    "    'SVC': [\n",
    "        {'kernel': ['linear'], 'C': [1, 10]},\n",
    "        {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Lancer la grid search\n",
    "df_best, dic_best, d_res =grid_search_global('clas',models,params,class_names=columns_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pipeline setup\n",
    "models = { \n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params = {\n",
    "    'GradientBoostingClassifier': { 'n_estimators': [5, 10, 20, 30, 40, 50, 60, 70 , 80 , 90, 100, 120, 150, 170, 200, 250, 300, 400, 500], \n",
    "                                   'learning_rate': [0.01,0.03,0.8,0.12,0.16,0.18,0.2,0.25,0.28,0.32,0.37,0.42,0.50,0.60,0.70,0.80,0.9],\n",
    "                                  'loss' : ['deviance','exponential'],\n",
    "                                  'max_depth' : [2, 3, 4, 5, 6, 7, 8, 9, 10] \n",
    "                                  }\n",
    "}\n",
    "\n",
    "# Lancer la grid search\n",
    "df_best, dic_best, d_res =grid_search_global('clas',models,params,class_names=columns_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pipeline setup\n",
    "models = { \n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params = {\n",
    "    # Il faut mettre 'ExtraTreesClassifier__n_estimators' dans 'ExtraTreesClassifier' car on est sur un pipeline \n",
    "    # il est donc possible de préciser des parametres pour chacune des étapes\n",
    "    'RandomForestClassifier': { 'n_estimators': [5, 10, 20, 30, 40, 50 ,100, 500 ],\n",
    "                               'criterion' : ['gini','entropy'],\n",
    "                               'max_features':['sqrt','log2',2,4,8,12,14,18,22],\n",
    "                               'min_samples_split': [2,3,5,6,8,10],\n",
    "                               'min_samples_leaf':  [1,3,5,7,8,10]\n",
    "                              }\n",
    "}\n",
    "\n",
    "# Lancer la grid search\n",
    "df_best, dic_best, d_res =grid_search_global('clas',models,params,class_names=columns_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pipeline setup\n",
    "models = { \n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params = {\n",
    "    # Il faut mettre 'ExtraTreesClassifier__n_estimators' dans 'ExtraTreesClassifier' car on est sur un pipeline \n",
    "    # il est donc possible de préciser des parametres pour chacune des étapes\n",
    "    'AdaBoostClassifier': { 'n_estimators': [5, 10, 20, 30, 40, 50 ,100, 500 ],\n",
    "                               'learning_rate' : [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                              }\n",
    "}\n",
    "\n",
    "# Lancer la grid search\n",
    "df_best, dic_best, d_res =grid_search_global('clas',models,params,class_names=columns_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Gridsearch\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Gridsearch for [{'kernel': ['poly'], 'C': [0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1], 'gamma': [0.08, 0.09, 0.1, 0.11, 0.12], 'degree': [2, 3]}] \n",
      "\n",
      "Best score : 0.841292134831\n",
      "Best params : {'C': 0.3, 'degree': 3, 'gamma': 0.09, 'kernel': 'poly'}\n",
      "\n",
      "Classification report on training set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.91      0.88       436\n",
      "          1       0.84      0.75      0.79       276\n",
      "\n",
      "avg / total       0.84      0.85      0.84       712\n",
      "\n",
      "\n",
      "Classification report on testing set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.86      0.84      0.85       113\n",
      "          1       0.74      0.76      0.75        66\n",
      "\n",
      "avg / total       0.81      0.81      0.81       179\n",
      "\n",
      "\n",
      "Grid Score #cv_results_ alégé\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>0.845854</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>{'C': 0.7, 'degree': 2, 'gamma': 0.12, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.023879</td>\n",
       "      <td>0.847963</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>{'C': 0.6, 'degree': 3, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>0.846207</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>{'C': 0.5, 'degree': 3, 'gamma': 0.08, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>0.846205</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>{'C': 0.9, 'degree': 2, 'gamma': 0.11, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>0.847260</td>\n",
       "      <td>0.006503</td>\n",
       "      <td>{'C': 0.7, 'degree': 3, 'gamma': 0.08, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>0.846909</td>\n",
       "      <td>0.005838</td>\n",
       "      <td>{'C': 0.4, 'degree': 3, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>0.844801</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>{'C': 0.4, 'degree': 3, 'gamma': 0.08, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>0.845854</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>{'C': 1, 'degree': 2, 'gamma': 0.1, 'kernel': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>0.846906</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>{'C': 1, 'degree': 2, 'gamma': 0.11, 'kernel':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>0.846909</td>\n",
       "      <td>0.005838</td>\n",
       "      <td>{'C': 0.6, 'degree': 3, 'gamma': 0.08, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>0.847260</td>\n",
       "      <td>0.006503</td>\n",
       "      <td>{'C': 0.5, 'degree': 3, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>0.846909</td>\n",
       "      <td>0.005838</td>\n",
       "      <td>{'C': 0.3, 'degree': 3, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>0.845153</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>{'C': 0.3, 'degree': 3, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>0.845854</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>{'C': 0.8, 'degree': 2, 'gamma': 0.11, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>0.846205</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>{'C': 0.8, 'degree': 2, 'gamma': 0.12, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.023404</td>\n",
       "      <td>0.845854</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>{'C': 0.9, 'degree': 2, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.022543</td>\n",
       "      <td>0.848664</td>\n",
       "      <td>0.007662</td>\n",
       "      <td>{'C': 0.7, 'degree': 3, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.022543</td>\n",
       "      <td>0.849718</td>\n",
       "      <td>0.008790</td>\n",
       "      <td>{'C': 0.5, 'degree': 3, 'gamma': 0.11, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.023693</td>\n",
       "      <td>0.844449</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>{'C': 0.7, 'degree': 2, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.022543</td>\n",
       "      <td>0.851122</td>\n",
       "      <td>0.009069</td>\n",
       "      <td>{'C': 0.7, 'degree': 3, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.022543</td>\n",
       "      <td>0.849367</td>\n",
       "      <td>0.008191</td>\n",
       "      <td>{'C': 0.6, 'degree': 3, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.023693</td>\n",
       "      <td>0.844800</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>{'C': 0.9, 'degree': 2, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.022543</td>\n",
       "      <td>0.849367</td>\n",
       "      <td>0.007806</td>\n",
       "      <td>{'C': 0.8, 'degree': 3, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.023693</td>\n",
       "      <td>0.844800</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>{'C': 0.6, 'degree': 2, 'gamma': 0.11, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.023404</td>\n",
       "      <td>0.845854</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>{'C': 0.6, 'degree': 2, 'gamma': 0.12, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.022543</td>\n",
       "      <td>0.848664</td>\n",
       "      <td>0.007662</td>\n",
       "      <td>{'C': 0.5, 'degree': 3, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.026571</td>\n",
       "      <td>0.847963</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>{'C': 0.8, 'degree': 3, 'gamma': 0.08, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.022543</td>\n",
       "      <td>0.840940</td>\n",
       "      <td>0.006155</td>\n",
       "      <td>{'C': 0.3, 'degree': 2, 'gamma': 0.08, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.023693</td>\n",
       "      <td>0.844800</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>{'C': 0.5, 'degree': 2, 'gamma': 0.12, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.022543</td>\n",
       "      <td>0.849718</td>\n",
       "      <td>0.008790</td>\n",
       "      <td>{'C': 0.9, 'degree': 3, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.022257</td>\n",
       "      <td>0.841291</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>{'C': 0.3, 'degree': 2, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.021949</td>\n",
       "      <td>0.841291</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>{'C': 0.4, 'degree': 2, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.026069</td>\n",
       "      <td>0.843045</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>{'C': 0.4, 'degree': 2, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.026069</td>\n",
       "      <td>0.843396</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>{'C': 0.4, 'degree': 2, 'gamma': 0.11, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.026069</td>\n",
       "      <td>0.843396</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>{'C': 0.6, 'degree': 2, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.021949</td>\n",
       "      <td>0.841291</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>{'C': 0.5, 'degree': 2, 'gamma': 0.08, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.026069</td>\n",
       "      <td>0.843045</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>{'C': 0.5, 'degree': 2, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.842695</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>{'C': 0.6, 'degree': 2, 'gamma': 0.08, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.025745</td>\n",
       "      <td>0.845502</td>\n",
       "      <td>0.007360</td>\n",
       "      <td>{'C': 1, 'degree': 2, 'gamma': 0.09, 'kernel':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.025745</td>\n",
       "      <td>0.844098</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>{'C': 0.4, 'degree': 2, 'gamma': 0.12, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.025745</td>\n",
       "      <td>0.844098</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>{'C': 0.7, 'degree': 2, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.025745</td>\n",
       "      <td>0.844098</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>{'C': 0.5, 'degree': 2, 'gamma': 0.11, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.021564</td>\n",
       "      <td>0.852876</td>\n",
       "      <td>0.010591</td>\n",
       "      <td>{'C': 0.6, 'degree': 3, 'gamma': 0.11, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.025745</td>\n",
       "      <td>0.844098</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>{'C': 0.6, 'degree': 2, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.025745</td>\n",
       "      <td>0.843396</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>{'C': 0.8, 'degree': 2, 'gamma': 0.08, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.025745</td>\n",
       "      <td>0.845502</td>\n",
       "      <td>0.007360</td>\n",
       "      <td>{'C': 0.8, 'degree': 2, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.021564</td>\n",
       "      <td>0.852876</td>\n",
       "      <td>0.010591</td>\n",
       "      <td>{'C': 0.8, 'degree': 3, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.025745</td>\n",
       "      <td>0.844098</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>{'C': 0.9, 'degree': 2, 'gamma': 0.08, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.834270</td>\n",
       "      <td>0.021255</td>\n",
       "      <td>0.853931</td>\n",
       "      <td>0.010027</td>\n",
       "      <td>{'C': 0.5, 'degree': 3, 'gamma': 0.12, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.834270</td>\n",
       "      <td>0.021255</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.009823</td>\n",
       "      <td>{'C': 0.9, 'degree': 3, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.021654</td>\n",
       "      <td>0.853582</td>\n",
       "      <td>0.009706</td>\n",
       "      <td>{'C': 0.7, 'degree': 3, 'gamma': 0.11, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.024104</td>\n",
       "      <td>0.854634</td>\n",
       "      <td>0.009641</td>\n",
       "      <td>{'C': 0.6, 'degree': 3, 'gamma': 0.12, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.024104</td>\n",
       "      <td>0.854283</td>\n",
       "      <td>0.009482</td>\n",
       "      <td>{'C': 1, 'degree': 3, 'gamma': 0.1, 'kernel': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.830056</td>\n",
       "      <td>0.024699</td>\n",
       "      <td>0.854986</td>\n",
       "      <td>0.009639</td>\n",
       "      <td>{'C': 0.8, 'degree': 3, 'gamma': 0.11, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.828652</td>\n",
       "      <td>0.025591</td>\n",
       "      <td>0.856042</td>\n",
       "      <td>0.009953</td>\n",
       "      <td>{'C': 0.9, 'degree': 3, 'gamma': 0.11, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.828652</td>\n",
       "      <td>0.025591</td>\n",
       "      <td>0.855691</td>\n",
       "      <td>0.009788</td>\n",
       "      <td>{'C': 0.7, 'degree': 3, 'gamma': 0.12, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.827247</td>\n",
       "      <td>0.027838</td>\n",
       "      <td>0.856392</td>\n",
       "      <td>0.009981</td>\n",
       "      <td>{'C': 1, 'degree': 3, 'gamma': 0.11, 'kernel':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.824438</td>\n",
       "      <td>0.031149</td>\n",
       "      <td>0.857796</td>\n",
       "      <td>0.008719</td>\n",
       "      <td>{'C': 0.9, 'degree': 3, 'gamma': 0.12, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.824438</td>\n",
       "      <td>0.029633</td>\n",
       "      <td>0.856743</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>{'C': 0.8, 'degree': 3, 'gamma': 0.12, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.824438</td>\n",
       "      <td>0.035316</td>\n",
       "      <td>0.859202</td>\n",
       "      <td>0.008654</td>\n",
       "      <td>{'C': 1, 'degree': 3, 'gamma': 0.12, 'kernel':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Algo  mean_test_score  std_test_score  mean_train_score  std_train_score  \\\n",
       "44  SVC         0.841292        0.024003          0.845854         0.007117   \n",
       "36  SVC         0.841292        0.023879          0.847963         0.006447   \n",
       "25  SVC         0.841292        0.027099          0.846207         0.006447   \n",
       "63  SVC         0.841292        0.024003          0.846205         0.007139   \n",
       "45  SVC         0.841292        0.027099          0.847260         0.006503   \n",
       "16  SVC         0.841292        0.027099          0.846909         0.005838   \n",
       "15  SVC         0.841292        0.027099          0.844801         0.006942   \n",
       "72  SVC         0.841292        0.024003          0.845854         0.007117   \n",
       "73  SVC         0.841292        0.024003          0.846906         0.006688   \n",
       "35  SVC         0.841292        0.027099          0.846909         0.005838   \n",
       "26  SVC         0.841292        0.027099          0.847260         0.006503   \n",
       "7   SVC         0.841292        0.027099          0.846909         0.005838   \n",
       "6   SVC         0.841292        0.027099          0.845153         0.006812   \n",
       "53  SVC         0.841292        0.024003          0.845854         0.007117   \n",
       "54  SVC         0.841292        0.024003          0.846205         0.007139   \n",
       "62  SVC         0.839888        0.023404          0.845854         0.007117   \n",
       "46  SVC         0.839888        0.022543          0.848664         0.007662   \n",
       "28  SVC         0.839888        0.022543          0.849718         0.008790   \n",
       "42  SVC         0.839888        0.023693          0.844449         0.006877   \n",
       "47  SVC         0.839888        0.022543          0.851122         0.009069   \n",
       "37  SVC         0.839888        0.022543          0.849367         0.008191   \n",
       "61  SVC         0.839888        0.023693          0.844800         0.006701   \n",
       "56  SVC         0.839888        0.022543          0.849367         0.007806   \n",
       "33  SVC         0.839888        0.023693          0.844800         0.006701   \n",
       "34  SVC         0.839888        0.023404          0.845854         0.007117   \n",
       "27  SVC         0.839888        0.022543          0.848664         0.007662   \n",
       "55  SVC         0.839888        0.026571          0.847963         0.006447   \n",
       "0   SVC         0.839888        0.022543          0.840940         0.006155   \n",
       "24  SVC         0.839888        0.023693          0.844800         0.006701   \n",
       "66  SVC         0.839888        0.022543          0.849718         0.008790   \n",
       "..  ...              ...             ...               ...              ...   \n",
       "1   SVC         0.838483        0.022257          0.841291         0.005854   \n",
       "11  SVC         0.838483        0.021949          0.841291         0.005854   \n",
       "12  SVC         0.838483        0.026069          0.843045         0.007538   \n",
       "13  SVC         0.838483        0.026069          0.843396         0.007277   \n",
       "31  SVC         0.838483        0.026069          0.843396         0.007277   \n",
       "20  SVC         0.838483        0.021949          0.841291         0.005854   \n",
       "21  SVC         0.838483        0.026069          0.843045         0.007538   \n",
       "30  SVC         0.837079        0.024691          0.842695         0.007695   \n",
       "71  SVC         0.837079        0.025745          0.845502         0.007360   \n",
       "14  SVC         0.837079        0.025745          0.844098         0.007117   \n",
       "41  SVC         0.837079        0.025745          0.844098         0.007117   \n",
       "23  SVC         0.837079        0.025745          0.844098         0.007117   \n",
       "38  SVC         0.837079        0.021564          0.852876         0.010591   \n",
       "32  SVC         0.837079        0.025745          0.844098         0.007117   \n",
       "50  SVC         0.837079        0.025745          0.843396         0.007277   \n",
       "52  SVC         0.837079        0.025745          0.845502         0.007360   \n",
       "57  SVC         0.837079        0.021564          0.852876         0.010591   \n",
       "60  SVC         0.837079        0.025745          0.844098         0.007117   \n",
       "29  SVC         0.834270        0.021255          0.853931         0.010027   \n",
       "67  SVC         0.834270        0.021255          0.853933         0.009823   \n",
       "48  SVC         0.832865        0.021654          0.853582         0.009706   \n",
       "39  SVC         0.831461        0.024104          0.854634         0.009641   \n",
       "77  SVC         0.831461        0.024104          0.854283         0.009482   \n",
       "58  SVC         0.830056        0.024699          0.854986         0.009639   \n",
       "68  SVC         0.828652        0.025591          0.856042         0.009953   \n",
       "49  SVC         0.828652        0.025591          0.855691         0.009788   \n",
       "78  SVC         0.827247        0.027838          0.856392         0.009981   \n",
       "69  SVC         0.824438        0.031149          0.857796         0.008719   \n",
       "59  SVC         0.824438        0.029633          0.856743         0.010120   \n",
       "79  SVC         0.824438        0.035316          0.859202         0.008654   \n",
       "\n",
       "                                               params  \n",
       "44  {'C': 0.7, 'degree': 2, 'gamma': 0.12, 'kernel...  \n",
       "36  {'C': 0.6, 'degree': 3, 'gamma': 0.09, 'kernel...  \n",
       "25  {'C': 0.5, 'degree': 3, 'gamma': 0.08, 'kernel...  \n",
       "63  {'C': 0.9, 'degree': 2, 'gamma': 0.11, 'kernel...  \n",
       "45  {'C': 0.7, 'degree': 3, 'gamma': 0.08, 'kernel...  \n",
       "16  {'C': 0.4, 'degree': 3, 'gamma': 0.09, 'kernel...  \n",
       "15  {'C': 0.4, 'degree': 3, 'gamma': 0.08, 'kernel...  \n",
       "72  {'C': 1, 'degree': 2, 'gamma': 0.1, 'kernel': ...  \n",
       "73  {'C': 1, 'degree': 2, 'gamma': 0.11, 'kernel':...  \n",
       "35  {'C': 0.6, 'degree': 3, 'gamma': 0.08, 'kernel...  \n",
       "26  {'C': 0.5, 'degree': 3, 'gamma': 0.09, 'kernel...  \n",
       "7   {'C': 0.3, 'degree': 3, 'gamma': 0.1, 'kernel'...  \n",
       "6   {'C': 0.3, 'degree': 3, 'gamma': 0.09, 'kernel...  \n",
       "53  {'C': 0.8, 'degree': 2, 'gamma': 0.11, 'kernel...  \n",
       "54  {'C': 0.8, 'degree': 2, 'gamma': 0.12, 'kernel...  \n",
       "62  {'C': 0.9, 'degree': 2, 'gamma': 0.1, 'kernel'...  \n",
       "46  {'C': 0.7, 'degree': 3, 'gamma': 0.09, 'kernel...  \n",
       "28  {'C': 0.5, 'degree': 3, 'gamma': 0.11, 'kernel...  \n",
       "42  {'C': 0.7, 'degree': 2, 'gamma': 0.1, 'kernel'...  \n",
       "47  {'C': 0.7, 'degree': 3, 'gamma': 0.1, 'kernel'...  \n",
       "37  {'C': 0.6, 'degree': 3, 'gamma': 0.1, 'kernel'...  \n",
       "61  {'C': 0.9, 'degree': 2, 'gamma': 0.09, 'kernel...  \n",
       "56  {'C': 0.8, 'degree': 3, 'gamma': 0.09, 'kernel...  \n",
       "33  {'C': 0.6, 'degree': 2, 'gamma': 0.11, 'kernel...  \n",
       "34  {'C': 0.6, 'degree': 2, 'gamma': 0.12, 'kernel...  \n",
       "27  {'C': 0.5, 'degree': 3, 'gamma': 0.1, 'kernel'...  \n",
       "55  {'C': 0.8, 'degree': 3, 'gamma': 0.08, 'kernel...  \n",
       "0   {'C': 0.3, 'degree': 2, 'gamma': 0.08, 'kernel...  \n",
       "24  {'C': 0.5, 'degree': 2, 'gamma': 0.12, 'kernel...  \n",
       "66  {'C': 0.9, 'degree': 3, 'gamma': 0.09, 'kernel...  \n",
       "..                                                ...  \n",
       "1   {'C': 0.3, 'degree': 2, 'gamma': 0.09, 'kernel...  \n",
       "11  {'C': 0.4, 'degree': 2, 'gamma': 0.09, 'kernel...  \n",
       "12  {'C': 0.4, 'degree': 2, 'gamma': 0.1, 'kernel'...  \n",
       "13  {'C': 0.4, 'degree': 2, 'gamma': 0.11, 'kernel...  \n",
       "31  {'C': 0.6, 'degree': 2, 'gamma': 0.09, 'kernel...  \n",
       "20  {'C': 0.5, 'degree': 2, 'gamma': 0.08, 'kernel...  \n",
       "21  {'C': 0.5, 'degree': 2, 'gamma': 0.09, 'kernel...  \n",
       "30  {'C': 0.6, 'degree': 2, 'gamma': 0.08, 'kernel...  \n",
       "71  {'C': 1, 'degree': 2, 'gamma': 0.09, 'kernel':...  \n",
       "14  {'C': 0.4, 'degree': 2, 'gamma': 0.12, 'kernel...  \n",
       "41  {'C': 0.7, 'degree': 2, 'gamma': 0.09, 'kernel...  \n",
       "23  {'C': 0.5, 'degree': 2, 'gamma': 0.11, 'kernel...  \n",
       "38  {'C': 0.6, 'degree': 3, 'gamma': 0.11, 'kernel...  \n",
       "32  {'C': 0.6, 'degree': 2, 'gamma': 0.1, 'kernel'...  \n",
       "50  {'C': 0.8, 'degree': 2, 'gamma': 0.08, 'kernel...  \n",
       "52  {'C': 0.8, 'degree': 2, 'gamma': 0.1, 'kernel'...  \n",
       "57  {'C': 0.8, 'degree': 3, 'gamma': 0.1, 'kernel'...  \n",
       "60  {'C': 0.9, 'degree': 2, 'gamma': 0.08, 'kernel...  \n",
       "29  {'C': 0.5, 'degree': 3, 'gamma': 0.12, 'kernel...  \n",
       "67  {'C': 0.9, 'degree': 3, 'gamma': 0.1, 'kernel'...  \n",
       "48  {'C': 0.7, 'degree': 3, 'gamma': 0.11, 'kernel...  \n",
       "39  {'C': 0.6, 'degree': 3, 'gamma': 0.12, 'kernel...  \n",
       "77  {'C': 1, 'degree': 3, 'gamma': 0.1, 'kernel': ...  \n",
       "58  {'C': 0.8, 'degree': 3, 'gamma': 0.11, 'kernel...  \n",
       "68  {'C': 0.9, 'degree': 3, 'gamma': 0.11, 'kernel...  \n",
       "49  {'C': 0.7, 'degree': 3, 'gamma': 0.12, 'kernel...  \n",
       "78  {'C': 1, 'degree': 3, 'gamma': 0.11, 'kernel':...  \n",
       "69  {'C': 0.9, 'degree': 3, 'gamma': 0.12, 'kernel...  \n",
       "59  {'C': 0.8, 'degree': 3, 'gamma': 0.12, 'kernel...  \n",
       "79  {'C': 1, 'degree': 3, 'gamma': 0.12, 'kernel':...  \n",
       "\n",
       "[80 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------------------------------------------------------\n",
      "\n",
      "List of best score and parameters by pipeline\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scores</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <td>0.841292</td>\n",
       "      <td>{'C': 0.3, 'degree': 3, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Scores                                         Parameters\n",
       "SVC  0.841292  {'C': 0.3, 'degree': 3, 'gamma': 0.09, 'kernel..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>0.845854</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>{'C': 0.7, 'degree': 2, 'gamma': 0.12, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.023879</td>\n",
       "      <td>0.847963</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>{'C': 0.6, 'degree': 3, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>0.846207</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>{'C': 0.5, 'degree': 3, 'gamma': 0.08, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>0.846205</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>{'C': 0.9, 'degree': 2, 'gamma': 0.11, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>0.847260</td>\n",
       "      <td>0.006503</td>\n",
       "      <td>{'C': 0.7, 'degree': 3, 'gamma': 0.08, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>0.846909</td>\n",
       "      <td>0.005838</td>\n",
       "      <td>{'C': 0.4, 'degree': 3, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>0.844801</td>\n",
       "      <td>0.006942</td>\n",
       "      <td>{'C': 0.4, 'degree': 3, 'gamma': 0.08, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>0.845854</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>{'C': 1, 'degree': 2, 'gamma': 0.1, 'kernel': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>0.846906</td>\n",
       "      <td>0.006688</td>\n",
       "      <td>{'C': 1, 'degree': 2, 'gamma': 0.11, 'kernel':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>0.846909</td>\n",
       "      <td>0.005838</td>\n",
       "      <td>{'C': 0.6, 'degree': 3, 'gamma': 0.08, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>0.847260</td>\n",
       "      <td>0.006503</td>\n",
       "      <td>{'C': 0.5, 'degree': 3, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>0.846909</td>\n",
       "      <td>0.005838</td>\n",
       "      <td>{'C': 0.3, 'degree': 3, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.027099</td>\n",
       "      <td>0.845153</td>\n",
       "      <td>0.006812</td>\n",
       "      <td>{'C': 0.3, 'degree': 3, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>0.845854</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>{'C': 0.8, 'degree': 2, 'gamma': 0.11, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.024003</td>\n",
       "      <td>0.846205</td>\n",
       "      <td>0.007139</td>\n",
       "      <td>{'C': 0.8, 'degree': 2, 'gamma': 0.12, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.023404</td>\n",
       "      <td>0.845854</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>{'C': 0.9, 'degree': 2, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.022543</td>\n",
       "      <td>0.848664</td>\n",
       "      <td>0.007662</td>\n",
       "      <td>{'C': 0.7, 'degree': 3, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.022543</td>\n",
       "      <td>0.849718</td>\n",
       "      <td>0.008790</td>\n",
       "      <td>{'C': 0.5, 'degree': 3, 'gamma': 0.11, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.023693</td>\n",
       "      <td>0.844449</td>\n",
       "      <td>0.006877</td>\n",
       "      <td>{'C': 0.7, 'degree': 2, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.022543</td>\n",
       "      <td>0.851122</td>\n",
       "      <td>0.009069</td>\n",
       "      <td>{'C': 0.7, 'degree': 3, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.022543</td>\n",
       "      <td>0.849367</td>\n",
       "      <td>0.008191</td>\n",
       "      <td>{'C': 0.6, 'degree': 3, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.023693</td>\n",
       "      <td>0.844800</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>{'C': 0.9, 'degree': 2, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.022543</td>\n",
       "      <td>0.849367</td>\n",
       "      <td>0.007806</td>\n",
       "      <td>{'C': 0.8, 'degree': 3, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.023693</td>\n",
       "      <td>0.844800</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>{'C': 0.6, 'degree': 2, 'gamma': 0.11, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.023404</td>\n",
       "      <td>0.845854</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>{'C': 0.6, 'degree': 2, 'gamma': 0.12, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.022543</td>\n",
       "      <td>0.848664</td>\n",
       "      <td>0.007662</td>\n",
       "      <td>{'C': 0.5, 'degree': 3, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.026571</td>\n",
       "      <td>0.847963</td>\n",
       "      <td>0.006447</td>\n",
       "      <td>{'C': 0.8, 'degree': 3, 'gamma': 0.08, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.022543</td>\n",
       "      <td>0.840940</td>\n",
       "      <td>0.006155</td>\n",
       "      <td>{'C': 0.3, 'degree': 2, 'gamma': 0.08, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.023693</td>\n",
       "      <td>0.844800</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>{'C': 0.5, 'degree': 2, 'gamma': 0.12, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.022543</td>\n",
       "      <td>0.849718</td>\n",
       "      <td>0.008790</td>\n",
       "      <td>{'C': 0.9, 'degree': 3, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.022257</td>\n",
       "      <td>0.841291</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>{'C': 0.3, 'degree': 2, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.021949</td>\n",
       "      <td>0.841291</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>{'C': 0.4, 'degree': 2, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.026069</td>\n",
       "      <td>0.843045</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>{'C': 0.4, 'degree': 2, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.026069</td>\n",
       "      <td>0.843396</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>{'C': 0.4, 'degree': 2, 'gamma': 0.11, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.026069</td>\n",
       "      <td>0.843396</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>{'C': 0.6, 'degree': 2, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.021949</td>\n",
       "      <td>0.841291</td>\n",
       "      <td>0.005854</td>\n",
       "      <td>{'C': 0.5, 'degree': 2, 'gamma': 0.08, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.026069</td>\n",
       "      <td>0.843045</td>\n",
       "      <td>0.007538</td>\n",
       "      <td>{'C': 0.5, 'degree': 2, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.024691</td>\n",
       "      <td>0.842695</td>\n",
       "      <td>0.007695</td>\n",
       "      <td>{'C': 0.6, 'degree': 2, 'gamma': 0.08, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.025745</td>\n",
       "      <td>0.845502</td>\n",
       "      <td>0.007360</td>\n",
       "      <td>{'C': 1, 'degree': 2, 'gamma': 0.09, 'kernel':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.025745</td>\n",
       "      <td>0.844098</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>{'C': 0.4, 'degree': 2, 'gamma': 0.12, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.025745</td>\n",
       "      <td>0.844098</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>{'C': 0.7, 'degree': 2, 'gamma': 0.09, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.025745</td>\n",
       "      <td>0.844098</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>{'C': 0.5, 'degree': 2, 'gamma': 0.11, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.021564</td>\n",
       "      <td>0.852876</td>\n",
       "      <td>0.010591</td>\n",
       "      <td>{'C': 0.6, 'degree': 3, 'gamma': 0.11, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.025745</td>\n",
       "      <td>0.844098</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>{'C': 0.6, 'degree': 2, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.025745</td>\n",
       "      <td>0.843396</td>\n",
       "      <td>0.007277</td>\n",
       "      <td>{'C': 0.8, 'degree': 2, 'gamma': 0.08, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.025745</td>\n",
       "      <td>0.845502</td>\n",
       "      <td>0.007360</td>\n",
       "      <td>{'C': 0.8, 'degree': 2, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.021564</td>\n",
       "      <td>0.852876</td>\n",
       "      <td>0.010591</td>\n",
       "      <td>{'C': 0.8, 'degree': 3, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.837079</td>\n",
       "      <td>0.025745</td>\n",
       "      <td>0.844098</td>\n",
       "      <td>0.007117</td>\n",
       "      <td>{'C': 0.9, 'degree': 2, 'gamma': 0.08, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.834270</td>\n",
       "      <td>0.021255</td>\n",
       "      <td>0.853931</td>\n",
       "      <td>0.010027</td>\n",
       "      <td>{'C': 0.5, 'degree': 3, 'gamma': 0.12, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.834270</td>\n",
       "      <td>0.021255</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.009823</td>\n",
       "      <td>{'C': 0.9, 'degree': 3, 'gamma': 0.1, 'kernel'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.021654</td>\n",
       "      <td>0.853582</td>\n",
       "      <td>0.009706</td>\n",
       "      <td>{'C': 0.7, 'degree': 3, 'gamma': 0.11, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.024104</td>\n",
       "      <td>0.854634</td>\n",
       "      <td>0.009641</td>\n",
       "      <td>{'C': 0.6, 'degree': 3, 'gamma': 0.12, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.024104</td>\n",
       "      <td>0.854283</td>\n",
       "      <td>0.009482</td>\n",
       "      <td>{'C': 1, 'degree': 3, 'gamma': 0.1, 'kernel': ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.830056</td>\n",
       "      <td>0.024699</td>\n",
       "      <td>0.854986</td>\n",
       "      <td>0.009639</td>\n",
       "      <td>{'C': 0.8, 'degree': 3, 'gamma': 0.11, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.828652</td>\n",
       "      <td>0.025591</td>\n",
       "      <td>0.856042</td>\n",
       "      <td>0.009953</td>\n",
       "      <td>{'C': 0.9, 'degree': 3, 'gamma': 0.11, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.828652</td>\n",
       "      <td>0.025591</td>\n",
       "      <td>0.855691</td>\n",
       "      <td>0.009788</td>\n",
       "      <td>{'C': 0.7, 'degree': 3, 'gamma': 0.12, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.827247</td>\n",
       "      <td>0.027838</td>\n",
       "      <td>0.856392</td>\n",
       "      <td>0.009981</td>\n",
       "      <td>{'C': 1, 'degree': 3, 'gamma': 0.11, 'kernel':...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.824438</td>\n",
       "      <td>0.031149</td>\n",
       "      <td>0.857796</td>\n",
       "      <td>0.008719</td>\n",
       "      <td>{'C': 0.9, 'degree': 3, 'gamma': 0.12, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.824438</td>\n",
       "      <td>0.029633</td>\n",
       "      <td>0.856743</td>\n",
       "      <td>0.010120</td>\n",
       "      <td>{'C': 0.8, 'degree': 3, 'gamma': 0.12, 'kernel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>SVC</td>\n",
       "      <td>0.824438</td>\n",
       "      <td>0.035316</td>\n",
       "      <td>0.859202</td>\n",
       "      <td>0.008654</td>\n",
       "      <td>{'C': 1, 'degree': 3, 'gamma': 0.12, 'kernel':...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Algo  mean_test_score  std_test_score  mean_train_score  std_train_score  \\\n",
       "44  SVC         0.841292        0.024003          0.845854         0.007117   \n",
       "36  SVC         0.841292        0.023879          0.847963         0.006447   \n",
       "25  SVC         0.841292        0.027099          0.846207         0.006447   \n",
       "63  SVC         0.841292        0.024003          0.846205         0.007139   \n",
       "45  SVC         0.841292        0.027099          0.847260         0.006503   \n",
       "16  SVC         0.841292        0.027099          0.846909         0.005838   \n",
       "15  SVC         0.841292        0.027099          0.844801         0.006942   \n",
       "72  SVC         0.841292        0.024003          0.845854         0.007117   \n",
       "73  SVC         0.841292        0.024003          0.846906         0.006688   \n",
       "35  SVC         0.841292        0.027099          0.846909         0.005838   \n",
       "26  SVC         0.841292        0.027099          0.847260         0.006503   \n",
       "7   SVC         0.841292        0.027099          0.846909         0.005838   \n",
       "6   SVC         0.841292        0.027099          0.845153         0.006812   \n",
       "53  SVC         0.841292        0.024003          0.845854         0.007117   \n",
       "54  SVC         0.841292        0.024003          0.846205         0.007139   \n",
       "62  SVC         0.839888        0.023404          0.845854         0.007117   \n",
       "46  SVC         0.839888        0.022543          0.848664         0.007662   \n",
       "28  SVC         0.839888        0.022543          0.849718         0.008790   \n",
       "42  SVC         0.839888        0.023693          0.844449         0.006877   \n",
       "47  SVC         0.839888        0.022543          0.851122         0.009069   \n",
       "37  SVC         0.839888        0.022543          0.849367         0.008191   \n",
       "61  SVC         0.839888        0.023693          0.844800         0.006701   \n",
       "56  SVC         0.839888        0.022543          0.849367         0.007806   \n",
       "33  SVC         0.839888        0.023693          0.844800         0.006701   \n",
       "34  SVC         0.839888        0.023404          0.845854         0.007117   \n",
       "27  SVC         0.839888        0.022543          0.848664         0.007662   \n",
       "55  SVC         0.839888        0.026571          0.847963         0.006447   \n",
       "0   SVC         0.839888        0.022543          0.840940         0.006155   \n",
       "24  SVC         0.839888        0.023693          0.844800         0.006701   \n",
       "66  SVC         0.839888        0.022543          0.849718         0.008790   \n",
       "..  ...              ...             ...               ...              ...   \n",
       "1   SVC         0.838483        0.022257          0.841291         0.005854   \n",
       "11  SVC         0.838483        0.021949          0.841291         0.005854   \n",
       "12  SVC         0.838483        0.026069          0.843045         0.007538   \n",
       "13  SVC         0.838483        0.026069          0.843396         0.007277   \n",
       "31  SVC         0.838483        0.026069          0.843396         0.007277   \n",
       "20  SVC         0.838483        0.021949          0.841291         0.005854   \n",
       "21  SVC         0.838483        0.026069          0.843045         0.007538   \n",
       "30  SVC         0.837079        0.024691          0.842695         0.007695   \n",
       "71  SVC         0.837079        0.025745          0.845502         0.007360   \n",
       "14  SVC         0.837079        0.025745          0.844098         0.007117   \n",
       "41  SVC         0.837079        0.025745          0.844098         0.007117   \n",
       "23  SVC         0.837079        0.025745          0.844098         0.007117   \n",
       "38  SVC         0.837079        0.021564          0.852876         0.010591   \n",
       "32  SVC         0.837079        0.025745          0.844098         0.007117   \n",
       "50  SVC         0.837079        0.025745          0.843396         0.007277   \n",
       "52  SVC         0.837079        0.025745          0.845502         0.007360   \n",
       "57  SVC         0.837079        0.021564          0.852876         0.010591   \n",
       "60  SVC         0.837079        0.025745          0.844098         0.007117   \n",
       "29  SVC         0.834270        0.021255          0.853931         0.010027   \n",
       "67  SVC         0.834270        0.021255          0.853933         0.009823   \n",
       "48  SVC         0.832865        0.021654          0.853582         0.009706   \n",
       "39  SVC         0.831461        0.024104          0.854634         0.009641   \n",
       "77  SVC         0.831461        0.024104          0.854283         0.009482   \n",
       "58  SVC         0.830056        0.024699          0.854986         0.009639   \n",
       "68  SVC         0.828652        0.025591          0.856042         0.009953   \n",
       "49  SVC         0.828652        0.025591          0.855691         0.009788   \n",
       "78  SVC         0.827247        0.027838          0.856392         0.009981   \n",
       "69  SVC         0.824438        0.031149          0.857796         0.008719   \n",
       "59  SVC         0.824438        0.029633          0.856743         0.010120   \n",
       "79  SVC         0.824438        0.035316          0.859202         0.008654   \n",
       "\n",
       "                                               params  \n",
       "44  {'C': 0.7, 'degree': 2, 'gamma': 0.12, 'kernel...  \n",
       "36  {'C': 0.6, 'degree': 3, 'gamma': 0.09, 'kernel...  \n",
       "25  {'C': 0.5, 'degree': 3, 'gamma': 0.08, 'kernel...  \n",
       "63  {'C': 0.9, 'degree': 2, 'gamma': 0.11, 'kernel...  \n",
       "45  {'C': 0.7, 'degree': 3, 'gamma': 0.08, 'kernel...  \n",
       "16  {'C': 0.4, 'degree': 3, 'gamma': 0.09, 'kernel...  \n",
       "15  {'C': 0.4, 'degree': 3, 'gamma': 0.08, 'kernel...  \n",
       "72  {'C': 1, 'degree': 2, 'gamma': 0.1, 'kernel': ...  \n",
       "73  {'C': 1, 'degree': 2, 'gamma': 0.11, 'kernel':...  \n",
       "35  {'C': 0.6, 'degree': 3, 'gamma': 0.08, 'kernel...  \n",
       "26  {'C': 0.5, 'degree': 3, 'gamma': 0.09, 'kernel...  \n",
       "7   {'C': 0.3, 'degree': 3, 'gamma': 0.1, 'kernel'...  \n",
       "6   {'C': 0.3, 'degree': 3, 'gamma': 0.09, 'kernel...  \n",
       "53  {'C': 0.8, 'degree': 2, 'gamma': 0.11, 'kernel...  \n",
       "54  {'C': 0.8, 'degree': 2, 'gamma': 0.12, 'kernel...  \n",
       "62  {'C': 0.9, 'degree': 2, 'gamma': 0.1, 'kernel'...  \n",
       "46  {'C': 0.7, 'degree': 3, 'gamma': 0.09, 'kernel...  \n",
       "28  {'C': 0.5, 'degree': 3, 'gamma': 0.11, 'kernel...  \n",
       "42  {'C': 0.7, 'degree': 2, 'gamma': 0.1, 'kernel'...  \n",
       "47  {'C': 0.7, 'degree': 3, 'gamma': 0.1, 'kernel'...  \n",
       "37  {'C': 0.6, 'degree': 3, 'gamma': 0.1, 'kernel'...  \n",
       "61  {'C': 0.9, 'degree': 2, 'gamma': 0.09, 'kernel...  \n",
       "56  {'C': 0.8, 'degree': 3, 'gamma': 0.09, 'kernel...  \n",
       "33  {'C': 0.6, 'degree': 2, 'gamma': 0.11, 'kernel...  \n",
       "34  {'C': 0.6, 'degree': 2, 'gamma': 0.12, 'kernel...  \n",
       "27  {'C': 0.5, 'degree': 3, 'gamma': 0.1, 'kernel'...  \n",
       "55  {'C': 0.8, 'degree': 3, 'gamma': 0.08, 'kernel...  \n",
       "0   {'C': 0.3, 'degree': 2, 'gamma': 0.08, 'kernel...  \n",
       "24  {'C': 0.5, 'degree': 2, 'gamma': 0.12, 'kernel...  \n",
       "66  {'C': 0.9, 'degree': 3, 'gamma': 0.09, 'kernel...  \n",
       "..                                                ...  \n",
       "1   {'C': 0.3, 'degree': 2, 'gamma': 0.09, 'kernel...  \n",
       "11  {'C': 0.4, 'degree': 2, 'gamma': 0.09, 'kernel...  \n",
       "12  {'C': 0.4, 'degree': 2, 'gamma': 0.1, 'kernel'...  \n",
       "13  {'C': 0.4, 'degree': 2, 'gamma': 0.11, 'kernel...  \n",
       "31  {'C': 0.6, 'degree': 2, 'gamma': 0.09, 'kernel...  \n",
       "20  {'C': 0.5, 'degree': 2, 'gamma': 0.08, 'kernel...  \n",
       "21  {'C': 0.5, 'degree': 2, 'gamma': 0.09, 'kernel...  \n",
       "30  {'C': 0.6, 'degree': 2, 'gamma': 0.08, 'kernel...  \n",
       "71  {'C': 1, 'degree': 2, 'gamma': 0.09, 'kernel':...  \n",
       "14  {'C': 0.4, 'degree': 2, 'gamma': 0.12, 'kernel...  \n",
       "41  {'C': 0.7, 'degree': 2, 'gamma': 0.09, 'kernel...  \n",
       "23  {'C': 0.5, 'degree': 2, 'gamma': 0.11, 'kernel...  \n",
       "38  {'C': 0.6, 'degree': 3, 'gamma': 0.11, 'kernel...  \n",
       "32  {'C': 0.6, 'degree': 2, 'gamma': 0.1, 'kernel'...  \n",
       "50  {'C': 0.8, 'degree': 2, 'gamma': 0.08, 'kernel...  \n",
       "52  {'C': 0.8, 'degree': 2, 'gamma': 0.1, 'kernel'...  \n",
       "57  {'C': 0.8, 'degree': 3, 'gamma': 0.1, 'kernel'...  \n",
       "60  {'C': 0.9, 'degree': 2, 'gamma': 0.08, 'kernel...  \n",
       "29  {'C': 0.5, 'degree': 3, 'gamma': 0.12, 'kernel...  \n",
       "67  {'C': 0.9, 'degree': 3, 'gamma': 0.1, 'kernel'...  \n",
       "48  {'C': 0.7, 'degree': 3, 'gamma': 0.11, 'kernel...  \n",
       "39  {'C': 0.6, 'degree': 3, 'gamma': 0.12, 'kernel...  \n",
       "77  {'C': 1, 'degree': 3, 'gamma': 0.1, 'kernel': ...  \n",
       "58  {'C': 0.8, 'degree': 3, 'gamma': 0.11, 'kernel...  \n",
       "68  {'C': 0.9, 'degree': 3, 'gamma': 0.11, 'kernel...  \n",
       "49  {'C': 0.7, 'degree': 3, 'gamma': 0.12, 'kernel...  \n",
       "78  {'C': 1, 'degree': 3, 'gamma': 0.11, 'kernel':...  \n",
       "69  {'C': 0.9, 'degree': 3, 'gamma': 0.12, 'kernel...  \n",
       "59  {'C': 0.8, 'degree': 3, 'gamma': 0.12, 'kernel...  \n",
       "79  {'C': 1, 'degree': 3, 'gamma': 0.12, 'kernel':...  \n",
       "\n",
       "[80 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gridsearch Finished\n",
      "\n",
      " -------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Pipeline setup\n",
    "models = { \n",
    "    'SVC': SVC()\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params = {\n",
    "    'SVC': [\n",
    "        {'kernel': ['poly'], 'C': [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], \n",
    "                            'gamma': [0.08,0.09,0.1,0.11,0.12],\n",
    "                            'degree': [2,3]}]}\n",
    "\n",
    "# Lancer la grid search\n",
    "df_best_svc , dic_best_svc, d_res_svc = grid_search_global('clas',models,params,class_names=columns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "svc_params = {'C': 0.3, 'degree': 3, 'gamma': 0.09, 'kernel': 'poly'}\n",
    "svc = SVC(**svc_params)\n",
    "svc.fit(data,target)\n",
    "svc_pred = svc.predict(test_data)\n",
    "Prediction['SVC'] = svc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(svc_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Gridsearch\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jules/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/jules/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/jules/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/jules/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/jules/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/jules/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/jules/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/jules/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Gridsearch for {'C': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.8, 0.9, 1], 'penalty': ['l2'], 'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag'], 'max_iter': [100, 250, 500], 'tol': [0.0001, 0.0003, 0.0007, 0.001, 0.003]} \n",
      "\n",
      "Best score : 0.835674157303\n",
      "Best params : {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001}\n",
      "\n",
      "Classification report on training set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.89      0.87       447\n",
      "          1       0.80      0.74      0.77       265\n",
      "\n",
      "avg / total       0.83      0.83      0.83       712\n",
      "\n",
      "\n",
      "Classification report on testing set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.83      0.82       102\n",
      "          1       0.77      0.74      0.75        77\n",
      "\n",
      "avg / total       0.79      0.79      0.79       179\n",
      "\n",
      "\n",
      "Grid Score #cv_results_ alégé\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838484</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838484</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838484</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838484</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838484</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838484</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838484</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.037728</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>{'C': 0.3, 'max_iter': 100, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.037728</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>{'C': 0.3, 'max_iter': 100, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.035885</td>\n",
       "      <td>0.830055</td>\n",
       "      <td>0.007756</td>\n",
       "      <td>{'C': 0.1, 'max_iter': 100, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Algo  mean_test_score  std_test_score  mean_train_score  std_train_score  \\\n",
       "482   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "494   lr         0.835674        0.038374          0.838484         0.008868   \n",
       "509   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "508   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "507   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "505   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "504   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "503   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "502   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "501   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "500   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "497   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "496   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "495   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "493   lr         0.835674        0.038374          0.838484         0.008868   \n",
       "511   lr         0.835674        0.038374          0.838484         0.008868   \n",
       "492   lr         0.835674        0.038374          0.838484         0.008868   \n",
       "491   lr         0.835674        0.038374          0.838484         0.008868   \n",
       "490   lr         0.835674        0.038374          0.838484         0.008868   \n",
       "489   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "488   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "487   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "486   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "485   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "484   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "483   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "481   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "480   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "510   lr         0.835674        0.038374          0.838484         0.008868   \n",
       "506   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "..   ...              ...             ...               ...              ...   \n",
       "93    lr         0.831461        0.039556          0.832865         0.009568   \n",
       "92    lr         0.831461        0.039556          0.832865         0.009568   \n",
       "91    lr         0.831461        0.039556          0.832865         0.009568   \n",
       "90    lr         0.831461        0.039556          0.832865         0.009568   \n",
       "89    lr         0.831461        0.039556          0.832865         0.009568   \n",
       "88    lr         0.831461        0.039556          0.832865         0.009568   \n",
       "87    lr         0.831461        0.039556          0.832865         0.009568   \n",
       "86    lr         0.831461        0.039556          0.832865         0.009568   \n",
       "85    lr         0.831461        0.039556          0.832865         0.009568   \n",
       "102   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "103   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "104   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "114   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "121   lr         0.831461        0.037728          0.835674         0.009455   \n",
       "120   lr         0.831461        0.037728          0.835674         0.009455   \n",
       "119   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "118   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "117   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "116   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "115   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "113   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "105   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "112   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "111   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "110   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "109   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "108   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "107   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "106   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "0     lr         0.831461        0.035885          0.830055         0.007756   \n",
       "\n",
       "                                                params  \n",
       "482  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "494  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "509  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "508  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "507  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "505  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "504  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "503  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "502  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "501  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "500  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "497  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "496  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "495  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "493  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "511  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "492  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "491  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "490  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "489  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "488  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "487  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "486  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "485  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "484  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "483  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "481  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "480  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "510  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "506  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "..                                                 ...  \n",
       "93   {'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...  \n",
       "92   {'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...  \n",
       "91   {'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...  \n",
       "90   {'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...  \n",
       "89   {'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...  \n",
       "88   {'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...  \n",
       "87   {'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...  \n",
       "86   {'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...  \n",
       "85   {'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...  \n",
       "102  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "103  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "104  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "114  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "121  {'C': 0.3, 'max_iter': 100, 'penalty': 'l2', '...  \n",
       "120  {'C': 0.3, 'max_iter': 100, 'penalty': 'l2', '...  \n",
       "119  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "118  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "117  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "116  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "115  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "113  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "105  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "112  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "111  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "110  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "109  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "108  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "107  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "106  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "0    {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', '...  \n",
       "\n",
       "[540 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------------------------------------------------------\n",
      "\n",
      "List of best score and parameters by pipeline\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scores</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>0.835674</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Scores                                         Parameters\n",
       "lr  0.835674  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838484</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838484</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838484</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838484</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838484</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838484</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838484</td>\n",
       "      <td>0.008868</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.038374</td>\n",
       "      <td>0.838132</td>\n",
       "      <td>0.008692</td>\n",
       "      <td>{'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.037728</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>{'C': 0.3, 'max_iter': 100, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.037728</td>\n",
       "      <td>0.835674</td>\n",
       "      <td>0.009455</td>\n",
       "      <td>{'C': 0.3, 'max_iter': 100, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.039556</td>\n",
       "      <td>0.832865</td>\n",
       "      <td>0.009568</td>\n",
       "      <td>{'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lr</td>\n",
       "      <td>0.831461</td>\n",
       "      <td>0.035885</td>\n",
       "      <td>0.830055</td>\n",
       "      <td>0.007756</td>\n",
       "      <td>{'C': 0.1, 'max_iter': 100, 'penalty': 'l2', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>540 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Algo  mean_test_score  std_test_score  mean_train_score  std_train_score  \\\n",
       "482   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "494   lr         0.835674        0.038374          0.838484         0.008868   \n",
       "509   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "508   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "507   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "505   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "504   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "503   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "502   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "501   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "500   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "497   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "496   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "495   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "493   lr         0.835674        0.038374          0.838484         0.008868   \n",
       "511   lr         0.835674        0.038374          0.838484         0.008868   \n",
       "492   lr         0.835674        0.038374          0.838484         0.008868   \n",
       "491   lr         0.835674        0.038374          0.838484         0.008868   \n",
       "490   lr         0.835674        0.038374          0.838484         0.008868   \n",
       "489   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "488   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "487   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "486   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "485   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "484   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "483   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "481   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "480   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "510   lr         0.835674        0.038374          0.838484         0.008868   \n",
       "506   lr         0.835674        0.038374          0.838132         0.008692   \n",
       "..   ...              ...             ...               ...              ...   \n",
       "93    lr         0.831461        0.039556          0.832865         0.009568   \n",
       "92    lr         0.831461        0.039556          0.832865         0.009568   \n",
       "91    lr         0.831461        0.039556          0.832865         0.009568   \n",
       "90    lr         0.831461        0.039556          0.832865         0.009568   \n",
       "89    lr         0.831461        0.039556          0.832865         0.009568   \n",
       "88    lr         0.831461        0.039556          0.832865         0.009568   \n",
       "87    lr         0.831461        0.039556          0.832865         0.009568   \n",
       "86    lr         0.831461        0.039556          0.832865         0.009568   \n",
       "85    lr         0.831461        0.039556          0.832865         0.009568   \n",
       "102   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "103   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "104   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "114   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "121   lr         0.831461        0.037728          0.835674         0.009455   \n",
       "120   lr         0.831461        0.037728          0.835674         0.009455   \n",
       "119   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "118   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "117   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "116   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "115   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "113   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "105   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "112   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "111   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "110   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "109   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "108   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "107   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "106   lr         0.831461        0.039556          0.832865         0.009568   \n",
       "0     lr         0.831461        0.035885          0.830055         0.007756   \n",
       "\n",
       "                                                params  \n",
       "482  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "494  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "509  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "508  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "507  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "505  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "504  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "503  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "502  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "501  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "500  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "497  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "496  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "495  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "493  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "511  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "492  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "491  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "490  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "489  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "488  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "487  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "486  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "485  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "484  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "483  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "481  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "480  {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'so...  \n",
       "510  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "506  {'C': 1, 'max_iter': 250, 'penalty': 'l2', 'so...  \n",
       "..                                                 ...  \n",
       "93   {'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...  \n",
       "92   {'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...  \n",
       "91   {'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...  \n",
       "90   {'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...  \n",
       "89   {'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...  \n",
       "88   {'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...  \n",
       "87   {'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...  \n",
       "86   {'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...  \n",
       "85   {'C': 0.2, 'max_iter': 250, 'penalty': 'l2', '...  \n",
       "102  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "103  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "104  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "114  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "121  {'C': 0.3, 'max_iter': 100, 'penalty': 'l2', '...  \n",
       "120  {'C': 0.3, 'max_iter': 100, 'penalty': 'l2', '...  \n",
       "119  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "118  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "117  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "116  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "115  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "113  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "105  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "112  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "111  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "110  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "109  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "108  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "107  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "106  {'C': 0.2, 'max_iter': 500, 'penalty': 'l2', '...  \n",
       "0    {'C': 0.1, 'max_iter': 100, 'penalty': 'l2', '...  \n",
       "\n",
       "[540 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gridsearch Finished\n",
      "\n",
      " -------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Pipeline setup\n",
    "models = { \n",
    "    'LogisticRegression': LogisticRegression()\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params = {'LogisticRegression' : { 'C': [0.1,0.2,0.3,0.4,0.5,0.6,0.8,0.9,1],\n",
    "           'penalty': ['l2'],\n",
    "           'solver': ['newton-cg','lbfgs','liblinear','sag'],\n",
    "           'max_iter': [100,250,500],\n",
    "           'tol':  [1e-4,3e-4,7e-4,1e-3,3e-3],\n",
    "          }\n",
    "         }\n",
    "\n",
    "# Lancer la grid search\n",
    "df_best_svc , dic_best_svc, d_res_svc = grid_search_global('clas',models,params,class_names=columns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lr_parm = {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001}\n",
    "lr = LogisticRegression(**lr_parm)\n",
    "lr.fit(X_train,y_train)\n",
    "lr_pred = lr.predict(test_data)\n",
    "Prediction['LR'] = lr_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418,)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train & Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classifier default parameters\n",
    "abc = AdaBoostClassifier(learning_rate = 0.5, n_estimators = 20)        \n",
    "lda = LinearDiscriminantAnalysis(n_components = 2, solver='svd')\n",
    "lr = LogisticRegression()\n",
    "svc = SVC(probability=True)\n",
    "rfc = RandomForestClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Classifier Tunep parameters\n",
    "abc_tp = AdaBoostClassifier(learning_rate = 0.5, n_estimators = 20)  \n",
    "lda_tp = LinearDiscriminantAnalysis(n_components = 2, solver='svd')\n",
    "lr_tp = LogisticRegression(C = 0.2, max_iter = 10, n_jobs = -1, penalty = 'l2', solver = 'sag', tol = 0.001)\n",
    "svc_tp = SVC(C=0.5, gamma=0.10, kernel='poly', degree=3, probability= True)\n",
    "rfc_tp = RandomForestClassifier(criterion = 'gini', max_features = 12, min_samples_leaf = 10,\n",
    "                             min_samples_split = 5, n_estimators = 30)\n",
    "gbc_tp = GradientBoostingClassifier(learning_rate=0.25, loss='exponential', max_depth=4, n_estimators=60)\n",
    "\n",
    "models = { \n",
    "    'VotingClassifier': VotingClassifier(estimators=[ ('lr', lr),('lda', lda), ('svc', svc), ('rfc', rfc), ('gbc', gbc)])\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params = {'VotingClassifier' : { 'estimators' : [[ ('lr', lr),('lda', lda), ('svc', svc), ('rfc', rfc), ('gbc', gbc)],\n",
    "                                                [ ('lr_tp', lr_tp),('lda_tp', lda_tp), ('svc_tp', svc_tp), ('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)]],\n",
    "                                   'voting': ['soft']\n",
    "          }\n",
    "         }\n",
    "\n",
    "# Lancer la grid search\n",
    "df_best_svc , dic_best_svc, d_res_svc = grid_search_global('clas',models,params,class_names=columns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jules/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:286: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/home/jules/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "# Classifier Tunep parameters\n",
    "# Score 0.77\n",
    "abc_tp = AdaBoostClassifier(learning_rate = 0.5, n_estimators = 20)  \n",
    "lda_tp = LinearDiscriminantAnalysis(n_components = 2, solver='svd')\n",
    "lr_tp = LogisticRegression(C = 0.2, max_iter = 10, n_jobs = -1, penalty = 'l2', solver = 'sag', tol = 0.001)\n",
    "svc_tp = SVC(C=0.5, gamma=0.10, kernel='poly', degree=3, probability= True)\n",
    "rfc_tp = RandomForestClassifier(criterion = 'gini', max_features = 12, min_samples_leaf = 10,\n",
    "                             min_samples_split = 5, n_estimators = 30)\n",
    "gbc_tp = GradientBoostingClassifier(learning_rate=0.25, loss='exponential', max_depth=4, n_estimators=60)\n",
    "\n",
    "\n",
    "VC_tp_soft = VotingClassifier(estimators=[ ('lr_tp', lr_tp),('lda_tp', lda_tp), ('svc_tp', svc_tp), ('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)],\n",
    "                                         voting='soft')\n",
    "VC_tp_soft.fit(X_train,y_train)\n",
    "Prediction['VC_tp_soft'] = VC_tp_soft.predict(Eval_OH_Std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 25)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Eval_OH_Std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(418, 2)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estim = #  Remplir ici\n",
    "Prediction = estim.predict(Eval_OH_Std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Prediction = Prediction['LR']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": PassengerId,\n",
    "        \"Survived\": Prediction\n",
    "    })\n",
    "submission.to_csv('titanic_lr_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
