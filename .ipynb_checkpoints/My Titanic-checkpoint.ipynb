{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict what sorts of people were likely to survive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- [Description of the data set](#Description-of-the-data-set)\n",
    "- [First look at the data](#First-look-at-the-data)\n",
    "    - [Import Libraries](#Import-Libraries)\n",
    "    - [Load Data](#Load-Data)\n",
    "    - [Brief summaries](#Brief-summaries)\n",
    "- [Visualization Part 1](#Visualization-Part-1)\n",
    "    - [Basic insight of the data](#Basic-insight-of-the-data)\n",
    "    - [Focus on the mean of survival](#Focus-on-the-mean-of-survival)\n",
    "- [Features engineering](#Features-engineering)\n",
    "    - [Name](#Name)\n",
    "    - [Family](#Family)\n",
    "    - [Family](#Family)\n",
    "    - [Cabin](#Cabin)\n",
    "- [Missing Values](#Missing-Values)\n",
    "    - [Embarked](#Embarked)\n",
    "    - [Fare](#Fare)\n",
    "    - [Age with Median](#Age-with-median)\n",
    "- [Visualization Part 2](#Visualization-Part-2)\n",
    "    - [Visualization Name](#Visualization-Name)\n",
    "    - [Visualization Family](#Visualization-Family)\n",
    "    - [Visualization Deck](#Visualization-Deck)\n",
    "    - [All features between Training and Testing set](#All-features-between-Training-and-Testing-set)\n",
    "- [Features Encoding](#Features-Encoding)\n",
    "    - [Categorial features encoding](#Categorial features encoding)\n",
    "        - [Label Encoding](#Label-Encoding)\n",
    "        - [One Hot Encoding](#One-Hot-Encodingn)   \n",
    "    - [Feature Scalling](#Feature-Scalling)\n",
    "    - [Data Preparation](#Data-Preparation)\n",
    "- [Features Importance](#Features-Importance)\n",
    "    - [Correlation - Quantitative Features](#Correlation---Quantitative-Features)\n",
    "    - [Correlation - Quantitative Features + One Hot Encoder](#Correlation---Quantitative-Features-+-One-Hot-Encoder)\n",
    "    - [LDA](#LDA)\n",
    "    - [Anova](#Anova)\n",
    "- [Model Selection](#Model-Selection)\n",
    "    - [Helper function](#Helper-function)\n",
    "    - [Gradient Boosting Classifier](#Gradient-Boosting-Classifier)\n",
    "    - [Random Forest Classifier](#Random-Forest-Classifier)\n",
    "    - [SVC](#SVC)\n",
    "    - [Voting Classifier](#Voting-Classifier)\n",
    "- [Submission](#Submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the data set"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "VARIABLE DESCRIPTIONS:\n",
    "survival        Survival\n",
    "                (0 = No; 1 = Yes)\n",
    "pclass          Passenger Class\n",
    "                (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "name            Name\n",
    "sex             Sex\n",
    "age             Age\n",
    "sibsp           Number of Siblings/Spouses Aboard\n",
    "parch           Number of Parents/Children Aboard\n",
    "ticket          Ticket Number\n",
    "fare            Passenger Fare\n",
    "cabin           Cabin\n",
    "embarked        Port of Embarkation\n",
    "                (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "\n",
    "SPECIAL NOTES:\n",
    "Pclass is a proxy for socio-economic status (SES)\n",
    " 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower\n",
    "\n",
    "Age is in Years; Fractional if Age less than One (1)\n",
    " If the Age is Estimated, it is in the form xx.5\n",
    "\n",
    "With respect to the family relation variables (i.e. sibsp and parch)\n",
    "some relations were ignored.  The following are the definitions used\n",
    "for sibsp and parch.\n",
    "\n",
    "Sibling:  Brother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic\n",
    "Spouse:   Husband or Wife of Passenger Aboard Titanic (Mistresses and Fiances Ignored)\n",
    "Parent:   Mother or Father of Passenger Aboard Titanic\n",
    "Child:    Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic\n",
    "\n",
    "Other family relatives excluded from this study include cousins,\n",
    "nephews/nieces, aunts/uncles, and in-laws.  Some children travelled\n",
    "only with a nanny, therefore parch=0 for them.  As well, some\n",
    "travelled with very close friends or neighbors in a village, however,\n",
    "the definitions do not support such relations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "# Sklearn\n",
    "\n",
    "    # General\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, f1_score,\n",
    "                            precision_score, recall_score) \n",
    "    # Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (ExtraTreesClassifier, RandomForestClassifier, \n",
    "                              AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier)\n",
    "\n",
    "# Warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Thayer)</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0  1            0         3        \n",
       "1  2            1         1        \n",
       "2  3            1         3        \n",
       "3  4            1         1        \n",
       "4  5            0         3        \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0  Braund, Mr. Owen Harris                              male    22.0  1       \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Thayer)  female  38.0  1       \n",
       "2  Heikkinen, Miss. Laina                               female  26.0  0       \n",
       "3  Futrelle, Mrs. Jacques Heath (Lily May Peel)         female  35.0  1       \n",
       "4  Allen, Mr. William Henry                             male    35.0  0       \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0  0      A/5 21171         7.2500   NaN   S        \n",
       "1  0      PC 17599          71.2833  C85   C        \n",
       "2  0      STON/O2. 3101282  7.9250   NaN   S        \n",
       "3  0      113803            53.1000  C123  S        \n",
       "4  0      373450            8.0500   NaN   S        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing set\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0  892          3       Kelly, Mr. James                              male     \n",
       "1  893          3       Wilkes, Mrs. James (Ellen Needs)              female   \n",
       "2  894          2       Myles, Mr. Thomas Francis                     male     \n",
       "3  895          3       Wirz, Mr. Albert                              male     \n",
       "4  896          3       Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5  0      0      330911   7.8292   NaN   Q        \n",
       "1  47.0  1      0      363272   7.0000   NaN   S        \n",
       "2  62.0  0      0      240276   9.6875   NaN   Q        \n",
       "3  27.0  0      0      315154   8.6625   NaN   S        \n",
       "4  22.0  1      1      3101298  12.2875  NaN   S        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load data\n",
    "df_train=pd.read_csv(\"Data/Titanic/train.csv\")\n",
    "df_test=pd.read_csv(\"Data/Titanic/test.csv\")\n",
    "\n",
    "# Get a combined Dataframe \n",
    "combined = df_train.append(df_test)\n",
    "combined.reset_index(inplace=True)\n",
    "\n",
    "# For visualization\n",
    "combined.loc[0:890,'Data_set'] = 'Train'\n",
    "combined.loc[891:,'Data_set'] = 'Test'\n",
    "combined.loc[0:890,'Train'] = 1\n",
    "combined.loc[891:,'Train'] = 0\n",
    "#combined.drop('index',axis=1,inplace=True)\n",
    "\n",
    "# Get PassengerId for test and targets for training set\n",
    "targets = df_train.Survived\n",
    "PassengerId = df_test['PassengerId']\n",
    "\n",
    "# Helpler function to split combined quickly\n",
    "def split_train_test(combined):\n",
    "    \n",
    "    train = pd.DataFrame()\n",
    "    test = pd.DataFrame()\n",
    "    \n",
    "    train = combined.ix[0:890]\n",
    "    test = combined.ix[891:]\n",
    "    \n",
    "    return train,test\n",
    "\n",
    "# Get a look at the first rows\n",
    "print(\"Training set\")\n",
    "display(df_train.head())\n",
    "print(\"Testing set\")\n",
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"----------------------------------Informations for the training set----------------------------------\\n\")\n",
    "df_train.info()\n",
    "print('\\nList of Null values \\n\\n',df_train.isnull().sum())\n",
    "print(\"\\n----------------------------------Informations for the testing set ----------------------------------\\n\")\n",
    "df_test.info()\n",
    "print('\\nList of Null values \\n\\n',df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that:\n",
    "    - No Survived feature on the testing set\n",
    "    - Lot of Ages values are missing \n",
    "    - Cabin feature is mostly null \n",
    "    - Embarked feature has a few missing values\n",
    "    - Survived and Pclass should be treated as object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic statistical information about quantitative and qualitative columns\n",
    "\n",
    "# Changing the type of Pclass and Survived \n",
    "df_train['Pclass']=df_train['Pclass'].astype(object)\n",
    "df_train['Survived']=df_train['Survived'].astype(object)\n",
    "df_test['Pclass']=df_test['Pclass'].astype(object)\n",
    "\n",
    "print(\"----------------------------------Informations for the training set----------------------------------\\n\")\n",
    "\n",
    "# Quantitative\n",
    "display(df_train.describe())\n",
    "\n",
    "# Qualitative\n",
    "display(df_train.describe(include=['object']))\n",
    "\n",
    "print(\"----------------------------------Informations for the testing set----------------------------------\\n\")\n",
    "\n",
    "# Quantitative\n",
    "display(df_test.describe())\n",
    "\n",
    "# Qualitative\n",
    "display(df_test.describe(include=['object']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic insight of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Qualitative Data : [Survived, Sex, Embarked, Pclass] \n",
    "fig, (axis1,axis2,axis3,axis4) = plt.subplots(1,4,figsize=(15,5))\n",
    "sns.countplot(x='Survived', data=df_train, ax=axis1)\n",
    "sns.countplot(x='Sex', data=df_train, ax=axis2)\n",
    "sns.countplot(x='Embarked', data=df_train, ax=axis3)\n",
    "sns.countplot(x='Pclass', data=df_train, ax=axis4)\n",
    "fig.suptitle(\"Basic representation of Qualitative data with count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discrete Quantitative Data : [SibSp, Parch] \n",
    "fig2, (axis1,axis2) = plt.subplots(1,2,figsize=(15,5))\n",
    "sns.countplot(df_train['SibSp'],ax=axis1)\n",
    "sns.countplot(df_train['Parch'],ax=axis2)\n",
    "fig2.suptitle(\"Basic representation of Discrete Quantitative data with count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Continuous Quantitative Data : [Age, Fare]\n",
    "fig3, (axis1,axis2) = plt.subplots(2,1,figsize=(15,10))\n",
    "sns.distplot(df_train['Age'].dropna(), bins=80, ax=axis1)\n",
    "sns.distplot(df_train['Fare'], ax=axis2)\n",
    "fig3.suptitle(\"Histogram and kernel density estimate of Continuous Quantitative data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Age distribution within Sex and Pclass\n",
    "fig3, ((axis1),(axis2),(axis3)) = plt.subplots(3,1,figsize=(15,15))\n",
    "\n",
    "# Age distribution\n",
    "df_train.Age.plot(kind='kde',ax=axis1)\n",
    "axis1.set_xlabel(\"Age\")    \n",
    "axis1.set_title(\"Age Distribution\")\n",
    "\n",
    "# Age distribution within Sex\n",
    "df_train.Age[df_train.Sex == 'male'].plot(kind='kde',ax=axis2,)    \n",
    "df_train.Age[df_train.Sex == 'female'].plot(kind='kde',ax=axis2)\n",
    "axis2.set_xlabel(\"Age\")    \n",
    "axis2.set_title(\"Age Distribution within Sex\")\n",
    "axis2.legend(('Male', 'Female'))\n",
    "\n",
    "# Age distribution within Pclass\n",
    "df_train.Age[df_train.Pclass == 1].plot(kind='kde',ax=axis3)    \n",
    "df_train.Age[df_train.Pclass == 2].plot(kind='kde',ax=axis3)\n",
    "df_train.Age[df_train.Pclass == 3].plot(kind='kde',ax=axis3)\n",
    "axis3.set_xlabel(\"Age\")    \n",
    "axis3.set_title(\"Age Distribution within Classes\")\n",
    "axis3.legend(('1st Class', '2nd Class','3rd Class'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Focus on the mean of survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (Sex, Pclass, Embarked) by mean of survival\n",
    "fig4, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(15,5))\n",
    "sns.barplot(x='Sex',y='Survived', data=df_train, ax=axis1)\n",
    "sns.barplot(x='Embarked',y='Survived', data=df_train, ax=axis2)\n",
    "sns.barplot(x='Pclass',y='Survived', data=df_train, ax=axis3)\n",
    "fig4.suptitle(\"Representation of features linked to the target : Survived \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (SibSp, Parch) by mean of survival\n",
    "fig6, (axis1,axis2) = plt.subplots(1,2,figsize=(15,5))\n",
    "sns.barplot(x='SibSp',y='Survived', data=df_train, ax=axis1)\n",
    "sns.barplot(x='Parch',y='Survived', data=df_train, ax=axis2)\n",
    "fig6.suptitle(\"Representation of features linked to the target : Survived \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross relation betwen (Sex, Pclass, Embarked) by mean of survival\n",
    "fig5, ((axis1,axis2),(axis3,axis4),(axis5,axis6)) = plt.subplots(3,2,figsize=(15,15))\n",
    "sns.barplot(x='Sex',y='Survived',hue='Pclass', data=df_train, ax=axis1)\n",
    "sns.barplot(x='Sex',y='Survived',hue='Embarked', data=df_train, ax=axis2)\n",
    "\n",
    "sns.barplot(x='Pclass',y='Survived',hue='Sex', data=df_train, ax=axis3)\n",
    "sns.barplot(x='Pclass',y='Survived',hue='Embarked', data=df_train, ax=axis4)\n",
    "\n",
    "sns.barplot(x='Embarked',y='Survived',hue='Sex', data=df_train, ax=axis5)\n",
    "sns.barplot(x='Embarked',y='Survived',hue='Pclass', data=df_train, ax=axis6)\n",
    "\n",
    "fig5.suptitle(\"Cross Representation of the features linked to the target : Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Age by mean of survival\n",
    "fig = plt.figure(figsize=(25,10))\n",
    "fig = sns.barplot(x='Age', y='Survived', data=df_train,errwidth=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Kernel density of survivor and non survivor by Age\n",
    "g1 = sns.FacetGrid( df_train , hue='Survived' , aspect=4)\n",
    "g1.map( sns.kdeplot , 'Age' , shade= True )\n",
    "g1.add_legend()\n",
    "\n",
    "# Kernel density of survivor and non survivor by Age and Sex \n",
    "g2 = sns.FacetGrid( df_train , hue='Survived' , aspect=4 , row = 'Sex')\n",
    "g2.map( sns.kdeplot , 'Age' , shade= True )\n",
    "g2.add_legend()\n",
    "\n",
    "# Kernel density of survivor and non survivor by Age and Pclass\n",
    "g3 = sns.FacetGrid( df_train , hue='Survived' , aspect=4 , row = 'Pclass')\n",
    "g3.map( sns.kdeplot , 'Age' , shade= True )\n",
    "g3.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scatterplot Fare & Age\n",
    "g = sns.FacetGrid(df_train, hue=\"Survived\", size=6)\n",
    "g=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\n",
    "g.add_legend()\n",
    "g.set(xlim=(0, 550))\n",
    "\n",
    "# Scatterplot Fare & Age by Sex\n",
    "g = sns.FacetGrid(df_train, hue=\"Survived\", col=\"Sex\", margin_titles=True,\n",
    "                palette=\"Set1\",hue_kws=dict(marker=[\"^\", \"v\"]),size=6)\n",
    "g=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\n",
    "g.add_legend()\n",
    "g.set(xlim=(0, 300))\n",
    "\n",
    "# Scatterplot Fare & Age by Pclass\n",
    "g = sns.FacetGrid(df_train, col=\"Pclass\", hue=\"Survived\", size=4)\n",
    "g=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\n",
    "g.add_legend()\n",
    "g.set(xlim=(0, 300))\n",
    "\n",
    "# Scatterplot Fare & Age by Pclass & Sex\n",
    "g = sns.FacetGrid(df_train, hue=\"Survived\", col=\"Pclass\", row=\"Sex\" ,margin_titles=True,\n",
    "                  palette={1:\"red\", 0:\"grey\"},size=5)\n",
    "g=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\n",
    "g.set(xlim=(0, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization concerning the feature engineering is in the section [Visualization Part 2](#Visualization-Part-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create feature for the length of name \n",
    "combined[\"Name_Length\"] = combined[\"Name\"].apply(lambda x: len(x))\n",
    "\n",
    "# Create a categorical feature Name_Size\n",
    "combined['Name_Size']=pd.cut(combined['Name_Length']\n",
    "                            ,bins=[0,20,40,60,90]\n",
    "                            ,labels=[\"Short\",\"Medium\",\"Long\",\"Very Long\"])\n",
    "\n",
    "# Extract the title from each name by sliding between the ',' and the '.' \n",
    "combined['Title'] = combined['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "\n",
    "# Map for aggregated titles\n",
    "Title_Dictionary = {\n",
    "                    \"Mme\":        \"Mrs\",\n",
    "                    \"Mlle\":       \"Miss\",\n",
    "                    \"Ms\":         \"Mrs\",\n",
    "                    \"Mr\" :        \"Mr\",\n",
    "                    \"Mrs\" :       \"Mrs\",\n",
    "                    \"Miss\" :      \"Miss\",\n",
    "                    \"Capt\":       \"Officer\",\n",
    "                    \"Col\":        \"Officer\",\n",
    "                    \"Major\":      \"Officer\",\n",
    "                    \"Dr\":         \"Officer\",\n",
    "                    \"Rev\":        \"Officer\",\n",
    "                    \"Master\" :    \"Master\",\n",
    "                    \"Lady\" :      \"Royalty\",\n",
    "                    \"Jonkheer\":   \"Royalty\",\n",
    "                    \"Don\":        \"Royalty\",\n",
    "                    \"Sir\" :       \"Royalty\",\n",
    "                    \"Dona\":       \"Royalty\",\n",
    "                    \"the Countess\":\"Royalty\"\n",
    "                    }\n",
    "    \n",
    "# Mapping\n",
    "combined['Title_aggr'] = combined.Title.map(Title_Dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creation of a feature Number_of_relatives = SibSp + Parch\n",
    "combined['Number_of_relatives']=combined['SibSp']+combined['Parch']\n",
    "\n",
    "# Creation of a categorical feature Size_Family\n",
    "combined.loc[combined['Number_of_relatives'] == 0, 'Size_Family'] = 'Alone'\n",
    "combined.loc[ (combined['Number_of_relatives'] > 0) \n",
    "            & (combined['Number_of_relatives'] < 4), 'Size_Family'] = 'Small'\n",
    "combined.loc[combined['Number_of_relatives'] > 3, 'Size_Family'] = 'Big'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of null values:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1014"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mostly NaN values\n",
    "print('Number of null values:')\n",
    "display(combined.Cabin.isnull().sum())\n",
    "\n",
    "# Create a category Unknown\n",
    "combined['Cabin'] = combined.Cabin.fillna( 'U' )\n",
    "\n",
    "# Get the Deck \n",
    "combined[\"Deck\"]=combined.Cabin.str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Fare  Pclass Embarked\n",
       "61   80.0  1       NaN    \n",
       "829  80.0  1       NaN    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAGTCAYAAAA8+/sRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nbBSVSzc8WwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c05b21710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get and display the rows where Embarked is null\n",
    "display(combined[combined.Embarked.isnull()][['Fare', 'Pclass', 'Embarked']])\n",
    "\n",
    "# Display boxplot of Embarked missing values\n",
    "combined.boxplot(column='Fare', by=['Embarked','Pclass'], figsize=(8,6))\n",
    "plt.axhline(y=80, color='blue')\n",
    "\n",
    "# Remplace null values by C as most people who are Pclass 1 and Fare 80 has Embarked from C\n",
    "combined = combined.set_value(combined.Embarked.isnull(), 'Embarked', 'C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFlCAYAAAA6QpuEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c02598cc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualization of the fare which is missing\n",
    "combined[combined.Fare.isnull()][['Pclass', 'Fare', 'Embarked']]\n",
    "combined.loc[(combined['Pclass']==3) & (combined['Embarked']=='S')].Fare.hist(bins=100,figsize=(8,6))\n",
    "\n",
    "# Get and affect the median to the missing value\n",
    "Fare_median=combined[(combined.Pclass==3) & (combined.Embarked=='S')].Fare.median()\n",
    "combined[\"Fare\"].fillna(Fare_median, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex     Pclass  Title_aggr\n",
       "female  1       Miss          30.0\n",
       "                Mrs           45.0\n",
       "                Officer       49.0\n",
       "                Royalty       39.0\n",
       "        2       Miss          20.0\n",
       "                Mrs           30.0\n",
       "        3       Miss          18.0\n",
       "                Mrs           31.0\n",
       "male    1       Master        6.0 \n",
       "                Mr            41.5\n",
       "                Officer       52.0\n",
       "                Royalty       40.0\n",
       "        2       Master        2.0 \n",
       "                Mr            30.0\n",
       "                Officer       41.5\n",
       "        3       Master        6.0 \n",
       "                Mr            26.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fill the NaN values with median using Sex, Pclass and Title\n",
    "grouped = combined.groupby(['Sex','Pclass','Title_aggr'])\n",
    "age_median = grouped['Age'].median()\n",
    "combined[\"Age\"] = combined.groupby(['Sex','Pclass','Title_aggr'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "# Display the median by Sex Pclass and Title_aggr\n",
    "display(age_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Verification of missing values\n",
    "print('Number of null values :')\n",
    "display(combined.isnull().sum())\n",
    "\n",
    "# Split for visualization\n",
    "df_train, df_test= split_train_test(combined)\n",
    "\n",
    "# Display shape\n",
    "display(df_train.shape)\n",
    "display(df_test.shape)\n",
    "\n",
    "# Name of columns\n",
    "display(df_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ((axis1,axis2),(axis3,axis4),(axis5,axis6),(axis7,axis8)) = plt.subplots(4,2,figsize=(20,20))\n",
    "\n",
    "# Plot Name_Length\n",
    "sns.distplot(df_train['Name_Length'],ax=axis1)\n",
    "axis1.set_title(\" Hist and kde of Name_Length\")\n",
    "# Plot Name_Length by mean of survival\n",
    "sns.barplot(x='Name_Length', y='Survived', data=df_train,errwidth=0,ax=axis2)\n",
    "axis2.set_title(\" Name_Length by mean of survival\")\n",
    "\n",
    "# Plot Name_Size\n",
    "sns.countplot(x='Name_Size', data=df_train, order=[\"Short\",\"Medium\",\"Long\",\"Very Long\"], ax=axis3)\n",
    "axis3.set_title(\" Count of Name_Size\")\n",
    "# Plot Name_Size by mean of survival\n",
    "sns.barplot(x='Name_Size',y='Survived', data=df_train, order=[\"Short\",\"Medium\",\"Long\",\"Very Long\"], ax=axis4)\n",
    "axis4.set_title(\" Name_Size by mean of survival\")\n",
    "\n",
    "# Plot Title\n",
    "sns.countplot(x='Title', data=df_train, ax=axis5)\n",
    "axis5.set_title(\" Count of Title\")\n",
    "# Plot Title\n",
    "sns.barplot(x='Title',y='Survived', data=df_train, ax=axis6)\n",
    "axis6.set_title(\" Title by mean of survival\")\n",
    "\n",
    "# Plot Title aggregate\n",
    "sns.countplot(x='Title_aggr', data=df_train, ax=axis7)\n",
    "axis7.set_title(\" Count of Title_aggr\")\n",
    "# Plot Title aggregate\n",
    "sns.barplot(x='Title_aggr',y='Survived', data=df_train, ax=axis8)\n",
    "axis8.set_title(\" Title_aggr by mean of survival\")\n",
    "\n",
    "# Display Title aggregate and Name Size by mean of survival\n",
    "#sns.barplot(x='Title_aggr',y='Survived', hue='Name_Size', data=df_train,errwidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ((axis1,axis2),(axis3,axis4),(axis5,axis6),(axis7,axis8)) = plt.subplots(4,2,figsize=(20,20))\n",
    "\n",
    "# Plot Number_of_relatives\n",
    "sns.countplot(x='Number_of_relatives', data=df_train, ax=axis1)\n",
    "axis1.set_title(\" Count of Number_of_relatives\")\n",
    "# Plot Number_of_relatives by mean of survival\n",
    "fig2 = sns.barplot(x='Number_of_relatives',y='Survived', data=df_train, ax=axis2)\n",
    "axis2.set_title(\" Number_of_relatives by mean of survival\")\n",
    "\n",
    "# Plot Size_Family\n",
    "sns.countplot(x='Size_Family', data=df_train, order=['Alone', 'Small', 'Big'], ax=axis3)\n",
    "axis3.set_title(\" Count of Size_Family\")\n",
    "# Plot Size_Family by mean of survival\n",
    "sns.barplot(x='Size_Family',y='Survived', data=df_train, order=['Alone', 'Small', 'Big'], ax=axis4)\n",
    "axis4.set_title(\" Size_Family by mean of survival\")\n",
    "\n",
    "# Plot Number_of_relatives and Pclass \n",
    "sns.barplot(x='Number_of_relatives',y='Survived',hue='Pclass', data=df_train, ax=axis5)\n",
    "axis5.set_title(\" Number_of_relatives and Pclass by mean of survival\")\n",
    "# Plot Number_of_relatives and Pclass by mean of survival\n",
    "sns.barplot(x='Number_of_relatives',y='Survived',hue='Sex', data=df_train, ax=axis6)\n",
    "axis6.set_title(\" Number_of_relatives and Sex by mean of survival\")\n",
    "\n",
    "# Plot Size_Family and Pclass\n",
    "sns.barplot(x='Size_Family',y='Survived',hue='Pclass', data=df_train, order=['Alone', 'Small', 'Big'], ax=axis7)\n",
    "axis7.set_title(\"Size_Family and Pclass by mean of survival\")\n",
    "# Plot Size_Family  and Pclass by mean of survival\n",
    "sns.barplot(x='Size_Family',y='Survived',hue='Sex', data=df_train, order=['Alone', 'Small', 'Big'], ax=axis8)\n",
    "axis8.set_title(\" Size_Family and Sex by mean of survival\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization Deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show Deck by size and mean of survival\n",
    "fig6, (axis1,axis2) = plt.subplots(1,2,figsize=(15,5))\n",
    "sns.countplot(x='Deck',hue='Data_set', data=df_train, ax=axis1)\n",
    "sns.barplot(x='Deck', y='Survived', data=df_train, ax=axis2)\n",
    "fig6.suptitle(\"Deck by size and mean of survival\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All features between Training and Testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display columns\n",
    "display(combined.columns)\n",
    "\n",
    "# Display shape\n",
    "display(df_test.shape)\n",
    "display(df_train.shape)\n",
    "display(combined.shape)\n",
    "\n",
    "# Ratio between the size of the training and testing set\n",
    "Ratio = df_train.shape[0]/df_test.shape[0]\n",
    "print('Ratio between training and testing set:',Ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Kde of Age, Fare, Name_Length and Number_of_relatives\n",
    "fig, ((axis1,axis2),(axis3,axis4))= plt.subplots(2,2,figsize=(20,20))\n",
    "\n",
    "# Age distribution within 3 datasets\n",
    "combined.Age.plot(kind='kde',ax=axis1)    \n",
    "df_train.Age.plot(kind='kde',ax=axis1)  \n",
    "df_test.Age.plot(kind='kde',ax=axis1)  \n",
    "axis1.set_xlabel(\"Age\")    \n",
    "axis1.set_title(\" Kde of Age for the 3 datasets\")\n",
    "axis1.legend(('Combined', 'Train','Test'))\n",
    "\n",
    "# Fare distribution within 3 datasets\n",
    "combined.Fare.plot(kind='kde',ax=axis2)    \n",
    "df_train.Fare.plot(kind='kde',ax=axis2)  \n",
    "df_test.Fare.plot(kind='kde',ax=axis2)  \n",
    "axis2.set_xlabel(\"Fare\")    \n",
    "axis2.set_title(\" Kde of Fare for the 3 datasets\")\n",
    "axis2.legend(('Combined', 'Train','Test'))\n",
    "\n",
    "# Name_Length distribution within 3 datasets\n",
    "combined.Name_Length.plot(kind='kde',ax=axis3)    \n",
    "df_train.Name_Length.plot(kind='kde',ax=axis3)  \n",
    "df_test.Name_Length.plot(kind='kde',ax=axis3)  \n",
    "axis3.set_xlabel(\"Name_Length\")    \n",
    "axis3.set_title(\" Kde of Name_Length for the 3 datasets\")\n",
    "axis3.legend(('Combined', 'Train','Test'))\n",
    "\n",
    "# Number_of_relatives distribution within 3 datasets\n",
    "combined.Number_of_relatives.plot(kind='kde',ax=axis4)    \n",
    "df_train.Number_of_relatives.plot(kind='kde',ax=axis4)  \n",
    "df_test.Number_of_relatives.plot(kind='kde',ax=axis4)  \n",
    "axis4.set_xlabel(\"Number_of_relatives\")    \n",
    "axis4.set_title(\" Kde of Number_of_relatives for the 3 datasets\")\n",
    "axis4.legend(('Combined', 'Train','Test'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count of Pclass, Sex, Embarked, Name_Size, Title and Title_aggr\n",
    "fig, ((axis1,axis2),(axis3,axis4),(axis5,axis6))= plt.subplots(3,2,figsize=(20,20))\n",
    "\n",
    "# Pclass\n",
    "sns.countplot(x='Pclass',hue='Data_set', data=combined, ax=axis1)\n",
    "axis1.set_xlabel(\"Pclass\")    \n",
    "axis1.set_title(\" Countplot of Pclass for the training and testing set\")\n",
    "\n",
    "# Sex\n",
    "sns.countplot(x='Sex',hue='Data_set', data=combined, ax=axis2)\n",
    "axis2.set_xlabel(\"Sex\")    \n",
    "axis2.set_title(\" Countplot of Sex for the training and testing set\")\n",
    "\n",
    "# Embarked\n",
    "sns.countplot(x='Embarked',hue='Data_set', data=combined, ax=axis3)\n",
    "axis3.set_xlabel(\"Name_Size\")    \n",
    "axis3.set_title(\" Countplot of Embarked for the training and testing set\")\n",
    "\n",
    "# Name_Size\n",
    "sns.countplot(x='Name_Size',hue='Data_set', data=combined, ax=axis4)\n",
    "axis4.set_xlabel(\"Name_Size\")    \n",
    "axis4.set_title(\" Countplot of Name_Size for the training and testing set\")\n",
    "\n",
    "# Title\n",
    "sns.countplot(x='Title',hue='Data_set', data=combined, ax=axis5)\n",
    "axis5.set_xlabel(\"Title\")    \n",
    "axis5.set_title(\" Countplot of Title for the training and testing set\")\n",
    "\n",
    "# Title_aggr\n",
    "sns.countplot(x='Title_aggr',hue='Data_set', data=combined, ax=axis6)\n",
    "axis6.set_xlabel(\"Title_aggr\")    \n",
    "axis6.set_title(\" Countplot of Title_aggr for the training and testing set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'Age', 'Cabin', 'Embarked', 'Fare', 'Name', 'Parch',\n",
       "       'PassengerId', 'Pclass', 'Sex', 'SibSp', 'Survived', 'Ticket',\n",
       "       'Data_set', 'Train', 'Name_Length', 'Name_Size', 'Title', 'Title_aggr',\n",
       "       'Number_of_relatives', 'Size_Family', 'Deck'],\n",
       "      dtype='object')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "index                  0  \n",
       "Age                    0  \n",
       "Cabin                  0  \n",
       "Embarked               0  \n",
       "Fare                   0  \n",
       "Name                   0  \n",
       "Parch                  0  \n",
       "PassengerId            0  \n",
       "Pclass                 0  \n",
       "Sex                    0  \n",
       "SibSp                  0  \n",
       "Survived               418\n",
       "Ticket                 0  \n",
       "Data_set               0  \n",
       "Train                  0  \n",
       "Name_Length            0  \n",
       "Name_Size              0  \n",
       "Title                  0  \n",
       "Title_aggr             0  \n",
       "Number_of_relatives    0  \n",
       "Size_Family            0  \n",
       "Deck                   0  \n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1309, 22)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Title_aggr</th>\n",
       "      <th>Size_Family</th>\n",
       "      <th>Name_Size</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Small</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C</td>\n",
       "      <td>female</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Small</td>\n",
       "      <td>Long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>Miss</td>\n",
       "      <td>Alone</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "      <td>female</td>\n",
       "      <td>Mrs</td>\n",
       "      <td>Small</td>\n",
       "      <td>Long</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "      <td>male</td>\n",
       "      <td>Mr</td>\n",
       "      <td>Alone</td>\n",
       "      <td>Medium</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Embarked     Sex Title_aggr Size_Family Name_Size  Pclass\n",
       "0  S        male    Mr         Small       Medium    3     \n",
       "1  C        female  Mrs        Small       Long      1     \n",
       "2  S        female  Miss       Alone       Medium    3     \n",
       "3  S        female  Mrs        Small       Long      1     \n",
       "4  S        male    Mr         Alone       Medium    3     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(combined.columns)\n",
    "display(combined.isnull().sum())\n",
    "display(combined.shape)\n",
    "display(combined[[\"Embarked\",\"Sex\",\"Title_aggr\",\"Size_Family\",\"Name_Size\",\"Pclass\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorial features encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dataframe with numerical categorical feature\n",
    "combined_num_cat = pd.DataFrame()\n",
    "\n",
    "# LabelEncoder\n",
    "labelEnc = LabelEncoder()\n",
    "\n",
    "# Columns to apply\n",
    "cat_vars=[\"Embarked\",\"Sex\",\"Title_aggr\",\"Size_Family\",\"Name_Size\"]\n",
    "\n",
    "for col in cat_vars:\n",
    "    labelEnc.fit(np.unique(list(combined[col].values)))\n",
    "    combined_num_cat[col]=labelEnc.transform(combined[col].astype('str'))\n",
    "    \n",
    "labelEnc.fit(np.unique(list(combined[\"Pclass\"].values)))\n",
    "combined_num_cat[\"Pclass\"]=labelEnc.transform(combined[\"Pclass\"].astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Title_aggr</th>\n",
       "      <th>Size_Family</th>\n",
       "      <th>Name_Size</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Embarked  Sex  Title_aggr  Size_Family  Name_Size  Pclass\n",
       "0  2         1    2           2            1          2     \n",
       "1  0         0    3           2            0          0     \n",
       "2  2         0    1           0            1          2     \n",
       "3  2         0    3           2            0          0     \n",
       "4  2         1    2           0            1          2     "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_num_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One Hot  Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(df_in, cols):\n",
    "    df_out = pd.DataFrame()\n",
    "    for each in cols:\n",
    "        dummies = pd.get_dummies(df_in[each], prefix=each, drop_first=False)\n",
    "        df_out = pd.concat([df_out, dummies], axis=1)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Columns to apply\n",
    "cat_vars=['Embarked','Sex',\"Title_aggr\",\"Size_Family\",\"Name_Size\",\"Pclass\"]\n",
    "combined_One_Hot_Cat = one_hot(combined,cat_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Title_aggr_Master</th>\n",
       "      <th>Title_aggr_Miss</th>\n",
       "      <th>Title_aggr_Mr</th>\n",
       "      <th>Title_aggr_Mrs</th>\n",
       "      <th>Title_aggr_Officer</th>\n",
       "      <th>...</th>\n",
       "      <th>Size_Family_Alone</th>\n",
       "      <th>Size_Family_Big</th>\n",
       "      <th>Size_Family_Small</th>\n",
       "      <th>Name_Size_Short</th>\n",
       "      <th>Name_Size_Medium</th>\n",
       "      <th>Name_Size_Long</th>\n",
       "      <th>Name_Size_Very Long</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows  21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Embarked_C  Embarked_Q  Embarked_S  Sex_female  Sex_male  \\\n",
       "0  0           0           1           0           1          \n",
       "1  1           0           0           1           0          \n",
       "2  0           0           1           1           0          \n",
       "3  0           0           1           1           0          \n",
       "4  0           0           1           0           1          \n",
       "\n",
       "   Title_aggr_Master  Title_aggr_Miss  Title_aggr_Mr  Title_aggr_Mrs  \\\n",
       "0  0                  0                1              0                \n",
       "1  0                  0                0              1                \n",
       "2  0                  1                0              0                \n",
       "3  0                  0                0              1                \n",
       "4  0                  0                1              0                \n",
       "\n",
       "   Title_aggr_Officer    ...     Size_Family_Alone  Size_Family_Big  \\\n",
       "0  0                     ...     0                  0                 \n",
       "1  0                     ...     0                  0                 \n",
       "2  0                     ...     1                  0                 \n",
       "3  0                     ...     0                  0                 \n",
       "4  0                     ...     1                  0                 \n",
       "\n",
       "   Size_Family_Small  Name_Size_Short  Name_Size_Medium  Name_Size_Long  \\\n",
       "0  1                  0                1                 0                \n",
       "1  1                  0                0                 1                \n",
       "2  0                  0                1                 0                \n",
       "3  1                  0                0                 1                \n",
       "4  0                  0                1                 0                \n",
       "\n",
       "   Name_Size_Very Long  Pclass_1  Pclass_2  Pclass_3  \n",
       "0  0                    0         0         1         \n",
       "1  0                    1         0         0         \n",
       "2  0                    0         0         1         \n",
       "3  0                    1         0         0         \n",
       "4  0                    0         0         1         \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_One_Hot_Cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scalling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age</th>\n",
       "      <th>Name_Length</th>\n",
       "      <th>Number_of_relatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2500</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.2833</td>\n",
       "      <td>38.0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.9250</td>\n",
       "      <td>26.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.1000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0500</td>\n",
       "      <td>35.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fare   Age  Name_Length  Number_of_relatives\n",
       "0  7.2500   22.0  23           1                  \n",
       "1  71.2833  38.0  51           1                  \n",
       "2  7.9250   26.0  22           0                  \n",
       "3  53.1000  35.0  44           1                  \n",
       "4  8.0500   35.0  24           0                  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[['Fare','Age','Name_Length','Number_of_relatives']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age</th>\n",
       "      <th>Name_Length</th>\n",
       "      <th>Number_of_relatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.503176</td>\n",
       "      <td>-0.541471</td>\n",
       "      <td>-0.434672</td>\n",
       "      <td>0.073352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.734809</td>\n",
       "      <td>0.648868</td>\n",
       "      <td>2.511806</td>\n",
       "      <td>0.073352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.490126</td>\n",
       "      <td>-0.243886</td>\n",
       "      <td>-0.539904</td>\n",
       "      <td>-0.558346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.383263</td>\n",
       "      <td>0.425680</td>\n",
       "      <td>1.775186</td>\n",
       "      <td>0.073352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.487709</td>\n",
       "      <td>0.425680</td>\n",
       "      <td>-0.329441</td>\n",
       "      <td>-0.558346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Fare       Age  Name_Length  Number_of_relatives\n",
       "0 -0.503176 -0.541471 -0.434672     0.073352           \n",
       "1  0.734809  0.648868  2.511806     0.073352           \n",
       "2 -0.490126 -0.243886 -0.539904    -0.558346           \n",
       "3  0.383263  0.425680  1.775186     0.073352           \n",
       "4 -0.487709  0.425680 -0.329441    -0.558346           "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_columns = ['Fare','Age','Name_Length','Number_of_relatives']\n",
    "\n",
    "combined_num_std = pd.DataFrame(combined[std_columns])\n",
    "\n",
    "# StandardScaller process\n",
    "std_scale = StandardScaler()\n",
    "combined_num_std[std_columns] = std_scale.fit_transform(combined[std_columns].astype(float))\n",
    "\n",
    "combined_num_std[std_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Available :\n",
    "combined_num_std\n",
    "combined_One_Hot_Cat\n",
    "combined_num_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 25)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1309, 10)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concat\n",
    "combined_OH_Std = pd.concat([combined_num_std,combined_One_Hot_Cat],axis=1)\n",
    "combined_Num_Std = pd.concat([combined_num_std,combined_num_cat],axis=1)\n",
    "\n",
    "# Display shape\n",
    "display(combined_OH_Std.shape)\n",
    "display(combined_Num_Std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 25)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(418, 25)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Split into Train and Eval\n",
    "Train_OH_Std, Eval_OH_Std= split_train_test(combined_OH_Std)\n",
    "Train_Num_Std, Eval_Num_Std = split_train_test(combined_Num_Std)\n",
    "\n",
    "# Display shape\n",
    "display(Train_OH_Std.shape)\n",
    "display(Eval_OH_Std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select Data\n",
    "data = Train_OH_Std\n",
    "test_data = Eval_OH_Std\n",
    "target = targets\n",
    "columns_name = list(Train_OH_Std)\n",
    "\n",
    "# Train & Validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20, random_state = 42,stratify=target)\n",
    "\n",
    "# Dataframe of prediction\n",
    "Prediction = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantitative Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "Quantitative = ['Fare','Age','Name_Length','Number_of_relatives']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Point Biserial Pearson Corr</th>\n",
       "      <th>Pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Name_Length</td>\n",
       "      <td>0.332350</td>\n",
       "      <td>2.026795e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.257307</td>\n",
       "      <td>6.120189e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>-0.059594</td>\n",
       "      <td>7.541267e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Number_of_relatives</td>\n",
       "      <td>0.016639</td>\n",
       "      <td>6.198911e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature  Point Biserial Pearson Corr          Pval\n",
       "2  Name_Length          0.332350                     2.026795e-24\n",
       "0  Fare                 0.257307                     6.120189e-15\n",
       "1  Age                 -0.059594                     7.541267e-02\n",
       "3  Number_of_relatives  0.016639                     6.198911e-01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>T Test Indep</th>\n",
       "      <th>Pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Name_Length</td>\n",
       "      <td>10.506602</td>\n",
       "      <td>2.026795e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fare</td>\n",
       "      <td>7.939192</td>\n",
       "      <td>6.120189e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>-1.780029</td>\n",
       "      <td>7.541267e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Number_of_relatives</td>\n",
       "      <td>0.496179</td>\n",
       "      <td>6.198911e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature  T Test Indep          Pval\n",
       "2  Name_Length          10.506602     2.026795e-24\n",
       "0  Fare                 7.939192      6.120189e-15\n",
       "1  Age                 -1.780029      7.541267e-02\n",
       "3  Number_of_relatives  0.496179      6.198911e-01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>Anova F value</th>\n",
       "      <th>Pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Name_Length</td>\n",
       "      <td>110.388690</td>\n",
       "      <td>2.026795e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fare</td>\n",
       "      <td>63.030764</td>\n",
       "      <td>6.120189e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>3.168504</td>\n",
       "      <td>7.541267e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Number_of_relatives</td>\n",
       "      <td>0.246193</td>\n",
       "      <td>6.198911e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature  Anova F value          Pval\n",
       "2  Name_Length          110.388690     2.026795e-24\n",
       "0  Fare                 63.030764      6.120189e-15\n",
       "1  Age                  3.168504       7.541267e-02\n",
       "3  Number_of_relatives  0.246193       6.198911e-01"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature</th>\n",
       "      <th>LDA Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Name_Length</td>\n",
       "      <td>0.880017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.682472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>-0.394781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Number_of_relatives</td>\n",
       "      <td>-0.407431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Feature  LDA Coef\n",
       "2  Name_Length          0.880017\n",
       "0  Fare                 0.682472\n",
       "1  Age                 -0.394781\n",
       "3  Number_of_relatives -0.407431"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concant data and target\n",
    "QF_Target = pd.concat([data[Quantitative],target],axis=1)\n",
    "Survived = QF_Target[QF_Target['Survived'] == 1]\n",
    "Died = QF_Target[QF_Target['Survived'] == 0]\n",
    "\n",
    "PointBiser = pd.DataFrame()\n",
    "TTest = pd.DataFrame()\n",
    "Anova = pd.DataFrame()\n",
    "Lda = pd.DataFrame() \n",
    "\n",
    "for var in enumerate(Quantitative) : \n",
    "    \n",
    "    # Point Biserial correlation\n",
    "    pb = stats.pointbiserialr(QF_Target['Survived'], QF_Target[var[1]])\n",
    "    PointBiser.loc[var[0],'Feature'] = var[1]\n",
    "    PointBiser.loc[var[0],'Point Biserial Pearson Corr'] = pb.correlation\n",
    "    PointBiser.loc[var[0],'Pval'] = pb.pvalue\n",
    "    PointBiser.sort_values('Pval',ascending=True,inplace=True)\n",
    "    \n",
    "    # T Test independance\n",
    "    t_test = stats.ttest_ind(Survived[var[1]], Died[var[1]])\n",
    "    TTest.loc[var[0],'Feature'] = var[1]\n",
    "    TTest.loc[var[0],'Student T Test Indep'] = t_test[0]\n",
    "    TTest.loc[var[0],'Pval'] = t_test[1]\n",
    "    TTest.sort_values('Pval',ascending=True,inplace=True)    \n",
    "    \n",
    "    # Anova\n",
    "    anova_one_way = stats.f_oneway(Survived[var[1]], Died[var[1]])\n",
    "    Anova.loc[var[0],'Feature'] = var[1]\n",
    "    Anova.loc[var[0],'Anova F value'] = anova_one_way[0]\n",
    "    Anova.loc[var[0],'Pval'] = anova_one_way[1]\n",
    "    Anova.sort_values('Pval',ascending=True,inplace=True)  \n",
    "    \n",
    "    # LDA\n",
    "    lda = LinearDiscriminantAnalysis(n_components = 2, solver='svd')\n",
    "    lda.fit(data[Quantitative], target)\n",
    "    Lda['Feature'] = Quantitative\n",
    "    Lda['LDA Coef'] = lda.coef_.transpose()\n",
    "    Lda.sort_values('LDA Coef',ascending=False,inplace=True)\n",
    "   \n",
    "\n",
    "display(PointBiser)\n",
    "display(TTest)\n",
    "display(Anova)\n",
    "display(Lda)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point Biserial Corr - Pearson Corr apply to nominal and continuous features:\n",
    "    - Very Small correlation for Age and Number_of_relatives with high p-values\n",
    "    - Positive correlation for Fare and Name_Length with very small p-value\n",
    "Student T Test Independance:\n",
    "    - We can reject mean independance for Name_Length and Fare\n",
    "    - We can say nothing about Age and Number_of_relatives as the value of the test is low and the p value high\n",
    "Anova - Test mean equality between survived and not survived :\n",
    "    - We can reject mean equality for Fare and Length\n",
    "    - We can say nothing about Age and Number_of_relatives\n",
    "LDA :\n",
    "    - Fare and Length have a positive and high coefficient\n",
    "    - Age and Number_of_relatives have a negative and smaller coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "MCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Qualitative = list(combined_One_Hot_Cat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "import scipy.stats as ss\n",
    "\n",
    "def Cramer_Chi2(crosstab):\n",
    "    n = crosstab.sum().sum()\n",
    "    chi2 = ss.chi2_contingency(confusion_matrix)[0]\n",
    "    pval = ss.chi2_contingency(confusion_matrix)[1]\n",
    "    CramerV = np.sqrt(chi2 / (n* (min(crosstab.shape) -1)))\n",
    "    return CramerV, chi2, pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pearson Phi</th>\n",
       "      <th>Cramer V</th>\n",
       "      <th>Test Chi 2 - Independance</th>\n",
       "      <th>Chi 2 Pval</th>\n",
       "      <th>Hamming Distance</th>\n",
       "      <th>Dice Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Sex_male</th>\n",
       "      <td>-0.543351</td>\n",
       "      <td>0.540936</td>\n",
       "      <td>260.717020</td>\n",
       "      <td>1.197357e-58</td>\n",
       "      <td>0.786756</td>\n",
       "      <td>0.762786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_aggr_Mr</th>\n",
       "      <td>-0.549199</td>\n",
       "      <td>0.546861</td>\n",
       "      <td>266.459805</td>\n",
       "      <td>6.706529e-60</td>\n",
       "      <td>0.782267</td>\n",
       "      <td>0.811409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass_3</th>\n",
       "      <td>-0.322308</td>\n",
       "      <td>0.319988</td>\n",
       "      <td>91.231792</td>\n",
       "      <td>1.277905e-21</td>\n",
       "      <td>0.667789</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Size_Family_Alone</th>\n",
       "      <td>-0.203367</td>\n",
       "      <td>0.201009</td>\n",
       "      <td>36.000514</td>\n",
       "      <td>1.972654e-09</td>\n",
       "      <td>0.620651</td>\n",
       "      <td>0.629124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>-0.155660</td>\n",
       "      <td>0.153082</td>\n",
       "      <td>20.879898</td>\n",
       "      <td>4.889994e-06</td>\n",
       "      <td>0.619529</td>\n",
       "      <td>0.559838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name_Size_Short</th>\n",
       "      <td>-0.193143</td>\n",
       "      <td>0.190552</td>\n",
       "      <td>32.352293</td>\n",
       "      <td>1.286054e-08</td>\n",
       "      <td>0.530864</td>\n",
       "      <td>0.808547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name_Size_Medium</th>\n",
       "      <td>-0.000867</td>\n",
       "      <td>0.001518</td>\n",
       "      <td>0.002053</td>\n",
       "      <td>9.638636e-01</td>\n",
       "      <td>0.529742</td>\n",
       "      <td>0.524444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Size_Family_Big</th>\n",
       "      <td>-0.125147</td>\n",
       "      <td>0.120612</td>\n",
       "      <td>12.961635</td>\n",
       "      <td>3.179394e-04</td>\n",
       "      <td>0.430976</td>\n",
       "      <td>0.950495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>0.003650</td>\n",
       "      <td>0.000456</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>9.891329e-01</td>\n",
       "      <td>0.402918</td>\n",
       "      <td>0.856802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass_2</th>\n",
       "      <td>0.093349</td>\n",
       "      <td>0.090498</td>\n",
       "      <td>7.297193</td>\n",
       "      <td>6.906244e-03</td>\n",
       "      <td>0.395062</td>\n",
       "      <td>0.669202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_aggr_Officer</th>\n",
       "      <td>-0.031316</td>\n",
       "      <td>0.023114</td>\n",
       "      <td>0.476021</td>\n",
       "      <td>4.902303e-01</td>\n",
       "      <td>0.392817</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_aggr_Royalty</th>\n",
       "      <td>0.033391</td>\n",
       "      <td>0.017944</td>\n",
       "      <td>0.286877</td>\n",
       "      <td>5.922286e-01</td>\n",
       "      <td>0.382716</td>\n",
       "      <td>0.982709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name_Size_Very Long</th>\n",
       "      <td>0.085083</td>\n",
       "      <td>0.067822</td>\n",
       "      <td>4.098452</td>\n",
       "      <td>4.292249e-02</td>\n",
       "      <td>0.379349</td>\n",
       "      <td>0.976879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_aggr_Master</th>\n",
       "      <td>0.085221</td>\n",
       "      <td>0.079648</td>\n",
       "      <td>5.652331</td>\n",
       "      <td>1.743218e-02</td>\n",
       "      <td>0.377104</td>\n",
       "      <td>0.879581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>0.174718</td>\n",
       "      <td>0.171781</td>\n",
       "      <td>26.292218</td>\n",
       "      <td>2.934688e-07</td>\n",
       "      <td>0.361392</td>\n",
       "      <td>0.628906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Size_Family_Small</th>\n",
       "      <td>0.279855</td>\n",
       "      <td>0.277396</td>\n",
       "      <td>68.561247</td>\n",
       "      <td>1.229976e-16</td>\n",
       "      <td>0.332211</td>\n",
       "      <td>0.466877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name_Size_Long</th>\n",
       "      <td>0.273448</td>\n",
       "      <td>0.269540</td>\n",
       "      <td>64.732768</td>\n",
       "      <td>8.577650e-16</td>\n",
       "      <td>0.327722</td>\n",
       "      <td>0.682243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass_1</th>\n",
       "      <td>0.285904</td>\n",
       "      <td>0.283211</td>\n",
       "      <td>71.465839</td>\n",
       "      <td>2.821002e-17</td>\n",
       "      <td>0.320988</td>\n",
       "      <td>0.512545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_aggr_Miss</th>\n",
       "      <td>0.332795</td>\n",
       "      <td>0.329945</td>\n",
       "      <td>96.997487</td>\n",
       "      <td>6.941537e-23</td>\n",
       "      <td>0.300786</td>\n",
       "      <td>0.509506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_aggr_Mrs</th>\n",
       "      <td>0.344935</td>\n",
       "      <td>0.341634</td>\n",
       "      <td>103.992178</td>\n",
       "      <td>2.031164e-24</td>\n",
       "      <td>0.299663</td>\n",
       "      <td>0.569296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_female</th>\n",
       "      <td>0.543351</td>\n",
       "      <td>0.540936</td>\n",
       "      <td>260.717020</td>\n",
       "      <td>1.197357e-58</td>\n",
       "      <td>0.213244</td>\n",
       "      <td>0.289634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Pearson Phi  Cramer V  Test Chi 2 - Independance  \\\n",
       "Sex_male            -0.543351     0.540936  260.717020                  \n",
       "Title_aggr_Mr       -0.549199     0.546861  266.459805                  \n",
       "Pclass_3            -0.322308     0.319988  91.231792                   \n",
       "Size_Family_Alone   -0.203367     0.201009  36.000514                   \n",
       "Embarked_S          -0.155660     0.153082  20.879898                   \n",
       "Name_Size_Short     -0.193143     0.190552  32.352293                   \n",
       "Name_Size_Medium    -0.000867     0.001518  0.002053                    \n",
       "Size_Family_Big     -0.125147     0.120612  12.961635                   \n",
       "Embarked_Q           0.003650     0.000456  0.000186                    \n",
       "Pclass_2             0.093349     0.090498  7.297193                    \n",
       "Title_aggr_Officer  -0.031316     0.023114  0.476021                    \n",
       "Title_aggr_Royalty   0.033391     0.017944  0.286877                    \n",
       "Name_Size_Very Long  0.085083     0.067822  4.098452                    \n",
       "Title_aggr_Master    0.085221     0.079648  5.652331                    \n",
       "Embarked_C           0.174718     0.171781  26.292218                   \n",
       "Size_Family_Small    0.279855     0.277396  68.561247                   \n",
       "Name_Size_Long       0.273448     0.269540  64.732768                   \n",
       "Pclass_1             0.285904     0.283211  71.465839                   \n",
       "Title_aggr_Miss      0.332795     0.329945  96.997487                   \n",
       "Title_aggr_Mrs       0.344935     0.341634  103.992178                  \n",
       "Sex_female           0.543351     0.540936  260.717020                  \n",
       "Survived             1.000000    NaN       NaN                          \n",
       "\n",
       "                       Chi 2 Pval  Hamming Distance  Dice Coefficient  \n",
       "Sex_male             1.197357e-58  0.786756          0.762786          \n",
       "Title_aggr_Mr        6.706529e-60  0.782267          0.811409          \n",
       "Pclass_3             1.277905e-21  0.667789          0.714286          \n",
       "Size_Family_Alone    1.972654e-09  0.620651          0.629124          \n",
       "Embarked_S           4.889994e-06  0.619529          0.559838          \n",
       "Name_Size_Short      1.286054e-08  0.530864          0.808547          \n",
       "Name_Size_Medium     9.638636e-01  0.529742          0.524444          \n",
       "Size_Family_Big      3.179394e-04  0.430976          0.950495          \n",
       "Embarked_Q           9.891329e-01  0.402918          0.856802          \n",
       "Pclass_2             6.906244e-03  0.395062          0.669202          \n",
       "Title_aggr_Officer   4.902303e-01  0.392817          0.972222          \n",
       "Title_aggr_Royalty   5.922286e-01  0.382716          0.982709          \n",
       "Name_Size_Very Long  4.292249e-02  0.379349          0.976879          \n",
       "Title_aggr_Master    1.743218e-02  0.377104          0.879581          \n",
       "Embarked_C           2.934688e-07  0.361392          0.628906          \n",
       "Size_Family_Small    1.229976e-16  0.332211          0.466877          \n",
       "Name_Size_Long       8.577650e-16  0.327722          0.682243          \n",
       "Pclass_1             2.821002e-17  0.320988          0.512545          \n",
       "Title_aggr_Miss      6.941537e-23  0.300786          0.509506          \n",
       "Title_aggr_Mrs       2.031164e-24  0.299663          0.569296          \n",
       "Sex_female           1.197357e-58  0.213244          0.289634          \n",
       "Survived            NaN           NaN               NaN                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concant data and target\n",
    "QF_OH_Target = pd.concat([data[Qualitative],target],axis=1)\n",
    "\n",
    "# Correlation with target\n",
    "confusion_matrix = pd.DataFrame()\n",
    "Corr = pd.DataFrame()\n",
    "\n",
    "Corr['Pearson Phi'] = QF_OH_Target.corr(method='pearson')[\"Survived\"]\n",
    "\n",
    "for var in enumerate(Qualitative) : \n",
    "    confusion_matrix = pd.crosstab(QF_OH_Target['Survived'], QF_OH_Target[var[1]])\n",
    "    Corr.loc[var[1],'Cramer V'] = Cramer_Chi2(confusion_matrix)[0]\n",
    "    Corr.loc[var[1],'Test Chi 2 - Independance'] = Cramer_Chi2(confusion_matrix)[1]\n",
    "    Corr.loc[var[1],'Chi 2 Pval']= Cramer_Chi2(confusion_matrix)[2]\n",
    "    Corr.loc[var[1],'Hamming Distance'] = distance.hamming(QF_OH_Target['Survived'].astype(int), QF_OH_Target[var[1]].astype(int))\n",
    "    Corr.loc[var[1],'Dice Coefficient'] = distance.dice(QF_OH_Target['Survived'].astype(int), QF_OH_Target[var[1]].astype(int))\n",
    "    \n",
    "Corr.sort_values('Hamming Distance',ascending=False,inplace=True)\n",
    "display(Corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pearson Phi :\n",
    "    - Very small correlation :\n",
    "        - Pclass_2\n",
    "        - Title_aggr_Master\n",
    "        - Name_Size_Very Long\n",
    "        - Title_aggr_Royalty\n",
    "        - Embarked_Q\n",
    "        - Name_Size_Medium\n",
    "    - High Correlation\n",
    "        - Positive: \n",
    "            - Sex_female\n",
    "            - Title_aggr_Mrs\n",
    "            - Title_aggr_Miss\n",
    "            - Pclass_1\n",
    "            - Size_Family_Small\n",
    "            - Name_Size_Long\n",
    "        - Negative: \n",
    "            - Sex_male\n",
    "            - Pclass_3\n",
    "        \n",
    "Chi 2 Independance and Cramer V:\n",
    "    - We can reject independance and the Cramer Corelation if high for:\n",
    "        - Title_aggr_Mr \n",
    "        - Sex_female \n",
    "        - Sex_male\n",
    "        --> The information of this 3 features is mostly the same\n",
    "    - We can reject independance and the Cramer Correlation is medium for :\n",
    "        - Title_aggr_Mrs \n",
    "        - Title_aggr_Miss \n",
    "        - Pclass_3\n",
    "        - Pclass_1\n",
    "        - Size_Family_Small\n",
    "        - Name_Size_Long\n",
    "        - Size_Family_Alone\n",
    "        - Name_Size_Short\n",
    "    - We can reject independance but the Cramer Correlation is low\n",
    "        - Embarked_C\n",
    "        - Embarked_S\n",
    "        - Size_Family_Big\n",
    "    - At 5 % we can't reject independance and the Cramer Correlation if very small:\n",
    "        - Name_Size_Very Long\n",
    "        - Title_aggr_Officer\n",
    "        - Title_aggr_Royalty\n",
    "        - Name_Size_Medium\n",
    "        - Embarked_Q \n",
    "        \n",
    "Hamming distance - Tell us about the numbers of difference :\n",
    "    - High distance\n",
    "        - Sex_male\n",
    "        - Title_aggr_Mr \n",
    "        - Pclass_3\n",
    "        - Size_Family_Alone\n",
    "        - Embarked_S\n",
    "    - Medium\n",
    "        - Name_Size_Short\n",
    "        - Name_Size_Medium\n",
    "        - Size_Family_Big\n",
    "        - Embarked_Q\n",
    "        - Pclass_2\n",
    "        - Title_aggr_Officer\n",
    "        - Title_aggr_Royalty\n",
    "        - Name_Size_Very Long \n",
    "        - Title_aggr_Master\n",
    "        - Embarked_C\n",
    "    - Small distance\n",
    "        - Size_Family_Small\n",
    "        - Name_Size_Long\n",
    "        - Pclass_1\n",
    "        - Title_aggr_Miss\n",
    "        - Title_aggr_Mrs\n",
    "        - Sex_female\n",
    "   \n",
    "Dice - Tell us about how much disjoint (0) or equal(1):\n",
    "    - Mostly disjoint\n",
    "        - Sex_female\n",
    "    - Medium\n",
    "        - Size_Family_Alone\n",
    "        - Embarked_C\n",
    "        - Title_aggr_Mrs\n",
    "        - Embarked_S\n",
    "        - Name_Size_Medium\n",
    "        - Pclass_1\n",
    "        - Title_aggr_Miss\n",
    "        - Size_Family_Small\n",
    "    - Mostly joint:\n",
    "        - Title_aggr_Royalty\n",
    "        - Name_Size_Very Long\n",
    "        - Title_aggr_Officer\n",
    "        - Size_Family_Big\n",
    "        - Title_aggr_Master\n",
    "        - Embarked_Q\n",
    "        - Title_aggr_Mr\n",
    "        - Name_Size_Short\n",
    "        - Sex_male\n",
    "        - Pclass_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note about 2 test, Cramer V and p-value :\n",
    "The p-value you got comes from the 2 test. It tells you the probability of getting a 2 statistic as extreme or more extreme than yours if the null hypothesis is true. It tells you nothing about how big the effect is.\n",
    "On the other hand, Cramer's V is a measure of effect size. It tells you how big the effect is. It tells you nothing about whether or not the effect is 'significant'. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(data.shape)\n",
    "display(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data.drop(['Title_aggr_Royalty','Title_aggr_Officer','Name_Size_Medium','Embarked_Q'],axis=1,inplace=True)\n",
    "test_data.drop(['Title_aggr_Royalty','Title_aggr_Officer','Name_Size_Medium','Embarked_Q'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(data.shape)\n",
    "display(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper function to analyse and get result\n",
    "\n",
    "\"\"\" \n",
    "========================\n",
    "Grid Score into a Pandas Dataframe\n",
    "========================\n",
    "\"\"\"\n",
    "def cv_results_to_df(cv_results):\n",
    "    \"\"\"\n",
    "    Convert a sklearn.model_selection.GridSearchCV.cv_results_ attribute to a tidy\n",
    "    pandas DataFrame where the output is filtered with only mean std and params, and sorted by mean test\n",
    "    \"\"\"\n",
    "    df=pd.DataFrame.from_dict(cv_results)\n",
    "    df=df[['mean_test_score', 'std_test_score', 'mean_train_score', 'std_train_score', 'params']]\n",
    "    df.sort_values('mean_test_score',ascending=False,inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "========================\n",
    "Plot confusion matrix \n",
    "========================\n",
    "\"\"\"\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "\n",
    "\"\"\" \n",
    "========================\n",
    "Helper function for GridSearch\n",
    "========================\n",
    "\"\"\"    \n",
    "def grid_search_global(dict_pip, dict_param, class_names, X_train, y_train, X_test, y_test, verbose = 2):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function help doing GridSearch with multiples pipelines of estimators and parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creation of the return objects\n",
    "    dict_of_res={}\n",
    "    dict_of_best={}\n",
    "    df_results_global=pd.DataFrame()\n",
    "    \n",
    "    print (\"Starting Gridsearch\")\n",
    "    \n",
    "    for key in dict_param.keys():\n",
    "        gs = GridSearchCV(dict_pip[key], dict_param[key], verbose=0, refit=True, n_jobs=-1, cv=5)\n",
    "        gs = gs.fit(X_train, y_train)\n",
    "        dict_of_res[key]=gs.grid_scores_\n",
    "        \n",
    "        # Prediction and scores for the evaluation set\n",
    "        y_test_pred=gs.predict(X_test)\n",
    "        validation_acc = accuracy_score(y_test,y_test_pred)\n",
    "        validation_Fscore = f1_score(y_test,y_test_pred)\n",
    "        confusion_mat = confusion_matrix(y_test,y_test_pred)\n",
    "        precission = precision_score(y_test,y_test_pred)\n",
    "        recall = recall_score(y_test,y_test_pred)\n",
    "        \n",
    "        # Saving of the results\n",
    "        df_results=cv_results_to_df(gs.cv_results_)\n",
    "        df_results['estimator'] = key\n",
    "        df_results['val_score'] = validation_acc\n",
    "        df_results['val_F_score'] = validation_Fscore\n",
    "        df_results['val_Precis'] = precission\n",
    "        df_results['val_Recall'] = recall\n",
    "        df_results['val_Confusion'] = str(confusion_mat)\n",
    "        df_results['|test-train|']=  np.absolute (df_results['mean_train_score'] - df_results['mean_test_score']) \n",
    "        df_results['|val-test|']= np.absolute(df_results['mean_test_score'] - df_results['val_score'])\n",
    "        \n",
    "        \n",
    "        df_results=df_results[['estimator','val_score','mean_test_score', 'mean_train_score', 'std_test_score', 'std_train_score',\n",
    "                               '|val-test|','|test-train|','val_F_score','val_Precis','val_Recall','val_Confusion', 'params']]\n",
    "        df_results_global=df_results_global.append(df_results)\n",
    "        \n",
    "        dict_of_best[key]=[gs.best_score_,gs.best_params_]\n",
    "        \n",
    "        # Display intermediate results\n",
    "        if (verbose > 1) :\n",
    "            print('\\n-------------------------------------------------------------------------------------------------------')\n",
    "            print (\"Gridsearch for \\n   estimator : %s \\n   parameters : %s \\n\" % (key,dict_param[key]))\n",
    "            print (\"Best mean_test_score :\", gs.best_score_)\n",
    "            print (\"Best params :\",gs.best_params_)\n",
    "            print(\"\\nResults for the pipeline \")\n",
    "            display(df_results)\n",
    "        \n",
    "    # Transfrom dict_of_best intro a Dataframe\n",
    "    df_best=pd.DataFrame.from_dict(dict_of_best,'index')\n",
    "    df_best.columns=['Scores','Parameters']\n",
    "    df_best.sort_values('Scores',ascending=False,inplace=True) \n",
    "    \n",
    "    # Sort the Dataframe of golbal results\n",
    "    df_results_global.sort_values('val_score',ascending=False,inplace=True)\n",
    " \n",
    "    # Display final results\n",
    "    if (verbose > 0) :   \n",
    "        print('\\n -------------------------------------------------------------------------------------------------------')\n",
    "        print('\\nList of best score and parameters by pipeline')\n",
    "        display(df_best)\n",
    "        print('\\nSummary')\n",
    "        display(df_results_global) \n",
    "        print('\\n -------------------------------------------------------------------------------------------------------')  \n",
    "    print (\"Gridsearch Finished\")\n",
    "    return df_best, dict_of_best, df_results_global\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "========================\n",
    "Plotting Learning Curves - From scikit learn example\n",
    "========================\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(0.7, 1)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "========================\n",
    "Plotting Validation Curves \n",
    "========================\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "def plot_validation_curve(estimator, estimator_name, param_name, param_range, X, y, cv,\n",
    "    scoring='accuracy', scale='classic' , n_jobs=-1):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate a simple plot of the validation learning curve.\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "    estimator_name : name of the estimator.\n",
    "    param_range : range of parameters to try.\n",
    "    scoring : scoring metric to use.\n",
    "    scale : classic or semi log scale\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "    cv : int, cross-validation generator or an iterable\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default -1).\n",
    "    \"\"\"\n",
    "    \n",
    "    train_scores, test_scores = validation_curve(\n",
    "        estimator, X, y, param_name=param_name, param_range=param_range,\n",
    "        cv=cv, scoring=scoring, n_jobs=n_jobs)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    title_fig='Validation Curve with %s' % estimator_name\n",
    "    plt.title(title_fig)\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(\"Score : %s\" % scoring)\n",
    "    plt.ylim(0.7, 1)\n",
    "    lw = 2\n",
    "    \n",
    "    if (scale=='semilog'):\n",
    "        plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "                     color=\"darkorange\", lw=lw)\n",
    "        plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                         color=\"darkorange\", lw=lw)\n",
    "        plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                     color=\"navy\", lw=lw)\n",
    "        plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                         color=\"navy\", lw=lw)\n",
    "    else :\n",
    "        plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
    "                     color=\"darkorange\", lw=lw)\n",
    "        plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                         color=\"darkorange\", lw=lw)\n",
    "        plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                     color=\"navy\", lw=lw)\n",
    "        plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                         color=\"navy\", lw=lw) \n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multipe Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train & Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20,random_state = 6725,stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pipeline setup\n",
    "models = { \n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'SVC': SVC()\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params = {\n",
    "    'RandomForestClassifier': { 'n_estimators': [5, 10, 15, 20, 25, 30, 35] },\n",
    "    'GradientBoostingClassifier': { 'n_estimators': [5, 10, 15, 20, 25, 30, 35], 'learning_rate': [0.8, 1.0] },\n",
    "    'SVC': [\n",
    "        {'kernel': ['linear'], 'C': [1, 10]},\n",
    "        {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Start grid search\n",
    "df_best, dic_best, d_res = grid_search_global(dict_pip = models, dict_param = params, class_names = columns_name,\n",
    "                                            X_train = X_train ,y_train = y_train, X_test = X_test, y_test = y_test,\n",
    "                                            verbose = 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train & Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20,random_state = 6725,stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pipeline setup\n",
    "models = { \n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params_quick = {\n",
    "    'GradientBoostingClassifier': {'n_estimators': [5, 10, 15, 20], \n",
    "                                   'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "                                   'loss' : ['deviance', 'exponential'],\n",
    "                                   'max_depth' : [3, 5, 7, 10],\n",
    "                                   'min_samples_split': [3, 5, 7],\n",
    "                                   'min_samples_leaf' : [3, 5, 7],\n",
    "                                   'max_features' : [2, 4, 6, 8, 10]\n",
    "                                  }\n",
    "}\n",
    "\n",
    "params_full = {\n",
    "    'GradientBoostingClassifier': { 'n_estimators': range(1,20,1), \n",
    "                                   'learning_rate': [0.05,0.08,0.10,0.12,0.14,0.16],\n",
    "                                  'loss' : ['deviance','exponential'],\n",
    "                                  'max_depth' : range(2,4),\n",
    "                                   'min_samples_split': range(2,10,1),\n",
    "                                   'min_samples_leaf' : range(2,10,1),\n",
    "                                   'max_features' : range(1,15,1)\n",
    "                                  }\n",
    "}\n",
    "\n",
    "params = params_quick\n",
    "\n",
    "# Start grid search\n",
    "df_best_gbc, dic_best_gbc, d_res_gbc = grid_search_global(dict_pip = models, dict_param = params, class_names = columns_name,\n",
    "                                            X_train = X_train ,y_train = y_train, X_test = X_test, y_test = y_test,\n",
    "                                            verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter results\n",
    "d_res_gbc.sort_values(by=['val_score','std_test_score'],ascending=[False,True],inplace=True)\n",
    "d_res_gbc_sort = d_res_gbc.loc[(d_res_gbc['val_score'] > 0.80) \n",
    "              & (d_res_gbc['|val-test|'] < 0.015) \n",
    "              & (d_res_gbc['|test-train|'] < 0.015)  \n",
    "              & (d_res_gbc['std_test_score'] < 0.015) \n",
    "              & (d_res_gbc['std_train_score'] < 0.015)]\n",
    "display(d_res_gbc_sort)\n",
    "\n",
    "# Take care not to search for too small values because it will certainly lead to overfitting our split of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selection of the parameters to study\n",
    "index_selection_gbc = [177, 130, 106, 63, 87, 86]\n",
    "df_study_gbc = d_res_gbc.loc[index_selection_gbc,['estimator','params','val_score','mean_test_score','mean_train_score','val_F_score']]\n",
    "display(df_study_gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Learning curve\n",
    "index = list(df_study_gbc.index)\n",
    "for ind in index :\n",
    "    estim = df_study_gbc.loc[ind, 'estimator']\n",
    "    params = df_study_gbc.loc[ind, 'params']\n",
    "    val_score = df_study_gbc.loc[ind, 'val_score']\n",
    "    mean_test = df_study_gbc.loc[ind, 'mean_test_score']\n",
    "    mean_train = df_study_gbc.loc[ind, 'mean_train_score']\n",
    "    title = \"Learning Curves for the estimator %s which results are \\n mean test: %s \\n mean train: %s \\n val_score : %s \\n with parameters %s)\" % (estim,mean_test,mean_train,val_score,params)\n",
    "    cv = ShuffleSplit(n_splits=50, test_size=0.2, random_state=0)\n",
    "    estimator = models[estim]\n",
    "    estimator.set_params(**params)\n",
    "    plot_learning_curve(estimator, title, data, target, (0.3, 1.01), cv=cv, n_jobs=-1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validation curve\n",
    "dict_Validation = { \n",
    "    'GradientBoostingClassifier':  { 'n_estimators': range(5,100,5), \n",
    "                                     'learning_rate': [0.01,0.03,0.1,0.2,0.3,0.4,0.5,0.6,0.7],\n",
    "                                     'max_depth' : range(2,10,1),\n",
    "                                     'min_samples_split': range(2,10,1),\n",
    "                                     'min_samples_leaf' : range(2,10,1),\n",
    "                                     'max_features' : range(2,19,1)\n",
    "                                  } \n",
    "}\n",
    "\n",
    "for ind in index :\n",
    "    \n",
    "    estim = df_study_gbc.loc[ind, 'estimator']\n",
    "    params = df_study_gbc.loc[ind, 'params']\n",
    "    mean_test = df_study_gbc.loc[ind, 'mean_test_score']\n",
    "    mean_train = df_study_gbc.loc[ind, 'mean_train_score']\n",
    "    val_score = df_study_gbc.loc[ind, 'val_score']\n",
    "    \n",
    "    print(\"Model: %s\\nMean test: %s\\nMean train: %s\\nVal score: %s \\nParams: %s\" % (estim,mean_test,mean_train,val_score,params))\n",
    "    \n",
    "    estimator = models[estim]\n",
    "    estimator.set_params(**params)\n",
    "    \n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "    \n",
    "    for key, value in dict_Validation[estim].items():\n",
    "        plot_validation_curve(estimator, estim, key, value, X_train, y_train, scoring='accuracy', cv=cv)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prediction \n",
    "GBC_params =  {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3, 'max_features': 4, 'min_samples_leaf': 7, 'min_samples_split': 7, 'n_estimators': 10}\n",
    "gbc = GradientBoostingClassifier(**GBC_params)\n",
    "gbc.fit(X_train,y_train)\n",
    "gbc_pred = gbc.predict(test_data)\n",
    "Prediction['GBC'] = gbc_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train & Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20,random_state = 6725,stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pipeline setup\n",
    "models = { \n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params_quick = {\n",
    "    'RandomForestClassifier': { 'n_estimators': [5,10,15,20,30,100],\n",
    "                               'criterion' : ['gini','entropy'],\n",
    "                               'max_depth' : [3,5,8,10,15,20],\n",
    "                               'max_features':[2,4,6,8],\n",
    "                               'min_samples_split': [3,5,7],\n",
    "                               'min_samples_leaf':  [3,5,7]\n",
    "                              }\n",
    "}\n",
    "\n",
    "params_full = {\n",
    "    'RandomForestClassifier': { 'n_estimators': range(1,20,1),\n",
    "                               'criterion' : ['gini','entropy'],\n",
    "                               'max_features':range(1,20,1),\n",
    "                               'max_depth' : range(3,10,1),\n",
    "                               'min_samples_split': range(2,10,1),\n",
    "                               'min_samples_leaf':  range(1,10,1)\n",
    "                              }\n",
    "}\n",
    "\n",
    "params = params_quick\n",
    "\n",
    "# Lancer la grid search\n",
    "df_best_rf, dic_best_rf, d_res_rf = grid_search_global(dict_pip = models, dict_param = params, class_names = columns_name,\n",
    "                                            X_train = X_train ,y_train = y_train, X_test = X_test, y_test = y_test,\n",
    "                                            verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter results\n",
    "d_res_rf.sort_values(by=['val_score','std_test_score'],ascending=[False,True],inplace=True)\n",
    "d_res_rf_sort = d_res_rf.loc[(d_res_rf['val_score'] > 0.80) \n",
    "              & (d_res_rf['|val-test|'] < 0.015) \n",
    "              & (d_res_rf['|test-train|'] < 0.015)  \n",
    "              & (d_res_rf['std_test_score'] < 0.015) \n",
    "              & (d_res_rf['std_train_score'] < 0.015)]\n",
    "display(d_res_rf_sort)\n",
    "\n",
    "# Take care not to search for too small values because it will certainly lead to overfitting our split of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Selection of the parameters to study\n",
    "index_selection_rf = [177, 130, 106, 63, 87, 86]\n",
    "df_study_rf = d_res_rf.loc[index_selection_rf,['estimator','params','val_score','mean_test_score','mean_train_score','val_F_score']]\n",
    "display(df_study_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Learning curve\n",
    "index = list(df_study_rf.index)\n",
    "for ind in index :\n",
    "    estim = df_study_rf.loc[ind, 'estimator']\n",
    "    params = df_study_rf.loc[ind, 'params']\n",
    "    val_score = df_study_rf.loc[ind, 'val_score']\n",
    "    mean_test = df_study_rf.loc[ind, 'mean_test_score']\n",
    "    mean_train = df_study_rf.loc[ind, 'mean_train_score']\n",
    "    title = \"Learning Curves for the estimator %s which results are \\n mean test: %s \\n mean train: %s \\n val_score : %s \\n with parameters %s)\" % (estim,mean_test,mean_train,val_score,params)\n",
    "    cv = ShuffleSplit(n_splits=50, test_size=0.2, random_state=0)\n",
    "    estimator = models[estim]\n",
    "    estimator.set_params(**params)\n",
    "    plot_learning_curve(estimator, title, data, target, (0.3, 1.01), cv=cv, n_jobs=-1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Validation curve\n",
    "dict_Validation = { \n",
    "    'RandomForestClassifier': {'n_estimators': range(1,50,2),\n",
    "                               'max_features':range(1,20,1),\n",
    "                               'min_samples_split': range(2,10,1),\n",
    "                               'min_samples_leaf': range(2,10,1)}  \n",
    "}\n",
    "\n",
    "for ind in index :\n",
    "    \n",
    "    estim = df_study_rf.loc[ind, 'estimator']\n",
    "    params = df_study_rf.loc[ind, 'params']\n",
    "    mean_test = df_study_rf.loc[ind, 'mean_test_score']\n",
    "    mean_train = df_study_rf.loc[ind, 'mean_train_score']\n",
    "    val_score = df_study_rf.loc[ind, 'val_score']\n",
    "    \n",
    "    print(\"Model: %s\\nMean test: %s\\nMean train: %s\\nVal score: %s \\nParams: %s\" % (estim,mean_test,mean_train,val_score,params))\n",
    "    \n",
    "    estimator = models[estim]\n",
    "    estimator.set_params(**params)\n",
    "    \n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "    \n",
    "    for key, value in dict_Validation[estim].items():\n",
    "        plot_validation_curve(estimator, estim, key, value, X_train, y_train, scoring='accuracy', cv=cv)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prediction \n",
    "RF_params =  {'criterion': 'entropy', 'max_features': 12, 'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 10}\n",
    "rf = RandomForestClassifier(**RF_params)\n",
    "rf.fit(X_train,y_train)\n",
    "rf_pred = rf.predict(test_data)\n",
    "Prediction['RF'] = rf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get and display feature importance for Random Forest model with parameters from behind\n",
    "Rf_feat_imp = pd.DataFrame()\n",
    "Rf_feat_imp['Feature'] = list(data.columns)\n",
    "Rf_feat_imp['Importance'] = rf.feature_importances_\n",
    "Rf_feat_imp.sort_values('Importance',ascending=False,inplace=True)\n",
    "display(Rf_feat_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train & Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20,random_state = 6725,stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pipeline setup\n",
    "models = { \n",
    "    'SVC': SVC()\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params = {\n",
    "    'SVC': [\n",
    "        {'kernel': ['poly'], \n",
    "             'C': [0.03,0.1,0.3,1,3,10,30], \n",
    "             'gamma': ['auto',0.03,0.1,0.3,1,3,10,30],\n",
    "             'degree': range(1,5)},\n",
    "        {'kernel': ['rbf'], \n",
    "             'C': [0.03,0.1,0.3,1,3,10,30], \n",
    "             'gamma': ['auto',0.03,0.1,0.3,1,3,10,30]},\n",
    "        {'kernel': ['linear'], \n",
    "             'C': [0.03,0.1,0.3,1,3,10,30]}\n",
    "    ]\n",
    "\n",
    "}\n",
    "\n",
    "# Start grid search\n",
    "df_best_svc , dic_best_svc, d_res_svc = grid_search_global(dict_pip = models, dict_param = params, class_names = columns_name,\n",
    "                                            X_train = X_train ,y_train = y_train, X_test = X_test, y_test = y_test,\n",
    "                                            verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter results\n",
    "d_res_svc.sort_values(by=['val_score','std_test_score'],ascending=[False,True],inplace=True)\n",
    "d_res_svc_sort = d_res_svc.loc[(d_res_svc['val_score'] > 0.80) \n",
    "              & (d_res_svc['|val-test|'] < 0.015) \n",
    "              & (d_res_svc['|test-train|'] < 0.015)  \n",
    "              & (d_res_svc['std_test_score'] < 0.015) \n",
    "              & (d_res_svc['std_train_score'] < 0.015)]\n",
    "display(d_res_svc_sort)\n",
    "\n",
    "# Take care not to search for too small values because it will certainly lead to overfit to the split of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Selection of the parameters to study\n",
    "index_selection_svc = [177, 130, 106, 63, 87, 86]\n",
    "df_study_svc = d_res_svc.loc[index_selection_svc,['estimator','params','val_score','mean_test_score','mean_train_score','val_F_score']]\n",
    "display(df_study_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Learning curve\n",
    "index = list(df_study_svc.index)\n",
    "for ind in index :\n",
    "    estim = df_study_svc.loc[ind, 'estimator']\n",
    "    params = df_study_svc.loc[ind, 'params']\n",
    "    val_score = df_study_svc.loc[ind, 'val_score']\n",
    "    mean_test = df_study_svc.loc[ind, 'mean_test_score']\n",
    "    mean_train = df_study_svc.loc[ind, 'mean_train_score']\n",
    "    title = \"Learning Curves for the estimator %s which results are \\n mean test: %s \\n mean train: %s \\n val_score : %s \\n with parameters %s)\" % (estim,mean_test,mean_train,val_score,params)\n",
    "    cv = ShuffleSplit(n_splits=50, test_size=0.2, random_state=0)\n",
    "    estimator = models[estim]\n",
    "    estimator.set_params(**params)\n",
    "    plot_learning_curve(estimator, title, data, target, (0.3, 1.01), cv=cv, n_jobs=-1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Validation curve\n",
    "dict_Validation = { \n",
    "    'SVC': { 'C': np.linspace(0.01,10,25),\n",
    "              'gamma': np.linspace(0.01,1,25),\n",
    "              'degree': range(2,5)}  \n",
    "    }\n",
    "\n",
    "\n",
    "for ind in index :\n",
    "    \n",
    "    estim = df_study_svc.loc[ind, 'estimator']\n",
    "    params = df_study_svc.loc[ind, 'params']\n",
    "    mean_test = df_study_svc.loc[ind, 'mean_test_score']\n",
    "    mean_train = df_study_svc.loc[ind, 'mean_train_score']\n",
    "    val_score = df_study_svc.loc[ind, 'val_score']\n",
    "    \n",
    "    print(\"Model: %s\\nMean test: %s\\nMean train: %s\\nVal score: %s \\nParams: %s\" % (estim,mean_test,mean_train,val_score,params))\n",
    "    \n",
    "    estimator = models[estim]\n",
    "    estimator.set_params(**params)\n",
    "    \n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "    \n",
    "    for key, value in dict_Validation[estim].items():\n",
    "        plot_validation_curve(estimator, estim, key, value, X_train, y_train, scoring='accuracy', cv=cv)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "svc_params = {'C': 0.8, 'degree': 2, 'gamma': 0.08, 'kernel': 'poly'}\n",
    "svc = SVC(**svc_params)\n",
    "svc.fit(data,target)\n",
    "svc_pred = svc.predict(test_data)\n",
    "Prediction['SVC'] = svc_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train & Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20,random_state = 6725,stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Classifier default parameters\n",
    "svc = SVC(probability=True)\n",
    "rfc = RandomForestClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Classifier Tunep parameters\n",
    "GBC_params = {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3, 'max_features': 10, 'min_samples_leaf': 7, 'min_samples_split': 5, 'n_estimators': 10}\n",
    "RF_params =  {'criterion': 'entropy', 'max_features': 4, 'min_samples_leaf': 8, 'min_samples_split': 9, 'n_estimators': 11}\n",
    "SVC_params = {'probability'= True}\n",
    "\n",
    "rfc_tp = RandomForestClassifier(**RF_params)\n",
    "gbc_tp = GradientBoostingClassifier(**GBC_params)\n",
    "svc_tp = SVC(**SVC_params)\n",
    "\n",
    "# Pipeline setup\n",
    "# Estimators must be filled during the creation of the classifier\n",
    "models = { \n",
    "    'VotingClassifier': VotingClassifier(estimators= [('svc_tp', svc_tp),('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)])\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params = {'VotingClassifier' : {'voting': ['soft','hard'] ,\n",
    "                                'estimators' : [\n",
    "                                    [('svc_tp', svc_tp),('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)],\n",
    "                                    [('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)],\n",
    "                                    [('svc', svc),('rfc', rfc), ('gbc', gbc)],\n",
    "                                    [('rfc', rfc), ('gbc', gbc)]\n",
    "                                    ]                   \n",
    "                               }\n",
    " }\n",
    "\n",
    "# Start grid search\n",
    "df_best_vc , dic_best_vc, d_res_vc = grid_search_global(dict_pip = models, dict_param = params, class_names = columns_name,\n",
    "                                            X_train = X_train ,y_train = y_train, X_test = X_test, y_test = y_test,\n",
    "                                            verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "GBC_params = {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3, 'max_features': 10, 'min_samples_leaf': 7, 'min_samples_split': 5, 'n_estimators': 10}\n",
    "RF_params =  {'criterion': 'entropy', 'max_features': 4, 'min_samples_leaf': 8, 'min_samples_split': 9, 'n_estimators': 11}\n",
    "SVC_params = {'probability'= True,}\n",
    "\n",
    "rfc_tp = RandomForestClassifier(**RF_params)\n",
    "gbc_tp = GradientBoostingClassifier(**GBC_params)\n",
    "svc_tp = SVC(**SVC_params)\n",
    "\n",
    "VC_tp_soft = VotingClassifier(estimators=[('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)],   \n",
    "                                         voting='soft')\n",
    "VC_tp_soft.fit(X_train,y_train)\n",
    "Prediction['VC_tp_soft'] = VC_tp_soft.predict(Eval_OH_Std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose the prediction to submit \n",
    "#Predic = Prediction['GBC']\n",
    "#Predic = Prediction['RF']\n",
    "Predic = Prediction['SVC']\n",
    "#Predic = Prediction['VC_tp_soft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save into a csv to submit\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": PassengerId,\n",
    "        \"Survived\": Predic\n",
    "    })\n",
    "submission.to_csv('titanic_SVC.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " ### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.79-0.81 with PassId_0.81 and without ticket and cabin and dropping 'Title_aggr_Royalty','Title_aggr_Officer','Name_Size_Medium','Embarked_Q'\n",
    "GBC_params = {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3, 'max_features': 10, 'min_samples_leaf': 7, 'min_samples_split': 6, 'n_estimators': 10}\n",
    "# 0.80 same conditions\n",
    "RF_params =  {'criterion': 'entropy', 'max_features': 10, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 30}\n",
    "#0.79\n",
    "VotingClassifier(estimators=[('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)],voting='soft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save X_train and y_train that generalize well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pass_Id = list(X_train.index)\n",
    "Pass_Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Res_gbc  =pd.DataFrame()\n",
    "Res_rf  =pd.DataFrame()\n",
    "\n",
    "for i in range(1,100) :\n",
    "    print('Step',i)\n",
    "    RS = np.random.randint(10000)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20,random_state = RS,stratify=target)\n",
    "\n",
    "    # Pipeline setup\n",
    "    model_gbc = { \n",
    "        'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    }\n",
    "\n",
    "    # Parameters setup\n",
    "    params_gbc = {\n",
    "        'GradientBoostingClassifier': { 'n_estimators': [5,10,15,20], \n",
    "                                       'learning_rate': [0.05,0.1,0.2],\n",
    "                                      'loss' : ['deviance','exponential'],\n",
    "                                      'max_depth' : [3],\n",
    "                                       'min_samples_split': [3,5,7],\n",
    "                                       'min_samples_leaf' : [3,5,7],\n",
    "                                       'max_features' : [2,4,6,8,10]\n",
    "                                      }\n",
    "    }\n",
    "\n",
    "    # Lancer la grid search\n",
    "    df_best_gbc, dic_best_gbc, d_res_gbc =grid_search_global(model_gbc,params_gbc,class_names=columns_name)\n",
    "\n",
    "    model_rf = { \n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    }\n",
    "\n",
    "    # Parameters setup\n",
    "    params_rf = {\n",
    "    # Il faut mettre 'ExtraTreesClassifier__n_estimators' dans 'ExtraTreesClassifier' car on est sur un pipeline \n",
    "    # il est donc possible de prciser des parametres pour chacune des tapes\n",
    "    'RandomForestClassifier': { 'n_estimators': [5,10,15,20,30],\n",
    "                               'criterion' : ['gini','entropy'],\n",
    "                               'max_depth' : [3,9,15,30],\n",
    "                               'max_features':[2,4,6,8],\n",
    "                               'min_samples_split': [3,5,7],\n",
    "                               'min_samples_leaf':  [3,5,7]\n",
    "                              }\n",
    "    }\n",
    "\n",
    "    # Lancer la grid search\n",
    "    df_best_rf, dic_best_rf, d_res_rf =grid_search_global(model_rf,params_rf,class_names=columns_name)\n",
    "\n",
    "    # Results dataframe\n",
    "    d_res_gbc['Random_state'] = RS\n",
    "    d_res_gbc.sort_values(by=['Val_Acc','std_test_score'],ascending=[False,True],inplace=True)\n",
    "    d_res_gbc_sort = d_res_gbc.loc[(d_res_gbc['Val_Acc'] > 0.80) \n",
    "                  & (d_res_gbc['Diff_test_val'] < 0.01) \n",
    "                  & (d_res_gbc['Diff_train_test'] < 0.01)  \n",
    "                  & (d_res_gbc['std_test_score'] < 0.01) \n",
    "                  & (d_res_gbc['std_train_score'] < 0.01)]\n",
    "    Res_gbc = Res_gbc.append(d_res_gbc_sort)\n",
    "    \n",
    "    # Results dataframe\n",
    "    d_res_rf['Random_state'] = RS\n",
    "    d_res_rf.sort_values(by=['Val_Acc','std_test_score'],ascending=[False,True],inplace=True)\n",
    "    d_res_rf_sort = d_res_rf.loc[(d_res_rf['Val_Acc'] > 0.80) \n",
    "                  & (d_res_rf['Diff_test_val'] < 0.01) \n",
    "                  & (d_res_rf['Diff_train_test'] < 0.01)  \n",
    "                  & (d_res_rf['std_test_score'] < 0.01) \n",
    "                  & (d_res_rf['std_train_score'] < 0.01)]\n",
    "    Res_rf = Res_rf.append(d_res_rf_sort)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GradientBoostingClassifier : {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3, 'max_features': 16, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 20}\t0.839888\t0.851827\n",
    "GradientBoostingClassifier : {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3, 'max_features': 16, 'min_samples_leaf': 7, 'min_samples_split': 4, 'n_estimators': 20}\t0.839888\t0.852178\n",
    "GradientBoostingClassifier : {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3, 'max_features': 10, 'min_samples_leaf': 7, 'min_samples_split': 6, 'n_estimators': 10}\t0.838483\t0.845508\n",
    "GradientBoostingClassifier : {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3, 'max_features': 10, 'min_samples_leaf': 7, 'min_samples_split': 6, 'n_estimators': 15}\t0.838483\t0.845155\n",
    "\n",
    "\n",
    "{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3, 'max_features': 10, 'min_samples_leaf': 7, 'min_samples_split': 6, 'n_estimators': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RF\n",
    "# data.drop(['Title_aggr_Royalty','Title_aggr_Officer','Name_Size_Medium','Embarked_Q'],axis=1,inplace=True)\n",
    "# {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 30}\n",
    "# Score 80.803 leader board, train with X_train or all data "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
