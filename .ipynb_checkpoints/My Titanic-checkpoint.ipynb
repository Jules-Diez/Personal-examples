{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description of the Kaggle challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict survival of the passengers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaggle specification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is 2 datasets, Train and Test. \n",
    "The Test dataset is used for the prediction and therefore do not have Survived feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- [Description of the data set](#Description-of-the-data-set)\n",
    "- [First look at the data](#First-look-at-the-data)\n",
    "    - [Import Libraries](#Import-Libraries)\n",
    "    - [Load Data](#Load-Data)\n",
    "    - [Brief summaries](#Brief-summaries)\n",
    "- [Visualization Part 1](#Visualization-Part-1)\n",
    "    - [Basic insight of the training set](#Basic-insight-of-the-training-set)\n",
    "    - [Focus on the mean of survival](#Focus-on-the-mean-of-survival)\n",
    "- [Features engineering](#Features-engineering)\n",
    "    - [Name](#Name)\n",
    "    - [Family](#Family)\n",
    "    - [Family](#Family)\n",
    "    - [Cabin](#Cabin)\n",
    "- [Missing Values](#Missing-Values)\n",
    "    - [Embarked](#Embarked)\n",
    "    - [Fare](#Fare)\n",
    "    - [Age with Median](#Age-with-median)\n",
    "- [Visualization Part 2](#Visualization-Part-2)\n",
    "    - [Visualization Name](#Visualization-Name)\n",
    "    - [Visualization Family](#Visualization-Family)\n",
    "    - [Visualization Deck](#Visualization-Deck)\n",
    "    - [All features between Training and Testing set](#All-features-between-Training-and-Testing-set)\n",
    "- [Features Encoding](#Features-Encoding)\n",
    "    - [Categorial features encoding](#Categorial features encoding)\n",
    "        - [Label Encoding](#Label-Encoding)\n",
    "        - [One Hot Encoding](#One-Hot-Encodingn)   \n",
    "    - [Feature Scalling](#Feature-Scalling)\n",
    "    - [Data Preparation](#Data-Preparation)\n",
    "- [Features Importance](#Features-Importance)\n",
    "    - [Quantitative Features](#Quantitative-Features)\n",
    "    - [One Hot Encoder](#One-Hot-Encoder)\n",
    "    - [Features Selection](#Features-Selection)\n",
    "- [Model Selection](#Model-Selection)\n",
    "    - [Helper function](#Helper-function)\n",
    "    - [Gradient Boosting Classifier](#Gradient-Boosting-Classifier)\n",
    "    - [Random Forest Classifier](#Random-Forest-Classifier)\n",
    "    - [SVC](#SVC)\n",
    "    - [Voting Classifier](#Voting-Classifier)\n",
    "- [Submission](#Submission)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the data set"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "VARIABLE DESCRIPTIONS:\n",
    "survival        Survival\n",
    "                (0 = No; 1 = Yes)\n",
    "pclass          Passenger Class\n",
    "                (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "name            Name\n",
    "sex             Sex\n",
    "age             Age\n",
    "sibsp           Number of Siblings/Spouses Aboard\n",
    "parch           Number of Parents/Children Aboard\n",
    "ticket          Ticket Number\n",
    "fare            Passenger Fare\n",
    "cabin           Cabin\n",
    "embarked        Port of Embarkation\n",
    "                (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "\n",
    "SPECIAL NOTES:\n",
    "Pclass is a proxy for socio-economic status (SES)\n",
    " 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower\n",
    "\n",
    "Age is in Years; Fractional if Age less than One (1)\n",
    " If the Age is Estimated, it is in the form xx.5\n",
    "\n",
    "With respect to the family relation variables (i.e. sibsp and parch)\n",
    "some relations were ignored.  The following are the definitions used\n",
    "for sibsp and parch.\n",
    "\n",
    "Sibling:  Brother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic\n",
    "Spouse:   Husband or Wife of Passenger Aboard Titanic (Mistresses and Fiances Ignored)\n",
    "Parent:   Mother or Father of Passenger Aboard Titanic\n",
    "Child:    Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic\n",
    "\n",
    "Other family relatives excluded from this study include cousins,\n",
    "nephews/nieces, aunts/uncles, and in-laws.  Some children travelled\n",
    "only with a nanny, therefore parch=0 for them.  As well, some\n",
    "travelled with very close friends or neighbors in a village, however,\n",
    "the definitions do not support such relations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "pd.set_option('display.max_rows', 1000)\n",
    "\n",
    "# Scipy\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "# Sklearn\n",
    "\n",
    "    # General\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.metrics import (accuracy_score, classification_report, confusion_matrix, f1_score,\n",
    "                            precision_score, recall_score) \n",
    "    # Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (ExtraTreesClassifier, RandomForestClassifier, \n",
    "                              AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier)\n",
    "\n",
    "# Warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load data\n",
    "df_train=pd.read_csv(\"Data/Titanic/train.csv\")\n",
    "df_test=pd.read_csv(\"Data/Titanic/test.csv\")\n",
    "\n",
    "# Get a combined Dataframe \n",
    "combined = df_train.append(df_test)\n",
    "combined.reset_index(inplace=True)\n",
    "\n",
    "# For visualization\n",
    "combined.loc[0:890,'Data_set'] = 'Train'\n",
    "combined.loc[891:,'Data_set'] = 'Test'\n",
    "combined.loc[0:890,'Train'] = 1\n",
    "combined.loc[891:,'Train'] = 0\n",
    "#combined.drop('index',axis=1,inplace=True)\n",
    "\n",
    "# Get PassengerId for test and targets for training set\n",
    "targets = df_train.Survived\n",
    "PassengerId = df_test['PassengerId']\n",
    "\n",
    "# Helpler function to split combined quickly\n",
    "def split_train_test(combined):\n",
    "    \n",
    "    train = pd.DataFrame()\n",
    "    test = pd.DataFrame()\n",
    "    \n",
    "    train = combined.ix[0:890]\n",
    "    test = combined.ix[891:]\n",
    "    \n",
    "    return train,test\n",
    "\n",
    "# Get a look at the first rows\n",
    "print(\"Training set\")\n",
    "display(df_train.head())\n",
    "print(\"Testing set\")\n",
    "display(df_test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"----------------------------------Informations for the training set----------------------------------\\n\")\n",
    "df_train.info()\n",
    "print('\\nList of Null values \\n\\n',df_train.isnull().sum())\n",
    "print(\"\\n----------------------------------Informations for the testing set ----------------------------------\\n\")\n",
    "df_test.info()\n",
    "print('\\nList of Null values \\n\\n',df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* No Survived feature on the testing set\n",
    "* Lot of Ages values are missing \n",
    "* Cabin feature is mostly null \n",
    "* Embarked feature has a few missing values\n",
    "* Survived and Pclass should be treated as object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Basic statistical information about quantitative and qualitative features\n",
    "\n",
    "# Changing the type of Pclass and Survived \n",
    "df_train['Pclass']=df_train['Pclass'].astype(object)\n",
    "df_train['Survived']=df_train['Survived'].astype(object)\n",
    "df_test['Pclass']=df_test['Pclass'].astype(object)\n",
    "\n",
    "print(\"----------------------------------Informations for the training set----------------------------------\\n\")\n",
    "\n",
    "# Quantitative\n",
    "display(df_train.describe())\n",
    "\n",
    "# Qualitative\n",
    "display(df_train.describe(include=['object']))\n",
    "\n",
    "print(\"----------------------------------Informations for the testing set----------------------------------\\n\")\n",
    "\n",
    "# Quantitative\n",
    "display(df_test.describe())\n",
    "\n",
    "# Qualitative\n",
    "display(df_test.describe(include=['object']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* The training and testing set seems well stratified\n",
    "\n",
    "\n",
    "* Age :  mean ~30 with std ~14\n",
    "* Sibsp and Parch mean  between 0.3 and 0.5 and std around 1\n",
    "* Fare : mean ~34 with big std ~50 \n",
    "\n",
    "\n",
    "* Pclass : top Pclass_3\n",
    "* Sex : top male\n",
    "* Embarked : top S\n",
    "* Ticket and cabin : is not unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Visualization Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic insight of the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Qualitative Data : [Survived, Sex, Embarked, Pclass] \n",
    "fig, (axis1,axis2,axis3,axis4) = plt.subplots(1,4,figsize=(15,5))\n",
    "sns.countplot(x='Survived', data=df_train, ax=axis1)\n",
    "sns.countplot(x='Sex', data=df_train, ax=axis2)\n",
    "sns.countplot(x='Embarked', data=df_train, ax=axis3)\n",
    "sns.countplot(x='Pclass', data=df_train, ax=axis4)\n",
    "fig.suptitle(\"Representation of qualitative features with count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* High imbalance between the values of the Survived, Sex, Plass and Embarked\n",
    "* Survived : Mostly 0\n",
    "* Sex : Mostly male\n",
    "* Pclass : Mostly Pclass3\n",
    "* Embarked : Mostly S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Discrete Quantitative Data : [SibSp, Parch] \n",
    "fig2, (axis1,axis2) = plt.subplots(1,2,figsize=(15,5))\n",
    "sns.countplot(df_train['SibSp'],ax=axis1)\n",
    "sns.countplot(df_train['Parch'],ax=axis2)\n",
    "fig2.suptitle(\"Representation of discrete quantitative features with count\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* SibSp and Parch mostly 0, with some 1 and 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Continuous Quantitative Data : [Age, Fare]\n",
    "fig3, (axis1,axis2) = plt.subplots(2,1,figsize=(15,10))\n",
    "sns.distplot(df_train['Age'].dropna(), bins=80, ax=axis1)\n",
    "sns.distplot(df_train['Fare'], ax=axis2)\n",
    "fig3.suptitle(\"Histogram and kernel density estimate of dontinuous quantitative features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* There is a bump representing Child in the Age distribution\n",
    "* Fare has a low std compare to the range of values it takes. A few peoples paid way more than the others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Age distribution within Sex and Pclass\n",
    "fig3, ((axis1),(axis2),(axis3)) = plt.subplots(3,1,figsize=(15,15))\n",
    "\n",
    "# Age distribution\n",
    "df_train.Age.plot(kind='kde',ax=axis1)\n",
    "axis1.set_xlabel(\"Age\")    \n",
    "axis1.set_title(\"Age distribution\")\n",
    "\n",
    "# Age distribution within Sex\n",
    "df_train.Age[df_train.Sex == 'male'].plot(kind='kde',ax=axis2,)    \n",
    "df_train.Age[df_train.Sex == 'female'].plot(kind='kde',ax=axis2)\n",
    "axis2.set_xlabel(\"Age\")    \n",
    "axis2.set_title(\"Age distribution within Sex\")\n",
    "axis2.legend(('Male', 'Female'))\n",
    "\n",
    "# Age distribution within Pclass\n",
    "df_train.Age[df_train.Pclass == 1].plot(kind='kde',ax=axis3)    \n",
    "df_train.Age[df_train.Pclass == 2].plot(kind='kde',ax=axis3)\n",
    "df_train.Age[df_train.Pclass == 3].plot(kind='kde',ax=axis3)\n",
    "axis3.set_xlabel(\"Age\")    \n",
    "axis3.set_title(\"Age distribution within PClass\")\n",
    "axis3.legend(('1st Class', '2nd Class','3rd Class'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* Small differences of distribution of Age between Male and Female\n",
    "* Significant differences of distribution of Age between Pclass 1, 2 and 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Focus on the mean of survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# (Sex, Pclass, Embarked) by mean of survival\n",
    "fig4, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(15,5))\n",
    "sns.barplot(x='Sex',y='Survived', data=df_train, ax=axis1)\n",
    "sns.barplot(x='Embarked',y='Survived', data=df_train, ax=axis3)\n",
    "sns.barplot(x='Pclass',y='Survived', data=df_train, ax=axis2)\n",
    "fig4.suptitle(\"Representation of qualitative features linked to the target : Survived \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations :\n",
    "* Sex :\n",
    "    * Male : low rate of survival ~0.2\n",
    "    * Female : high rate of survival ~0.75\n",
    "* Pclass by mean of survival 1 > 2 > 3\n",
    "* Embarked : Differences of survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# (SibSp, Parch) by mean of survival\n",
    "fig6, (axis1,axis2) = plt.subplots(1,2,figsize=(15,5))\n",
    "sns.barplot(x='SibSp',y='Survived', data=df_train, ax=axis1)\n",
    "sns.barplot(x='Parch',y='Survived', data=df_train, ax=axis2)\n",
    "fig6.suptitle(\"Representation of discrete quantitative features linked to the target : Survived \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations :\n",
    "* Parch seems to have small differences of rate for the most encountered values. But 0 still get a lower rate. \n",
    "* Sibsp seems better and we can group them together for create a new feature showing the number of relatives (even if a lot of them are not counted in this both features, for more information you can go to the data description with this link:\n",
    "  [Description](#Description-of-the-data-set)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross relation betwen (Sex, Pclass, Embarked) by mean of survival\n",
    "fig5, ((axis1,axis2),(axis3,axis4),(axis5,axis6)) = plt.subplots(3,2,figsize=(15,15))\n",
    "sns.barplot(x='Sex',y='Survived',hue='Pclass', data=df_train, ax=axis1)\n",
    "sns.barplot(x='Sex',y='Survived',hue='Embarked', data=df_train, ax=axis2)\n",
    "\n",
    "sns.barplot(x='Pclass',y='Survived',hue='Sex', data=df_train, ax=axis3)\n",
    "sns.barplot(x='Pclass',y='Survived',hue='Embarked', data=df_train, ax=axis4)\n",
    "\n",
    "sns.barplot(x='Embarked',y='Survived',hue='Sex', data=df_train, ax=axis5)\n",
    "sns.barplot(x='Embarked',y='Survived',hue='Pclass', data=df_train, ax=axis6)\n",
    "\n",
    "fig5.suptitle(\"Cross Representation of qualitative features linked to the target : Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* Male Pclass 1 has around twice the rate of male from Pclass 2 and 3\n",
    "* Female class 3 has a rate around twice lower than female from Pclass 1 and 2\n",
    "* Embarked do not seems very meaningfull for us, but Pclass 3 Embarked from S is really lower than the others 3nd Pclass and male from Embarked Q lower than male from Embarked S and C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Age by mean of survival\n",
    "df_train['Age'] = df_train['Age'].map(lambda s : s if np.isnan(s) else int(s))\n",
    "fig6, (axis1,axis2) = plt.subplots(2,1,figsize=(20,14))\n",
    "sns.countplot(x='Age', data=df_train,ax=axis1)\n",
    "sns.barplot(x='Age', y='Survived', data=df_train,errwidth=0.2,ax=axis2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations :\n",
    "* Age by mean of survival is high from child and eldery and low for medium ages, following the opposite of the distribution of Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Kernel density of survivor and non survivor by Age\n",
    "g1 = sns.FacetGrid( df_train , hue='Survived' , aspect=4)\n",
    "g1.map( sns.kdeplot , 'Age' , shade= True )\n",
    "g1.add_legend()\n",
    "\n",
    "# Kernel density of survivor and non survivor by Age and Sex \n",
    "g2 = sns.FacetGrid( df_train , hue='Survived' , aspect=4 , row = 'Sex')\n",
    "g2.map( sns.kdeplot , 'Age' , shade= True )\n",
    "g2.add_legend()\n",
    "\n",
    "# Kernel density of survivor and non survivor by Age and Pclass\n",
    "g3 = sns.FacetGrid( df_train , hue='Survived' , aspect=4 , row = 'Pclass')\n",
    "g3.map( sns.kdeplot , 'Age' , shade= True )\n",
    "g3.add_legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obersations :\n",
    "* Thinking about the creation of a feature for Child as the distribution show good survival rate for young passengers. Need to check if the Training and Test dataset have the same distribution of Age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Scatterplot Fare & Age\n",
    "g = sns.FacetGrid(df_train, hue=\"Survived\", size=6)\n",
    "g=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\n",
    "g.add_legend()\n",
    "g.set(xlim=(0, 550))\n",
    "\n",
    "# Scatterplot Fare & Age by Sex\n",
    "g = sns.FacetGrid(df_train, hue=\"Survived\", col=\"Sex\", margin_titles=True,\n",
    "                palette=\"Set1\",hue_kws=dict(marker=[\"^\", \"v\"]),size=6)\n",
    "g=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\n",
    "g.add_legend()\n",
    "g.set(xlim=(0, 300))\n",
    "\n",
    "# Scatterplot Fare & Age by Pclass\n",
    "g = sns.FacetGrid(df_train, col=\"Pclass\", hue=\"Survived\", size=4)\n",
    "g=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\n",
    "g.add_legend()\n",
    "g.set(xlim=(0, 300))\n",
    "\n",
    "# Scatterplot Fare & Age by Pclass & Sex\n",
    "g = sns.FacetGrid(df_train, hue=\"Survived\", col=\"Pclass\", row=\"Sex\" ,margin_titles=True,\n",
    "                  palette={1:\"red\", 0:\"grey\"},size=5)\n",
    "g=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\n",
    "g.set(xlim=(0, 300))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obersations :\n",
    "* Female with Fare more than 50 are really likely to survive\n",
    "* In Pclass 1 Fare more than 100 show a good increase of the rate but is made mostly by Female"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The visualization concerning the feature engineering is in the section [Visualization Part 2](#Visualization-Part-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of 4 features :\n",
    "* Name_Length : The number of letters of the full name\n",
    "* Name_Size : The categorised size : Short, Medium, Long and Very Long\n",
    "* Title : The extracted title of the passenger\n",
    "* Title_aggr : The aggregation of the less encountered values with high rate of survival together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create feature for the length of name \n",
    "combined[\"Name_Length\"] = combined[\"Name\"].apply(lambda x: len(x))\n",
    "\n",
    "# Create a categorical feature Name_Size\n",
    "combined['Name_Size']=pd.cut(combined['Name_Length']\n",
    "                            ,bins=[0,20,40,60,90]\n",
    "                            ,labels=[\"Short\",\"Medium\",\"Long\",\"Very Long\"])\n",
    "\n",
    "# Extract the title from each name by sliding between the ',' and the '.' \n",
    "combined['Title'] = combined['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "\n",
    "# Map for aggregated titles\n",
    "Title_Dictionary = {\n",
    "                    \"Mme\":        \"Mrs\",\n",
    "                    \"Mlle\":       \"Miss\",\n",
    "                    \"Ms\":         \"Mrs\",\n",
    "                    \"Mr\" :        \"Mr\",\n",
    "                    \"Mrs\" :       \"Mrs\",\n",
    "                    \"Miss\" :      \"Miss\",\n",
    "                    \"Capt\":       \"Officer\",\n",
    "                    \"Col\":        \"Officer\",\n",
    "                    \"Major\":      \"Officer\",\n",
    "                    \"Dr\":         \"Officer\",\n",
    "                    \"Rev\":        \"Officer\",\n",
    "                    \"Master\" :    \"Master\",\n",
    "                    \"Lady\" :      \"Royalty\",\n",
    "                    \"Jonkheer\":   \"Royalty\",\n",
    "                    \"Don\":        \"Royalty\",\n",
    "                    \"Sir\" :       \"Royalty\",\n",
    "                    \"Dona\":       \"Royalty\",\n",
    "                    \"the Countess\":\"Royalty\"\n",
    "                    }\n",
    "    \n",
    "# Mapping\n",
    "combined['Title_aggr'] = combined.Title.map(Title_Dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of 2 features:\n",
    "* Number of relatives = SibSp + Parch\n",
    "* Size_Family =  The categorised size : Alone, Small and Big"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Creation of a feature Number_of_relatives = SibSp + Parch\n",
    "combined['Number_of_relatives']=combined['SibSp']+combined['Parch']\n",
    "\n",
    "# Creation of a categorical feature Size_Family\n",
    "combined.loc[combined['Number_of_relatives'] == 0, 'Size_Family'] = 'Alone'\n",
    "combined.loc[ (combined['Number_of_relatives'] > 0) \n",
    "            & (combined['Number_of_relatives'] < 4), 'Size_Family'] = 'Small'\n",
    "combined.loc[combined['Number_of_relatives'] > 3, 'Size_Family'] = 'Big'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cabin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of the Deck feature by extraction of the cabin number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mostly NaN values\n",
    "print('Number of null values:')\n",
    "display(combined.Cabin.isnull().sum())\n",
    "\n",
    "# Create a category Unknown\n",
    "combined['Cabin'] = combined.Cabin.fillna( 'U' )\n",
    "\n",
    "# Get the Deck \n",
    "combined[\"Deck\"]=combined.Cabin.str[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embarked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the missing values and remplacing them by looking at the boxplot of Embarked and Pclass with Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get and display the rows where Embarked is null\n",
    "display(combined[combined.Embarked.isnull()][['Fare', 'Pclass', 'Embarked']])\n",
    "\n",
    "# Display boxplot of Embarked missing values\n",
    "combined.boxplot(column='Fare', by=['Embarked','Pclass'], figsize=(8,6))\n",
    "plt.axhline(y=80, color='blue')\n",
    "\n",
    "# Remplace null values by C as most people who are Pclass 1 and Fare 80 has Embarked from C\n",
    "combined = combined.set_value(combined.Embarked.isnull(), 'Embarked', 'C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Displaying the missing values and remplacing them by the mean of Fare for the same Pclass and Embarked."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Visualization of the fare which is missing\n",
    "display(combined[combined.Fare.isnull()][['Pclass', 'Fare', 'Embarked']])\n",
    "combined.loc[(combined['Pclass']==3) & (combined['Embarked']=='S')].Fare.hist(bins=100,figsize=(8,6))\n",
    "\n",
    "# Get and affect the median to the missing value\n",
    "Fare_median=combined[(combined.Pclass==3) & (combined.Embarked=='S')].Fare.median()\n",
    "combined[\"Fare\"].fillna(Fare_median, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age with median and creation of child feature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filling Age by taking the mean of a group by with Sex, Pclass and Title_aggr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fill the NaN values with median using Sex, Pclass and Title\n",
    "grouped = combined.groupby(['Sex','Pclass','Title_aggr'])\n",
    "age_median = grouped['Age'].median()\n",
    "combined[\"Age\"] = combined.groupby(['Sex','Pclass','Title_aggr'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "combined.Age = combined.Age.astype(int)\n",
    "\n",
    "# Display the median by Sex Pclass and Title_aggr\n",
    "display(age_median)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of a Child feature representing passengers younger than 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creation of a Child feature\n",
    "combined['Child'] = combined['Age'].map(lambda s : 1 if s < 14 else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization Part 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This part of the visualization treat new features created during feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Verification of missing values\n",
    "print('Number of null values :')\n",
    "display(combined.isnull().sum())\n",
    "\n",
    "# Split for visualization\n",
    "df_train, df_test= split_train_test(combined)\n",
    "\n",
    "# Display shape\n",
    "display(df_train.shape)\n",
    "display(df_test.shape)\n",
    "\n",
    "# Name of columns\n",
    "display(df_train.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ((axis1,axis2),(axis3,axis4),(axis5,axis6),(axis7,axis8)) = plt.subplots(4,2,figsize=(20,20))\n",
    "\n",
    "# Plot Name_Length\n",
    "sns.distplot(df_train['Name_Length'],ax=axis1)\n",
    "axis1.set_title(\" Hist and kde of Name_Length\")\n",
    "# Plot Name_Length by mean of survival\n",
    "sns.barplot(x='Name_Length', y='Survived', data=df_train,errwidth=0,ax=axis2)\n",
    "axis2.set_title(\" Name_Length by mean of survival\")\n",
    "\n",
    "# Plot Name_Size\n",
    "sns.countplot(x='Name_Size', data=df_train, order=[\"Short\",\"Medium\",\"Long\",\"Very Long\"], ax=axis3)\n",
    "axis3.set_title(\" Count of Name_Size\")\n",
    "# Plot Name_Size by mean of survival\n",
    "sns.barplot(x='Name_Size',y='Survived', data=df_train, order=[\"Short\",\"Medium\",\"Long\",\"Very Long\"], ax=axis4)\n",
    "axis4.set_title(\" Name_Size by mean of survival\")\n",
    "\n",
    "# Plot Title\n",
    "sns.countplot(x='Title', data=df_train, ax=axis5)\n",
    "axis5.set_title(\" Count of Title\")\n",
    "# Plot Title\n",
    "sns.barplot(x='Title',y='Survived', data=df_train, ax=axis6)\n",
    "axis6.set_title(\" Title by mean of survival\")\n",
    "\n",
    "# Plot Title aggregate\n",
    "sns.countplot(x='Title_aggr', data=df_train, ax=axis7)\n",
    "axis7.set_title(\" Count of Title_aggr\")\n",
    "# Plot Title aggregate\n",
    "sns.barplot(x='Title_aggr',y='Survived', data=df_train, ax=axis8)\n",
    "axis8.set_title(\" Title_aggr by mean of survival\")\n",
    "\n",
    "# Display Title aggregate and Name Size by mean of survival\n",
    "#sns.barplot(x='Title_aggr',y='Survived', hue='Name_Size', data=df_train,errwidth=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations :\n",
    "* Name_Length has a big density between 15 and 35 and decrease after a small bump\n",
    "* Name_Length by mean of survival increase with Name_Length\n",
    "* Name_Size is mostly composed of Medium than Short.\n",
    "* Name_Size by mean of survival increase with Name_Size\n",
    "* Title mostly composed of Mr, Mrs, Miss and Master\n",
    "* Title by mean of survival is low for Mr and high for Female and Master\n",
    "* Title_aggr aggreate all the small features of Title into Royality and Officer "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig, ((axis1,axis2),(axis3,axis4),(axis5,axis6),(axis7,axis8)) = plt.subplots(4,2,figsize=(20,20))\n",
    "\n",
    "# Plot Number_of_relatives\n",
    "sns.countplot(x='Number_of_relatives', data=df_train, ax=axis1)\n",
    "axis1.set_title(\" Count of Number_of_relatives\")\n",
    "# Plot Number_of_relatives by mean of survival\n",
    "fig2 = sns.barplot(x='Number_of_relatives',y='Survived', data=df_train, ax=axis2)\n",
    "axis2.set_title(\" Number_of_relatives by mean of survival\")\n",
    "\n",
    "# Plot Size_Family\n",
    "sns.countplot(x='Size_Family', data=df_train, order=['Alone', 'Small', 'Big'], ax=axis3)\n",
    "axis3.set_title(\" Count of Size_Family\")\n",
    "# Plot Size_Family by mean of survival\n",
    "sns.barplot(x='Size_Family',y='Survived', data=df_train, order=['Alone', 'Small', 'Big'], ax=axis4)\n",
    "axis4.set_title(\" Size_Family by mean of survival\")\n",
    "\n",
    "# Plot Number_of_relatives and Pclass \n",
    "sns.barplot(x='Number_of_relatives',y='Survived',hue='Pclass', data=df_train, ax=axis5)\n",
    "axis5.set_title(\" Number_of_relatives and Pclass by mean of survival\")\n",
    "# Plot Number_of_relatives and Pclass by mean of survival\n",
    "sns.barplot(x='Number_of_relatives',y='Survived',hue='Sex', data=df_train, ax=axis6)\n",
    "axis6.set_title(\" Number_of_relatives and Sex by mean of survival\")\n",
    "\n",
    "# Plot Size_Family and Pclass\n",
    "sns.barplot(x='Size_Family',y='Survived',hue='Pclass', data=df_train, order=['Alone', 'Small', 'Big'], ax=axis7)\n",
    "axis7.set_title(\"Size_Family and Pclass by mean of survival\")\n",
    "# Plot Size_Family  and Pclass by mean of survival\n",
    "sns.barplot(x='Size_Family',y='Survived',hue='Sex', data=df_train, order=['Alone', 'Small', 'Big'], ax=axis8)\n",
    "axis8.set_title(\" Size_Family and Sex by mean of survival\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations :\n",
    "* Number_of_relatives mostly 0, with some 1 and 2\n",
    "* Size_Family is mostly composed of Alone and Small.\n",
    "* Size_Family by mean of survival is low for Alone and Big and higher for Small group\n",
    "* Male get an increase of the rate of survival with Number_of_relatives from 0 to 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization Deck"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Show Deck by size and mean of survival\n",
    "fig6, (axis1,axis2) = plt.subplots(1,2,figsize=(15,5))\n",
    "sns.countplot(x='Deck', data=df_train, ax=axis1)\n",
    "sns.barplot(x='Deck', y='Survived', data=df_train, ax=axis2)\n",
    "fig6.suptitle(\"Deck by size and mean of survival\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* Mostly Unknow and no significant difference with the mean of survival => Will not be used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization Child"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fig6, (axis1,axis2) = plt.subplots(1,2,figsize=(15,5))\n",
    "# Plot Child\n",
    "sns.countplot(df_train['Child'],ax=axis1)\n",
    "axis1.set_title(\" Count of Child\")\n",
    "# Plot Child by mean of survival\n",
    "sns.barplot(x='Child', y='Survived', data=df_train,errwidth=0,ax=axis2)\n",
    "axis2.set_title(\" Child by mean of survival\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All features between Training and Testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test the stratification of features between Training and Testing set, so that we have a better idea of which feature might be usefull. Moreover it can lead to the discover that some feature engineering will certainly not work well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display columns\n",
    "display(combined.columns)\n",
    "\n",
    "# Display shape\n",
    "print('Shape of df_train : ',df_train.shape)\n",
    "print('Shape of df_test : ',df_test.shape)\n",
    "print('Shape of combined : ',combined.shape)\n",
    "\n",
    "# Ratio between the size of the training and testing set\n",
    "Ratio = df_train.shape[0]/df_test.shape[0]\n",
    "print('Ratio between training and testing set:',Ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By a countplot we can check if the ratio of 2,1 is followed for the qualitative features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Kde of Age, Fare, Name_Length and Number_of_relatives\n",
    "fig, ((axis1,axis2),(axis3,axis4))= plt.subplots(2,2,figsize=(20,20))\n",
    "\n",
    "# Age distribution within 3 datasets\n",
    "combined.Age.plot(kind='kde',ax=axis1)    \n",
    "df_train.Age.plot(kind='kde',ax=axis1)  \n",
    "df_test.Age.plot(kind='kde',ax=axis1)  \n",
    "axis1.set_xlabel(\"Age\")    \n",
    "axis1.set_title(\" Kde of Age for the 3 datasets\")\n",
    "axis1.legend(('Combined', 'Train','Test'))\n",
    "\n",
    "# Fare distribution within 3 datasets\n",
    "combined.Fare.plot(kind='kde',ax=axis2)    \n",
    "df_train.Fare.plot(kind='kde',ax=axis2)  \n",
    "df_test.Fare.plot(kind='kde',ax=axis2)  \n",
    "axis2.set_xlabel(\"Fare\")    \n",
    "axis2.set_title(\" Kde of Fare for the 3 datasets\")\n",
    "axis2.legend(('Combined', 'Train','Test'))\n",
    "\n",
    "# Name_Length distribution within 3 datasets\n",
    "combined.Name_Length.plot(kind='kde',ax=axis3)    \n",
    "df_train.Name_Length.plot(kind='kde',ax=axis3)  \n",
    "df_test.Name_Length.plot(kind='kde',ax=axis3)  \n",
    "axis3.set_xlabel(\"Name_Length\")    \n",
    "axis3.set_title(\" Kde of Name_Length for the 3 datasets\")\n",
    "axis3.legend(('Combined', 'Train','Test'))\n",
    "\n",
    "# Number_of_relatives distribution within 3 datasets\n",
    "combined.Number_of_relatives.plot(kind='kde',ax=axis4)    \n",
    "df_train.Number_of_relatives.plot(kind='kde',ax=axis4)  \n",
    "df_test.Number_of_relatives.plot(kind='kde',ax=axis4)  \n",
    "axis4.set_xlabel(\"Number_of_relatives\")    \n",
    "axis4.set_title(\" Kde of Number_of_relatives for the 3 datasets\")\n",
    "axis4.legend(('Combined', 'Train','Test'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations:\n",
    "* Age from the Test set have a lower bump for child in the kernel density\n",
    "* Name_Length from Testing have more high values around 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count of Pclass, Sex, Embarked, Name_Size, Title and Title_aggr\n",
    "fig, ((axis1,axis2),(axis3,axis4),(axis5,axis6))= plt.subplots(3,2,figsize=(20,20))\n",
    "\n",
    "# Pclass\n",
    "sns.countplot(x='Pclass',hue='Data_set', data=combined, ax=axis1)\n",
    "axis1.set_xlabel(\"Pclass\")    \n",
    "axis1.set_title(\" Countplot of Pclass for the training and testing set\")\n",
    "\n",
    "# Sex\n",
    "sns.countplot(x='Sex',hue='Data_set', data=combined, ax=axis2)\n",
    "axis2.set_xlabel(\"Sex\")    \n",
    "axis2.set_title(\" Countplot of Sex for the training and testing set\")\n",
    "\n",
    "# Embarked\n",
    "sns.countplot(x='Embarked',hue='Data_set', data=combined, ax=axis3)\n",
    "axis3.set_xlabel(\"Embarked\")    \n",
    "axis3.set_title(\" Countplot of Embarked for the training and testing set\")\n",
    "\n",
    "# Name_Size\n",
    "sns.countplot(x='Name_Size',hue='Data_set', data=combined, ax=axis4)\n",
    "axis4.set_xlabel(\"Name_Size\")    \n",
    "axis4.set_title(\" Countplot of Name_Size for the training and testing set\")\n",
    "\n",
    "# Title\n",
    "sns.countplot(x='Title',hue='Data_set', data=combined, ax=axis5)\n",
    "axis5.set_xlabel(\"Title\")    \n",
    "axis5.set_title(\" Countplot of Title for the training and testing set\")\n",
    "\n",
    "# Title_aggr\n",
    "sns.countplot(x='Title_aggr',hue='Data_set', data=combined, ax=axis6)\n",
    "axis6.set_xlabel(\"Title_aggr\")    \n",
    "axis6.set_title(\" Countplot of Title_aggr for the training and testing set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations :\n",
    "* Qualitative features seem  well stratified between Train and Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Features can come in various different flavors. Typically we distinguish between\n",
    "\n",
    "- continuous and\n",
    "- categorical (discrete)\n",
    "features.\n",
    "\n",
    "\n",
    "And the categorical features can be categorized further into:\n",
    "\n",
    "- ordinal and\n",
    "- nominal (= no order implied) features.\n",
    "\n",
    "Most implementations of machine learning algorithms require numerical data as input, and we have to prepare our data accordingly.\n",
    "\n",
    "Ordinal Features\n",
    "Ordinal features need special attention: We have to make sure that the correct values are associated with the corresponding strings. Thus, we need to set-up an explicit mapping dictionary:\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame([\n",
    "            ['green', 'M', 10.1, 'class1'], \n",
    "            ['red', 'L', 13.5, 'class2'], \n",
    "            ['blue', 'XL', 15.3, 'class1']])\n",
    "df.columns = ['color', 'size', 'prize', 'class label']\n",
    "\n",
    "size_mapping = {\n",
    "           'XL': 3,\n",
    "           'L': 2,\n",
    "           'M': 1}\n",
    "\n",
    "df['size'] = df['size'].map(size_mapping)\n",
    "\n",
    "inv_size_mapping = {v: k for k, v in size_mapping.items()}\n",
    "df['size'] = df['size'].map(inv_size_mapping)\n",
    "\n",
    "Nominal Features\n",
    "\n",
    "The scikit-learn and pandas libraries comes with many useful preprocessing functions that we can use for our convenience.\n",
    "\n",
    "scikit LabelEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "class_le = LabelEncoder()\n",
    "df['class label'] = class_le.fit_transform(df['class label'])\n",
    "\n",
    "The class labels can be converted back from integer to string via the inverse_transform method:\n",
    "class_le.inverse_transform(df['class label'])\n",
    "\n",
    "pandas get_dummies\n",
    "Also, pandas comes with a convenience function to create new categories for nominal features, namely: [`get_dummies`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.core.reshape.get_dummies.html).\n",
    "\n",
    "pd.get_dummies(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label encoding and one hot encoding for nominal features and scalling for quantitative features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print('Shape of combined : ',combined.shape)\n",
    "print('Columns of combined :')\n",
    "display(combined.columns)\n",
    "print('Number of Null values by features :')\n",
    "display(combined.isnull().sum())\n",
    "display(combined[[\"Embarked\",\"Sex\",\"Title_aggr\",\"Size_Family\",\"Name_Size\",\"Pclass\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Binary encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Male is set 1 and female to 0\n",
    "combined['Sex'] = combined['Sex'].map(lambda s : 1 if s=='male' else 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorial features encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataframe with numerical categorical feature\n",
    "combined_num_cat = pd.DataFrame()\n",
    "\n",
    "# LabelEncoder\n",
    "labelEnc = LabelEncoder()\n",
    "\n",
    "# Columns to apply\n",
    "cat_str_vars = [\"Embarked\",\"Title_aggr\",\"Size_Family\",\"Name_Size\"]\n",
    "cat_int_vars = [\"Pclass\"]\n",
    "\n",
    "# Apply to string categorical features\n",
    "for col in cat_str_vars:\n",
    "    labelEnc.fit(np.unique(list(combined[col].values)))\n",
    "    combined_num_cat[col]=labelEnc.transform(combined[col].astype('str'))\n",
    "\n",
    "# Apply to numerical categorical features\n",
    "for col in cat_int_vars:\n",
    "    labelEnc.fit(np.unique(list(combined[col].values)))\n",
    "    combined_num_cat[col]=labelEnc.transform(combined[col].astype('int'))\n",
    "    \n",
    "# Add Sex and Child\n",
    "combined_num_cat['Male'] = combined['Sex']\n",
    "combined_num_cat['Child'] = combined['Child']\n",
    "\n",
    "# Display\n",
    "display(combined_num_cat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One Hot  Encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note about : One Hot encoder**\n",
    "\n",
    "When a categorical feature contain 2 or more levels, a way of represention is to create a One Hot encoder also named dummy variables or indicator variables. It takes the value 0 or 1 to indicate the absence or presence of some level of the categorical feature. A categorical feature with k level will then create k dummy variables. \n",
    "\n",
    "The general guideline is as followed : If a variable has k levels, you can create only k-1 indicators. You have to choose one of the k categories as a \"baseline\" and leave out its indicator. \n",
    "\n",
    "Some of the reasons for this guideline are:\n",
    "\n",
    "* By giving K indicators you are adding redundancy to your representation of the data. Statistical redundancy has the property that it can be removed from the data without destroying any information.\n",
    "\n",
    "\n",
    "* Dropping one of the dummy variables enable to avoid the state of Multicollinearity. Which is a state of perfect correlations among the independent variables, meaning that one can be predicted from the others. It is therefore, a type of disturbance in the data, that may affect the results or the performances of the models used.\n",
    "\n",
    "\n",
    "* If K indicators are used and an intercept term (vector of ones) is present in a model where all the predictors are considered together as a linear combination, problems could occur because of perfect multicollinearity between the intercept term and the K indicators, in regression this is know as the dummy variable trap. In this case two of the solutions are to drop one dummy variable or drop the intercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(df_in, cols):\n",
    "    df_out = pd.DataFrame()\n",
    "    for each in cols:\n",
    "        dummies = pd.get_dummies(df_in[each], prefix=each, drop_first=False)\n",
    "        df_out = pd.concat([df_out, dummies], axis=1)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Columns to apply\n",
    "cat_vars=['Embarked',\"Title_aggr\",\"Size_Family\",\"Name_Size\",\"Pclass\"]\n",
    "\n",
    "# Get One Hot encoder\n",
    "combined_One_Hot_Cat = one_hot(combined,cat_vars)\n",
    "\n",
    "# Add Sex and Child\n",
    "combined_One_Hot_Cat['Male'] = combined['Sex']\n",
    "combined_One_Hot_Cat['Child'] = combined['Child']\n",
    "\n",
    "# Display\n",
    "display(combined_One_Hot_Cat.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scalling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note about:  Feature Scalling**\n",
    "\n",
    "Feature scalling is not only important if we are comparing measurements that have different units, but it is also a general requirement for many machine learning algorithms. \n",
    "\n",
    "Feature scaling is a method used to standardize the range of independent variables . This is generally performed during the data preprocessing step. \n",
    "\n",
    "-----------------------------------------------------------------------------------------------\n",
    "\n",
    "Motivations\n",
    "  \n",
    " * Since the range of values of raw data varies widely, in some machine learning algorithms, objective functions will not work properly without normalization. For example, a lot of classifiers calculate the distance between two points by the Euclidean distance. If one of the features has a broad range of values, the distance will be governed by this particular feature. Therefore, the range of all features should be normalized so that each feature contributes approximately proportionately to the final distance.\n",
    " \n",
    " \n",
    " * Another reason why feature scaling is applied is that gradient descent converges much faster with feature scaling than without as it lead to increase the convergence speed.\n",
    " \n",
    " -----------------------------------------------------------------------------------------------\n",
    " \n",
    "Two of the main methods for feature scaling are :\n",
    " \n",
    " * **Standardization** also know as Z-score normalization\n",
    " \n",
    "    The result of standardization is that the features will be rescaled so that they'll have the properties of a standard normal distribution with $\\mu = 0$ and $\\sigma = 1$, where $\\mu$ is the mean and $\\sigma$ is the standard deviation. Compute as follow :\n",
    "    \n",
    "    \\begin{equation} z = \\frac{x - \\mu}{\\sigma}\\end{equation} \n",
    "    \n",
    "    As a result, all variables in the data set have equal means (0) and standard deviations (1) but different ranges.\n",
    "    \n",
    "    This method is widely used for normalization in many machine learning algorithms (e.g., support vector machines, logistic regression, and neural networks)\n",
    "      \n",
    "    \n",
    "* **Normalization** also know as Feature scalling\n",
    "\n",
    "    In Normalization, the data are scaled to a fixed range, usually [0,1] or [-1,1]. The cost of having this bounded range is that we will end up with smaller standard deviations, which can suppress the effect of outliers.  \n",
    "    \n",
    "  The 0-1 scaling or Min-Max scaling is as followed : \\begin{equation} X_{norm} = \\frac{X - X_{min}}{X_{max}-X_{min}} \\end{equation}    \n",
    "    This method allows variables to have differing means and standard deviations but equal ranges. In this case, there is at least one observed value at the 0 and 1 endpoints.\n",
    "   Typical application of 0-1 scaling is for image processing and some neural network that require data on 0-1 scale.\n",
    "     \n",
    "   \n",
    "   \n",
    "-----------------------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "* Some Models by scale invariance\n",
    "\n",
    "    * scale-invariant \n",
    "        * tree-based methods.   \n",
    "\n",
    "    * scale-variant \n",
    "        * k-nearest neighbors, k-means with an Euclidean distance\n",
    "        * logistic regression, SVMs, perceptrons, neural networks etc, while using gradient descent-based optimization\n",
    "        * linear discriminant analysis, principal component analysis etc since the model want to find direction of maximizing the variance wihtin orthogonal space so scale impact on measurement of a feature.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Columns and dataframe for features scalling\n",
    "std_columns = ['Fare','Age','Name_Length','Number_of_relatives']\n",
    "combined_num_std = pd.DataFrame(combined[std_columns])\n",
    "\n",
    "# StandardScaller process\n",
    "std_scale = StandardScaler()\n",
    "combined_num_std[std_columns] = std_scale.fit_transform(combined[std_columns].astype(float))\n",
    "\n",
    "# Display before and after\n",
    "display(combined[std_columns].head())\n",
    "display(combined_num_std[std_columns].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Continuous Quantitative Data : [Age, Fare]\n",
    "fig3, (axis1,axis2) = plt.subplots(2,1,figsize=(15,10))\n",
    "sns.distplot(combined_num_std['Age'].dropna(), bins=80, ax=axis1)\n",
    "sns.distplot(combined_num_std['Fare'], ax=axis2)\n",
    "fig3.suptitle(\"Histogram and kernel density estimate of dontinuous quantitative features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creation of 2 data sets:\n",
    "* label encoder + scalled quantitative features\n",
    "* one hot encoder + scalled quantitative features "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Available :\n",
    "* combined_num_std\n",
    "* combined_One_Hot_Cat\n",
    "* combined_num_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Concat into One Hot or Label encoding\n",
    "combined_OH_Std = pd.concat([combined_num_std,combined_One_Hot_Cat],axis=1)\n",
    "\n",
    "\n",
    "combined_Num_Std = pd.concat([combined_num_std,combined_num_cat],axis=1)\n",
    "\n",
    "# Display shape\n",
    "print('Shape of combined_OH_Std : ',combined_OH_Std.shape)\n",
    "print('Shape of combined_Num_Std : ',combined_Num_Std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split into Train and Eval for submit prediction on kaggle\n",
    "Train_OH_Std, Eval_OH_Std= split_train_test(combined_OH_Std)\n",
    "Train_Num_Std, Eval_Num_Std = split_train_test(combined_Num_Std)\n",
    "\n",
    "# Display shape\n",
    "print('Shape of Train_OH_Std : ',Train_OH_Std.shape)\n",
    "print('Shape of Eval_OH_Std : ',Eval_OH_Std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select Data to use\n",
    "data = Train_OH_Std\n",
    "test_data = Eval_OH_Std\n",
    "target = targets\n",
    "columns_name = list(Train_OH_Std)\n",
    "\n",
    "# Train & Validation set\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20, random_state = 42,stratify=target)\n",
    "\n",
    "# Dataframe of prediction\n",
    "Prediction = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Selection\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features selection can be made using results of this analysis at the beginning but the process of features selection is an iteration so it's needed to try differents models and tuned up your parameters to make your final decision.\n",
    "\n",
    "As in our case there is not so much features to study we can do it manualy by classical statistical analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Study the relation between:\n",
    "* Target and quantitative features with :\n",
    "    * Point Biserial Pearson Correlation\n",
    "    * Anova\n",
    "    * Linear Discriminant Analysis\n",
    "        \n",
    "        \n",
    "* Target and one hot categorical encoding with :\n",
    "    * Pearson Phi\n",
    "    * Chi 2 Independance and Cramer V\n",
    "    * Hamming and Dice distance\n",
    "    * Multiple Correspondence Analysis\n",
    "        \n",
    "        \n",
    "*  Target and all features with \n",
    "    * Logistic Regression\n",
    "    * Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://blog.yhat.com/posts/logistic-regression-python-rodeo.html\n",
    "using of stats to do statisical logistic regression with classical results\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note about: Classification with mixed features**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note about: Result of analysis**\n",
    "* Correlation Coefficient shows the variation of dataset values(original) from the regression line. The higher the coefficient, the lower the variation from the regression line.\n",
    "\n",
    "* Feature Importance shows how much the model fit decreases when you drop a feature. When you drop a feature, The more the model fit decreases, the more significant and informative the feature. The \"model fit\" refers to the accuracy of the prediction values(i.e. regression line)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note about: Missing values**\n",
    "\n",
    "If you ever faced a column with NaN values, you usually will fill these values manually, But, How?\n",
    "\n",
    "* Using random values that are within 1 standard deviation of the mean. In other words, random values from mean-std till mean+std. As an example, see 'Age' column in the script above.\n",
    "* Using mean value. This is the average value for range of numbers. I usually use the mean when the values are continuous, or distributed normally, or they are float.\n",
    "* Using median value. This is the middle value in range of numbers. I usually see the median when the values represent categories(discrete data), or non normally distributed(i.e. [1,1,1,2,2,2,3,3,3,4,7,10,12,15,20,23,200,500])\n",
    "* Using 0, or -1, or the most occurred value, or a value based on other column, ...etc. Sometimes the best value to fill is not one of the previous, So, you need to think about and choose the best suitable value for the missing values.\n",
    "\n",
    "\n",
    "Since the NaN values were assigned by values from [mean-std, mean+std] which represents 68% of values, So, the new age values will be almost the same"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note about : Feature Selection**\n",
    "    \n",
    "The more features you have, the more you need to take care of features selection because of the curse of dimensionality.\n",
    "\n",
    "In the general case there is 3 main approach to feature selection:\n",
    "\n",
    "* Filter Methods: \n",
    "    * 1 vs 1\n",
    "    * Filter features by their relevance with the target.\n",
    "    * Filter methods pick up the intrinsic properties of the features measured via univariate statistics. Some examples :\n",
    "        * information gain\n",
    "        * chi-square test\n",
    "        * fisher score\n",
    "        * correlation coefficient\n",
    "        * variance threshold\n",
    "        \n",
    "* Wrapper Methods: \n",
    "    * 1 vs subset of all\n",
    "    * Evaluation of each possible subset against a model, and see which one will give you a better performance.\n",
    "    * Wrapper methods measure the usefulness of each feature based on the classifier performance within a subset. So, wrapper methods are optimizing the classifier performance, but they are computationally more expensive compared to filter methods due to the repeated learning steps and cross-validation needed. Some examples :\n",
    "        * recursive feature elimination\n",
    "        * sequential feature selection algorithms\n",
    "        * genetic algorithms\n",
    "\n",
    "* Embedded Methods: \n",
    "    * 1 vs subset of all\n",
    "    * There are models that learn which features best contribute to the perforance of the model. These models compute feature importance, which can be used to discard unimportant features.\n",
    "    * Embedded methods, are quite similar to wrapper methods since they are also used to optimize the objective function or performance of a learning algorithm or model. The difference to wrapper methods is that an intrinsic model building metric is used during learning. Some examples :\n",
    "        * L1 (LASSO) regularization\n",
    "        * decision tree\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note about : Dimensionality Reduction with feature extraction** \n",
    "\n",
    "Dimensionality Reduction with feature extraction serves two purposes, analysing and/or reducing your features.\n",
    "\n",
    "When the number of features is high, or if you suspect that some of them might not be meaninfull or not well represented, you can use dimensionality reduction methods to reduce the number of features or to get a better understanding thanks to the principal components obtain than enable you to visualize high dimentional data in a set of 2D plot.  As dimensionality reduction is about reducing the numbers of features and saving a lot of the information, when you choose the number of principal components to use, you also choose the percentage of variance explained by the representation.\n",
    "\n",
    "If you choose to take a number of principal components as input of your models or others analysis, you are losing a certain amount of variance and you may also loose the easiness of explaining your features, but you gain stronger features that can be used as input of various machine learning algorithms and can lead to better scores in some cases. \n",
    "\n",
    "As an alternative, you can study your features with the results of the dimensionality reduction methods and others  analysis and choose yourselft if and which features need to be drop.\n",
    "\n",
    "Some of the main methods are \n",
    "* Principal Component Analysis (PCA),unsupervised , which takes quantitative features and returns axes of maximal variance given the constraint that those axes are orthogonal to each other\n",
    "* Multiple Correspondence Analysis (MCA),unsupervised , which takes qualitative features and appears to be the counterpart of principal component analysis for categorical data\n",
    "* Linear Discriminant Analysis (LDA),supervised , returns axes that maximizes class separability given the constraint that those axes are orthogonal to each other\n",
    "* kernel PCA : uses kernel trick to transform non-linear data to a feature space were samples may be linearly separable\n",
    "* [List of nonlinear dimensionality reduction methods][https://en.wikipedia.org/wiki/Nonlinear_dimensionality_reduction]\n",
    "\n",
    "\n",
    "As the results of PCA and MCA are quantitatives features, it can make you able to switch your representation from categorical to quantitative features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Factor analysis of mixed data -> MCA with quantitatives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantitative Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Features to apply\n",
    "Quantitative = ['Fare','Age','Name_Length','Number_of_relatives']\n",
    "\n",
    "# Concatenate data and target\n",
    "QF_Target = pd.concat([data[Quantitative],target],axis=1)\n",
    "\n",
    "# Create Survied and Died set\n",
    "Survived = QF_Target[QF_Target['Survived'] == 1]\n",
    "Died = QF_Target[QF_Target['Survived'] == 0]\n",
    "\n",
    "# Create results dataframes\n",
    "PointBiser = pd.DataFrame()\n",
    "TTest = pd.DataFrame()\n",
    "Anova = pd.DataFrame()\n",
    "Lda = pd.DataFrame() \n",
    "\n",
    "for var in enumerate(Quantitative) : \n",
    "    \n",
    "    # Point Biserial correlation\n",
    "    pb = stats.pointbiserialr(QF_Target['Survived'], QF_Target[var[1]])\n",
    "    PointBiser.loc[var[0],'Feature'] = var[1]\n",
    "    PointBiser.loc[var[0],'Point Biserial Pearson Corr'] = pb.correlation\n",
    "    PointBiser.loc[var[0],'Pval'] = pb.pvalue\n",
    "    PointBiser.sort_values('Pval',ascending=True,inplace=True)\n",
    "    \n",
    "    # Student T Test : mean independance\n",
    "    #t_test = stats.ttest_ind(Survived[var[1]], Died[var[1]])\n",
    "    #TTest.loc[var[0],'Feature'] = var[1]\n",
    "    #TTest.loc[var[0],'Student T Test Indep'] = t_test[0]\n",
    "    #TTest.loc[var[0],'Pval'] = t_test[1]\n",
    "    #TTest.sort_values('Pval',ascending=True,inplace=True)    \n",
    "    \n",
    "    # One way Anova\n",
    "    anova_one_way = stats.f_oneway(Survived[var[1]], Died[var[1]])\n",
    "    Anova.loc[var[0],'Feature'] = var[1]\n",
    "    Anova.loc[var[0],'Anova F value'] = anova_one_way[0]\n",
    "    Anova.loc[var[0],'Pval'] = anova_one_way[1]\n",
    "    Anova.sort_values('Pval',ascending=True,inplace=True)  \n",
    "    \n",
    "# LDA\n",
    "lda = LinearDiscriminantAnalysis(n_components = 2, solver='svd')\n",
    "lda.fit(X_train[Quantitative], y_train)\n",
    "Lda['Feature'] = Quantitative\n",
    "Lda['LDA Coef'] = lda.coef_.transpose()\n",
    "Lda.sort_values('LDA Coef',ascending=False,inplace=True)\n",
    "\n",
    "y_train_pred_lda = lda.predict(X_train[Quantitative])\n",
    "y_test_pred_lda = lda.predict(X_test[Quantitative])\n",
    "\n",
    "lda_acc = accuracy_score(y_test, y_test_pred_lda)\n",
    "lda_cr= classification_report(y_test, y_test_pred_lda)\n",
    "lda_cm = confusion_matrix(y_test, y_test_pred_lda)\n",
    "\n",
    "lda_acc_train = accuracy_score(y_train, y_train_pred_lda)\n",
    "lda_cr_train = classification_report(y_train, y_train_pred_lda)\n",
    "lda_cm_train = confusion_matrix(y_train, y_train_pred_lda)\n",
    "\n",
    "# Display results\n",
    "display(PointBiser)\n",
    "#display(TTest)\n",
    "display(Anova)\n",
    "display(Lda)\n",
    "\n",
    "# LDA Results\n",
    "print(\"LDA Results\\n\")\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "print(\"Training set\")\n",
    "print( \"LDA Accuracy :\", lda_acc_train)\n",
    "print(lda_cr_train)\n",
    "print(\"Confusion Matrix :\\n\",lda_cm_train)\n",
    "print('Balance of classes',lda.priors_)\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "print(\"Testing set\")\n",
    "print( \"LDA Accuracy :\", lda_acc)\n",
    "print(lda_cr)\n",
    "print(\"Confusion Matrix :\\n\",lda_cm)\n",
    "print(\"-----------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observations :\n",
    "\n",
    "**Point Biserial Corr - Pearson Corr apply to nominal and continuous features**:\n",
    "* Very Small correlation for Age and Number_of_relatives with high p-values\n",
    "* Positive correlation for Fare and Name_Length with very small p-value\n",
    "    \n",
    "**Anova - Test mean equality between survived and not survived **:\n",
    "* We can reject mean equality for Fare and Length\n",
    "* We can say nothing about Age and Number_of_relatives\n",
    "    \n",
    "**LDA : Linear Discriminant Analysis**\n",
    "* Fare and Length have a positive and high coefficient\n",
    "* Age and Number_of_relatives have a negative and smaller coefficient"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### One Hot Encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note about : 2 test, Cramer V and p-value**\n",
    "\n",
    "The p-value from the 2 test tells you the probability of getting a 2 statistic as extreme or more extreme than yours if the null hypothesis is true, but tells you nothing about how big the effect is.\n",
    "\n",
    "On the other hand, Cramer's V which is based on 2 statistic is a measure of effect size. It tells you how big the effect is but tells you nothing about whether or not the effect is 'significant'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "import scipy.stats as ss\n",
    "\n",
    "def Cramer_Chi2(crosstab):\n",
    "    n = crosstab.sum().sum()\n",
    "    chi2 = ss.chi2_contingency(crosstab)[0]\n",
    "    pval = ss.chi2_contingency(crosstab)[1]\n",
    "    CramerV = np.sqrt(chi2 / (n* (min(crosstab.shape) -1)))\n",
    "    return CramerV, chi2, pval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Features to apply\n",
    "Qualitative = list(combined_One_Hot_Cat.columns)\n",
    "\n",
    "# Concant data and target\n",
    "QF_OH_Target = pd.concat([data[Qualitative],target],axis=1)\n",
    "\n",
    "# Result and temp dataframe\n",
    "confusion_mat = pd.DataFrame()\n",
    "Corr = pd.DataFrame()\n",
    "\n",
    "Corr['Pearson Phi'] = QF_OH_Target.corr(method='pearson')[\"Survived\"]\n",
    "\n",
    "for var in enumerate(Qualitative) : \n",
    "    confusion_mat = pd.crosstab(QF_OH_Target['Survived'], QF_OH_Target[var[1]])\n",
    "    Corr.loc[var[1],'Cramer V'] = Cramer_Chi2(confusion_mat)[0]\n",
    "    Corr.loc[var[1],'Test Chi 2 - Independance'] = Cramer_Chi2(confusion_mat)[1]\n",
    "    Corr.loc[var[1],'Chi 2 Pval']= Cramer_Chi2(confusion_mat)[2]\n",
    "    Corr.loc[var[1],'Hamming Distance'] = distance.hamming(QF_OH_Target['Survived'].astype(int), QF_OH_Target[var[1]].astype(int))\n",
    "    Corr.loc[var[1],'Dice Coefficient'] = distance.dice(QF_OH_Target['Survived'].astype(int), QF_OH_Target[var[1]].astype(int))\n",
    "    \n",
    "Corr.sort_values('Chi 2 Pval',ascending=True,inplace=True)\n",
    "display(Corr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pearson Phi** :\n",
    "* Very small correlation :\n",
    "    - Pclass_2\n",
    "    - Title_aggr_Master\n",
    "    - Name_Size_Very Long\n",
    "    - Title_aggr_Royalty\n",
    "    - Embarked_Q\n",
    "    - Name_Size_Medium\n",
    "* High Correlation\n",
    "    - Positive: \n",
    "        - Sex_female\n",
    "        - Title_aggr_Mrs\n",
    "        - Title_aggr_Miss\n",
    "        - Pclass_1\n",
    "        - Size_Family_Small\n",
    "        - Name_Size_Long\n",
    "    - Negative: \n",
    "        - Sex_male\n",
    "        - Pclass_3\n",
    "\n",
    "**Chi 2 Independance and Cramer V**:\n",
    "* We can reject independance and the Cramer Corelation if high for:\n",
    "    - Title_aggr_Mr \n",
    "    - Sex_female \n",
    "    - Sex_male\n",
    "    --> The information of this 3 features is mostly the same\n",
    "* We can reject independance and the Cramer Correlation is medium for :\n",
    "    - Title_aggr_Mrs \n",
    "    - Title_aggr_Miss \n",
    "    - Pclass_3\n",
    "    - Pclass_1\n",
    "    - Size_Family_Small\n",
    "    - Name_Size_Long\n",
    "    - Size_Family_Alone\n",
    "    - Name_Size_Short\n",
    "* We can reject independance but the Cramer Correlation is low\n",
    "    - Embarked_C\n",
    "    - Embarked_S\n",
    "    - Size_Family_Big\n",
    "* At 5 % we can't reject independance and the Cramer Correlation if very small:\n",
    "    - Name_Size_Very Long\n",
    "    - Title_aggr_Officer\n",
    "    - Title_aggr_Royalty\n",
    "    - Name_Size_Medium\n",
    "    - Embarked_Q \n",
    "        \n",
    "**Hamming distance - Tell us about the numbers of difference** :\n",
    "* High distance\n",
    "    - Sex_male\n",
    "    - Title_aggr_Mr \n",
    "    - Pclass_3\n",
    "    - Size_Family_Alone\n",
    "    - Embarked_S\n",
    "* Medium\n",
    "    - Name_Size_Short\n",
    "    - Name_Size_Medium\n",
    "    - Size_Family_Big\n",
    "    - Embarked_Q\n",
    "    - Pclass_2\n",
    "    - Title_aggr_Officer\n",
    "    - Title_aggr_Royalty\n",
    "    - Name_Size_Very Long \n",
    "    - Title_aggr_Master\n",
    "    - Embarked_C\n",
    "* Small distance\n",
    "    - Size_Family_Small\n",
    "    - Name_Size_Long\n",
    "    - Pclass_1\n",
    "    - Title_aggr_Miss\n",
    "    - Title_aggr_Mrs\n",
    "    - Sex_female\n",
    "   \n",
    "**Dice - Tell us about how much disjoint (0) or equal(1)**:\n",
    "* Mostly disjoint\n",
    "    - Sex_female\n",
    "* Medium\n",
    "    - Size_Family_Alone\n",
    "    - Embarked_C\n",
    "    - Title_aggr_Mrs\n",
    "    - Embarked_S\n",
    "    - Name_Size_Medium\n",
    "    - Pclass_1\n",
    "    - Title_aggr_Miss\n",
    "    - Size_Family_Small\n",
    "* Mostly joint:\n",
    "    - Title_aggr_Royalty\n",
    "    - Name_Size_Very Long\n",
    "    - Title_aggr_Officer\n",
    "    - Size_Family_Big\n",
    "    - Title_aggr_Master\n",
    "    - Embarked_Q\n",
    "    - Title_aggr_Mr\n",
    "    - Name_Size_Short\n",
    "    - Sex_male\n",
    "    - Pclass_3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target and All features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Logistic Regression\n",
    "Lr = pd.DataFrame()\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "Lr['Feature'] = list(X_train.columns)\n",
    "Lr['LR Coef'] = lr.coef_.transpose()\n",
    "Lr.sort_values('LR Coef',ascending=False,inplace=True)\n",
    "\n",
    "y_train_pred_lr = lr.predict(X_train)\n",
    "y_test_pred_lr = lr.predict(X_test)\n",
    "\n",
    "lr_acc = accuracy_score(y_test, y_test_pred_lr)\n",
    "lr_cr= classification_report(y_test, y_test_pred_lr)\n",
    "lr_cm = confusion_matrix(y_test, y_test_pred_lr)\n",
    "\n",
    "lr_acc_train = accuracy_score(y_train, y_train_pred_lr)\n",
    "lr_cr_train = classification_report(y_train, y_train_pred_lr)\n",
    "lr_cm_train = confusion_matrix(y_train, y_train_pred_lr)\n",
    "\n",
    "display(Lr)\n",
    "\n",
    "# Logistic Regression Results\n",
    "print(\"Logistic Regression Results\\n\")\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "print(\"Training set\")\n",
    "print( \"LR Accuracy :\", lr_acc_train)\n",
    "print(lr_cr_train)\n",
    "print(\"Confusion Matrix :\\n\",lr_cm_train)\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "print(\"Testing set\")\n",
    "print( \"LR Accuracy :\", lr_acc)\n",
    "print(lr_cr)\n",
    "print(\"Confusion Matrix :\\n\",lr_cm)\n",
    "print(\"-----------------------------------------------------------------------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "Rf = pd.DataFrame()\n",
    "param_rf = {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 30}\n",
    "rf = RandomForestClassifier(**param_rf)\n",
    "rf.fit(X_train, y_train)\n",
    "Rf['Feature'] = list(X_train.columns)\n",
    "Rf['Rf Coef'] = rf.feature_importances_\n",
    "Rf.sort_values('Rf Coef',ascending=False,inplace=True)\n",
    "\n",
    "y_train_pred_rf = lr.predict(X_train)\n",
    "y_test_pred_rf = lr.predict(X_test)\n",
    "\n",
    "rf_acc = accuracy_score(y_test, y_test_pred_lr)\n",
    "rf_cr= classification_report(y_test, y_test_pred_lr)\n",
    "rf_cm = confusion_matrix(y_test, y_test_pred_lr)\n",
    "\n",
    "rf_acc_train = accuracy_score(y_train, y_train_pred_rf)\n",
    "rf_cr_train = classification_report(y_train, y_train_pred_rf)\n",
    "rf_cm_train = confusion_matrix(y_train, y_train_pred_rf)\n",
    "\n",
    "display(Rf)\n",
    "\n",
    "# Random Forest Results\n",
    "print(\"Random Forest Results\\n\")\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "print(\"Training set\")\n",
    "print( \"RF Accuracy :\", rf_acc_train)\n",
    "print(rf_cr_train)\n",
    "print(\"Confusion Matrix :\\n\",rf_cm_train)\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "print(\"Testing set\")\n",
    "print( \"RF Accuracy :\", rf_acc)\n",
    "print(rf_cr)\n",
    "print(\"Confusion Matrix :\\n\",rf_cm)\n",
    "print(\"-----------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referring to Filter Methods in Feature Selection. You can drop the dummy column that has the lowest relevance to the label(meaning it's correlation tends to 0). The closer the correlation to 0, the lower the relevance to the label, and the higher variation from the the regression line."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Referring to Embedded Methods in Feature Selection from Kaggle. If you have enough large data set for your model to figure out the high correlation between the features, therefore, it will discard redundant features. So, you can leave the decision to your model to see which features can best contribute to the accuracy of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the analysis done just before we can select some features to drop.\n",
    "I took the choice to drop :\n",
    "* Number_of_relatives\n",
    "* Embarked_Q\n",
    "* Embarked_C\n",
    "* Embarked_S\n",
    "* Title_aggr_Royalty\n",
    "* Title_aggr_Officer\n",
    "* Name_Size_Medium\n",
    "* Name_Size_Very Long\n",
    "\n",
    "Because :\n",
    "\n",
    "Number_of_relatives don't seem to correlate well, and the mean between survived does not show good separation. Morevover we still have some informations left into Size_Family\n",
    "\n",
    "For nominals, Cramer V were low and/or we were unable to reject independance with the Chi 2 Test. Moreover Embarked didn't show good separation with the visualization neither Title_aggre_Royality and Officer. For the Name_Size the two usefull label during visualization were Short and Long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display shape before\n",
    "display(data.shape)\n",
    "display(test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dropping the features\n",
    "var_to_drop =['Number_of_relatives','Title_aggr_Royalty','Title_aggr_Officer','Name_Size_Medium','Name_Size_Very Long',\n",
    "           'Embarked_Q','Embarked_C','Embarked_S']\n",
    "\n",
    "data.drop(var_to_drop,axis=1,inplace=True)\n",
    "test_data.drop(var_to_drop,axis=1,inplace=True)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Display shape after\n",
    "display(data.shape)\n",
    "display(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, creation of helper functions to make easy grid search, plotting learning curve and validation curve.\n",
    "\n",
    "Then, the test of Gradient Boosting Classifier, Random Forest Classifier and SVC into one search, before tuning each of this estimators and grouping them into a Voting Classifier. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Helper function to analyse and get result\n",
    "\n",
    "\"\"\" \n",
    "========================\n",
    "Grid Score into a Pandas Dataframe\n",
    "========================\n",
    "\"\"\"\n",
    "def cv_results_to_df(cv_results):\n",
    "    \"\"\"\n",
    "    Convert a sklearn.model_selection.GridSearchCV.cv_results_ attribute to a tidy\n",
    "    pandas DataFrame where the output is filtered with only mean std and params, and sorted by mean test\n",
    "    \"\"\"\n",
    "    df=pd.DataFrame.from_dict(cv_results)\n",
    "    df=df[['mean_test_score', 'std_test_score', 'mean_train_score', 'std_train_score', 'params']]\n",
    "    df.sort_values('mean_test_score',ascending=False,inplace=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "========================\n",
    "Plot confusion matrix \n",
    "========================\n",
    "\"\"\"\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    \n",
    "\n",
    "\"\"\" \n",
    "========================\n",
    "Helper function for GridSearch\n",
    "========================\n",
    "\"\"\"    \n",
    "def grid_search_global(dict_pip, dict_param, class_names, X_train, y_train, X_test, y_test, verbose = 2):\n",
    "    \n",
    "    \"\"\"\n",
    "    This function help doing GridSearch with multiples pipelines of estimators and parameters.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Creation of the return objects\n",
    "    dict_of_res={}\n",
    "    dict_of_best={}\n",
    "    df_results_global=pd.DataFrame()\n",
    "    \n",
    "    print (\"Starting Gridsearch\")\n",
    "    \n",
    "    for key in dict_param.keys():\n",
    "        gs = GridSearchCV(dict_pip[key], dict_param[key], verbose=0, refit=True, n_jobs=-1, cv=5)\n",
    "        gs = gs.fit(X_train, y_train)\n",
    "        dict_of_res[key]=gs.grid_scores_\n",
    "        \n",
    "        # Prediction and scores for the evaluation set\n",
    "        y_test_pred=gs.predict(X_test)\n",
    "        validation_acc = accuracy_score(y_test,y_test_pred)\n",
    "        validation_Fscore = f1_score(y_test,y_test_pred)\n",
    "        confusion_mat = confusion_matrix(y_test,y_test_pred)\n",
    "        precission = precision_score(y_test,y_test_pred)\n",
    "        recall = recall_score(y_test,y_test_pred)\n",
    "        \n",
    "        # Saving of the results\n",
    "        df_results=cv_results_to_df(gs.cv_results_)\n",
    "        df_results['estimator'] = key\n",
    "        df_results['val_score'] = validation_acc\n",
    "        df_results['val_F_score'] = validation_Fscore\n",
    "        df_results['val_Precis'] = precission\n",
    "        df_results['val_Recall'] = recall\n",
    "        df_results['val_Confusion'] = str(confusion_mat)\n",
    "        df_results['|test-train|']=  np.absolute (df_results['mean_train_score'] - df_results['mean_test_score']) \n",
    "        df_results['|val-test|']= np.absolute(df_results['mean_test_score'] - df_results['val_score'])\n",
    "        \n",
    "        \n",
    "        df_results=df_results[['estimator','val_score','mean_test_score', 'mean_train_score', 'std_test_score', 'std_train_score',\n",
    "                               '|val-test|','|test-train|','val_F_score','val_Precis','val_Recall','val_Confusion', 'params']]\n",
    "        df_results_global=df_results_global.append(df_results)\n",
    "        \n",
    "        dict_of_best[key]=[gs.best_score_,gs.best_params_]\n",
    "        \n",
    "        # Display intermediate results\n",
    "        if (verbose > 1) :\n",
    "            print('\\n-------------------------------------------------------------------------------------------------------')\n",
    "            print (\"Gridsearch for \\n   estimator : %s \\n   parameters : %s \\n\" % (key,dict_param[key]))\n",
    "            print (\"Best mean_test_score :\", gs.best_score_)\n",
    "            print (\"Best params :\",gs.best_params_)\n",
    "            print(\"\\nResults for the pipeline \")\n",
    "            display(df_results)\n",
    "        \n",
    "    # Transfrom dict_of_best intro a Dataframe\n",
    "    df_best=pd.DataFrame.from_dict(dict_of_best,'index')\n",
    "    df_best.columns=['Scores','Parameters']\n",
    "    df_best.sort_values('Scores',ascending=False,inplace=True) \n",
    "    \n",
    "    # Sort the Dataframe of golbal results\n",
    "    df_results_global.sort_values('val_score',ascending=False,inplace=True)\n",
    " \n",
    "    # Display final results\n",
    "    if (verbose > 0) :   \n",
    "        print('\\n -------------------------------------------------------------------------------------------------------')\n",
    "        print('\\nList of best score and parameters by pipeline')\n",
    "        display(df_best)\n",
    "        print('\\nSummary')\n",
    "        display(df_results_global) \n",
    "        print('\\n -------------------------------------------------------------------------------------------------------')  \n",
    "    print (\"Gridsearch Finished\")\n",
    "    return df_best, dict_of_best, df_results_global\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "========================\n",
    "Plotting Learning Curves - From scikit learn example\n",
    "========================\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(0.7, 1)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "========================\n",
    "Plotting Validation Curves \n",
    "========================\n",
    "\"\"\"\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "def plot_validation_curve(estimator, estimator_name, param_name, param_range, X, y, cv,\n",
    "    scoring='accuracy', scale='classic' , n_jobs=-1):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generate a simple plot of the validation learning curve.\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "    estimator_name : name of the estimator.\n",
    "    param_range : range of parameters to try.\n",
    "    scoring : scoring metric to use.\n",
    "    scale : classic or semi log scale\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "    cv : int, cross-validation generator or an iterable\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default -1).\n",
    "    \"\"\" \n",
    "    train_scores, test_scores = validation_curve(\n",
    "        estimator, X, y, param_name=param_name, param_range=param_range,\n",
    "        cv=cv, scoring=scoring, n_jobs=n_jobs)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    title_fig='Validation Curve with %s' % estimator_name\n",
    "    plt.title(title_fig)\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(\"Score : %s\" % scoring)\n",
    "    plt.ylim(0.7, 1)\n",
    "    lw = 2\n",
    "    \n",
    "    if (scale=='semilog'):\n",
    "        plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "                     color=\"darkorange\", lw=lw)\n",
    "        plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                         color=\"darkorange\", lw=lw)\n",
    "        plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                     color=\"navy\", lw=lw)\n",
    "        plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                         color=\"navy\", lw=lw)\n",
    "    else :\n",
    "        plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
    "                     color=\"darkorange\", lw=lw)\n",
    "        plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                         color=\"darkorange\", lw=lw)\n",
    "        plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                     color=\"navy\", lw=lw)\n",
    "        plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                         color=\"navy\", lw=lw) \n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multipe Estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train & Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20,random_state = 6725,stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pipeline setup\n",
    "models = { \n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'SVC': SVC()\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params = {\n",
    "    'RandomForestClassifier': { 'n_estimators': [5, 10, 15, 20, 25, 30, 35] },\n",
    "    'GradientBoostingClassifier': { 'n_estimators': [5, 10, 15, 20, 25, 30, 35], 'learning_rate': [0.8, 1.0] },\n",
    "    'SVC': [\n",
    "        {'kernel': ['linear'], 'C': [1, 10]},\n",
    "        {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Start grid search\n",
    "df_best, dic_best, d_res = grid_search_global(dict_pip = models, dict_param = params, class_names = columns_name,\n",
    "                                            X_train = X_train ,y_train = y_train, X_test = X_test, y_test = y_test,\n",
    "                                            verbose = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train & Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20,random_state = 6725,stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pipeline setup\n",
    "models = { \n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params_quick = {\n",
    "    'GradientBoostingClassifier': {'n_estimators': [5, 10, 15, 20], \n",
    "                                   'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "                                   'loss' : ['deviance', 'exponential'],\n",
    "                                   'max_depth' : [3, 5, 7, 10],\n",
    "                                   'min_samples_split': [3, 5, 7],\n",
    "                                   'min_samples_leaf' : [3, 5, 7],\n",
    "                                   'max_features' : [2, 4, 6, 8, 10]\n",
    "                                  }\n",
    "}\n",
    "\n",
    "params_full = {\n",
    "    'GradientBoostingClassifier': { 'n_estimators': range(1,20,1), \n",
    "                                   'learning_rate': [0.05,0.08,0.10,0.12,0.14,0.16],\n",
    "                                  'loss' : ['deviance','exponential'],\n",
    "                                  'max_depth' : range(2,4),\n",
    "                                   'min_samples_split': range(2,10,1),\n",
    "                                   'min_samples_leaf' : range(2,10,1),\n",
    "                                   'max_features' : range(1,15,1)\n",
    "                                  }\n",
    "}\n",
    "\n",
    "params = params_quick\n",
    "\n",
    "# Start grid search\n",
    "df_best_gbc, dic_best_gbc, d_res_gbc = grid_search_global(dict_pip = models, dict_param = params, class_names = columns_name,\n",
    "                                            X_train = X_train ,y_train = y_train, X_test = X_test, y_test = y_test,\n",
    "                                            verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter results\n",
    "d_res_gbc.sort_values(by=['val_score','std_test_score'],ascending=[False,True],inplace=True)\n",
    "d_res_gbc_sort = d_res_gbc.loc[(d_res_gbc['val_score'] > 0.80) \n",
    "              & (d_res_gbc['|val-test|'] < 0.015) \n",
    "              & (d_res_gbc['|test-train|'] < 0.015)  \n",
    "              & (d_res_gbc['std_test_score'] < 0.015) \n",
    "              & (d_res_gbc['std_train_score'] < 0.015)]\n",
    "display(d_res_gbc_sort)\n",
    "\n",
    "# Take care not to search for too small values because it will certainly lead to overfitting our split of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selection of the parameters to study\n",
    "index_selection_gbc = [177, 130, 106, 63, 87, 86]\n",
    "df_study_gbc = d_res_gbc.loc[index_selection_gbc,['estimator','params','val_score','mean_test_score','mean_train_score','val_F_score']]\n",
    "display(df_study_gbc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Learning curve\n",
    "index = list(df_study_gbc.index)\n",
    "for ind in index :\n",
    "    estim = df_study_gbc.loc[ind, 'estimator']\n",
    "    params = df_study_gbc.loc[ind, 'params']\n",
    "    val_score = df_study_gbc.loc[ind, 'val_score']\n",
    "    mean_test = df_study_gbc.loc[ind, 'mean_test_score']\n",
    "    mean_train = df_study_gbc.loc[ind, 'mean_train_score']\n",
    "    title = \"Learning Curves for the estimator %s which results are \\n mean test: %s \\n mean train: %s \\n val_score : %s \\n with parameters %s)\" % (estim,mean_test,mean_train,val_score,params)\n",
    "    cv = ShuffleSplit(n_splits=50, test_size=0.2, random_state=0)\n",
    "    estimator = models[estim]\n",
    "    estimator.set_params(**params)\n",
    "    plot_learning_curve(estimator, title, data, target, (0.3, 1.01), cv=cv, n_jobs=-1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validation curve\n",
    "dict_Validation = { \n",
    "    'GradientBoostingClassifier':  { 'n_estimators': range(5,100,5), \n",
    "                                     'learning_rate': [0.01,0.03,0.1,0.2,0.3,0.4,0.5,0.6,0.7],\n",
    "                                     'max_depth' : range(2,10,1),\n",
    "                                     'min_samples_split': range(2,10,1),\n",
    "                                     'min_samples_leaf' : range(2,10,1),\n",
    "                                     'max_features' : range(2,19,1)\n",
    "                                  } \n",
    "}\n",
    "\n",
    "for ind in index :\n",
    "    \n",
    "    estim = df_study_gbc.loc[ind, 'estimator']\n",
    "    params = df_study_gbc.loc[ind, 'params']\n",
    "    mean_test = df_study_gbc.loc[ind, 'mean_test_score']\n",
    "    mean_train = df_study_gbc.loc[ind, 'mean_train_score']\n",
    "    val_score = df_study_gbc.loc[ind, 'val_score']\n",
    "    \n",
    "    print(\"Model: %s\\nMean test: %s\\nMean train: %s\\nVal score: %s \\nParams: %s\" % (estim,mean_test,mean_train,val_score,params))\n",
    "    \n",
    "    estimator = models[estim]\n",
    "    estimator.set_params(**params)\n",
    "    \n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "    \n",
    "    for key, value in dict_Validation[estim].items():\n",
    "        plot_validation_curve(estimator, estim, key, value, X_train, y_train, scoring='accuracy', cv=cv)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prediction \n",
    "GBC_params =  {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 3, 'max_features': 4, 'min_samples_leaf': 7, 'min_samples_split': 7, 'n_estimators': 10}\n",
    "gbc = GradientBoostingClassifier(**GBC_params)\n",
    "gbc.fit(X_train,y_train)\n",
    "gbc_pred = gbc.predict(test_data)\n",
    "Prediction['GBC'] = gbc_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train & Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20,random_state = 6725,stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pipeline setup\n",
    "models = { \n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params_quick = {\n",
    "    'RandomForestClassifier': { 'n_estimators': [5,10,15,20,30,100],\n",
    "                               'criterion' : ['gini','entropy'],\n",
    "                               'max_depth' : [3,5,8,10,15,20],\n",
    "                               'max_features':[2,4,6,8],\n",
    "                               'min_samples_split': [3,5,7],\n",
    "                               'min_samples_leaf':  [3,5,7]\n",
    "                              }\n",
    "}\n",
    "\n",
    "params_full = {\n",
    "    'RandomForestClassifier': { 'n_estimators': range(1,20,1),\n",
    "                               'criterion' : ['gini','entropy'],\n",
    "                               'max_features':range(1,20,1),\n",
    "                               'max_depth' : range(3,10,1),\n",
    "                               'min_samples_split': range(2,10,1),\n",
    "                               'min_samples_leaf':  range(1,10,1)\n",
    "                              }\n",
    "}\n",
    "\n",
    "params = params_quick\n",
    "\n",
    "# Lancer la grid search\n",
    "df_best_rf, dic_best_rf, d_res_rf = grid_search_global(dict_pip = models, dict_param = params, class_names = columns_name,\n",
    "                                            X_train = X_train ,y_train = y_train, X_test = X_test, y_test = y_test,\n",
    "                                            verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter results\n",
    "d_res_rf.sort_values(by=['val_score','std_test_score'],ascending=[False,True],inplace=True)\n",
    "d_res_rf_sort = d_res_rf.loc[(d_res_rf['val_score'] > 0.80) \n",
    "              & (d_res_rf['|val-test|'] < 0.015) \n",
    "              & (d_res_rf['|test-train|'] < 0.015)  \n",
    "              & (d_res_rf['std_test_score'] < 0.015) \n",
    "              & (d_res_rf['std_train_score'] < 0.015)]\n",
    "display(d_res_rf_sort)\n",
    "\n",
    "# Take care not to search for too small values because it will certainly lead to overfitting our split of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Selection of the parameters to study\n",
    "index_selection_rf = [177, 130, 106, 63, 87, 86]\n",
    "df_study_rf = d_res_rf.loc[index_selection_rf,['estimator','params','val_score','mean_test_score','mean_train_score','val_F_score']]\n",
    "display(df_study_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Learning curve\n",
    "index = list(df_study_rf.index)\n",
    "for ind in index :\n",
    "    estim = df_study_rf.loc[ind, 'estimator']\n",
    "    params = df_study_rf.loc[ind, 'params']\n",
    "    val_score = df_study_rf.loc[ind, 'val_score']\n",
    "    mean_test = df_study_rf.loc[ind, 'mean_test_score']\n",
    "    mean_train = df_study_rf.loc[ind, 'mean_train_score']\n",
    "    title = \"Learning Curves for the estimator %s which results are \\n mean test: %s \\n mean train: %s \\n val_score : %s \\n with parameters %s)\" % (estim,mean_test,mean_train,val_score,params)\n",
    "    cv = ShuffleSplit(n_splits=50, test_size=0.2, random_state=0)\n",
    "    estimator = models[estim]\n",
    "    estimator.set_params(**params)\n",
    "    plot_learning_curve(estimator, title, data, target, (0.3, 1.01), cv=cv, n_jobs=-1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Validation curve\n",
    "dict_Validation = { \n",
    "    'RandomForestClassifier': {'n_estimators': range(1,50,2),\n",
    "                               'max_features':range(1,20,1),\n",
    "                               'min_samples_split': range(2,10,1),\n",
    "                               'min_samples_leaf': range(2,10,1)}  \n",
    "}\n",
    "\n",
    "for ind in index :\n",
    "    \n",
    "    estim = df_study_rf.loc[ind, 'estimator']\n",
    "    params = df_study_rf.loc[ind, 'params']\n",
    "    mean_test = df_study_rf.loc[ind, 'mean_test_score']\n",
    "    mean_train = df_study_rf.loc[ind, 'mean_train_score']\n",
    "    val_score = df_study_rf.loc[ind, 'val_score']\n",
    "    \n",
    "    print(\"Model: %s\\nMean test: %s\\nMean train: %s\\nVal score: %s \\nParams: %s\" % (estim,mean_test,mean_train,val_score,params))\n",
    "    \n",
    "    estimator = models[estim]\n",
    "    estimator.set_params(**params)\n",
    "    \n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "    \n",
    "    for key, value in dict_Validation[estim].items():\n",
    "        plot_validation_curve(estimator, estim, key, value, X_train, y_train, scoring='accuracy', cv=cv)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prediction \n",
    "RF_params =  {'criterion': 'entropy', 'max_features': 12, 'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 10}\n",
    "rf = RandomForestClassifier(**RF_params)\n",
    "rf.fit(X_train,y_train)\n",
    "rf_pred = rf.predict(test_data)\n",
    "Prediction['RF'] = rf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get and display feature importance for Random Forest model with parameters from behind\n",
    "Rf_feat_imp = pd.DataFrame()\n",
    "Rf_feat_imp['Feature'] = list(data.columns)\n",
    "Rf_feat_imp['Importance'] = rf.feature_importances_\n",
    "Rf_feat_imp.sort_values('Importance',ascending=False,inplace=True)\n",
    "display(Rf_feat_imp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train & Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20,random_state = 6725,stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pipeline setup\n",
    "models = { \n",
    "    'SVC': SVC()\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params = {\n",
    "    'SVC': [\n",
    "        {'kernel': ['poly'], \n",
    "             'C': [0.03,0.1,0.3,1,3,10,30], \n",
    "             'gamma': ['auto',0.03,0.1,0.3,1,3,10,30],\n",
    "             'degree': range(1,5)},\n",
    "        {'kernel': ['rbf'], \n",
    "             'C': [0.03,0.1,0.3,1,3,10,30], \n",
    "             'gamma': ['auto',0.03,0.1,0.3,1,3,10,30]},\n",
    "        {'kernel': ['linear'], \n",
    "             'C': [0.03,0.1,0.3,1,3,10,30]}\n",
    "    ]\n",
    "\n",
    "}\n",
    "\n",
    "# Start grid search\n",
    "df_best_svc , dic_best_svc, d_res_svc = grid_search_global(dict_pip = models, dict_param = params, class_names = columns_name,\n",
    "                                            X_train = X_train ,y_train = y_train, X_test = X_test, y_test = y_test,\n",
    "                                            verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Filter results\n",
    "d_res_svc.sort_values(by=['val_score','std_test_score'],ascending=[False,True],inplace=True)\n",
    "d_res_svc_sort = d_res_svc.loc[(d_res_svc['val_score'] > 0.80) \n",
    "              & (d_res_svc['|val-test|'] < 0.015) \n",
    "              & (d_res_svc['|test-train|'] < 0.015)  \n",
    "              & (d_res_svc['std_test_score'] < 0.015) \n",
    "              & (d_res_svc['std_train_score'] < 0.015)]\n",
    "display(d_res_svc_sort)\n",
    "\n",
    "# Take care not to search for too small values because it will certainly lead to overfit to the split of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Selection of the parameters to study\n",
    "index_selection_svc = [177, 130, 106, 63, 87, 86]\n",
    "df_study_svc = d_res_svc.loc[index_selection_svc,['estimator','params','val_score','mean_test_score','mean_train_score','val_F_score']]\n",
    "display(df_study_svc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Learning curve\n",
    "index = list(df_study_svc.index)\n",
    "for ind in index :\n",
    "    estim = df_study_svc.loc[ind, 'estimator']\n",
    "    params = df_study_svc.loc[ind, 'params']\n",
    "    val_score = df_study_svc.loc[ind, 'val_score']\n",
    "    mean_test = df_study_svc.loc[ind, 'mean_test_score']\n",
    "    mean_train = df_study_svc.loc[ind, 'mean_train_score']\n",
    "    title = \"Learning Curves for the estimator %s which results are \\n mean test: %s \\n mean train: %s \\n val_score : %s \\n with parameters %s)\" % (estim,mean_test,mean_train,val_score,params)\n",
    "    cv = ShuffleSplit(n_splits=50, test_size=0.2, random_state=0)\n",
    "    estimator = models[estim]\n",
    "    estimator.set_params(**params)\n",
    "    plot_learning_curve(estimator, title, data, target, (0.3, 1.01), cv=cv, n_jobs=-1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Validation curve\n",
    "dict_Validation = { \n",
    "    'SVC': { 'C': np.linspace(0.01,10,25),\n",
    "              'gamma': np.linspace(0.01,1,25),\n",
    "              'degree': range(2,5)}  \n",
    "    }\n",
    "\n",
    "\n",
    "for ind in index :\n",
    "    \n",
    "    estim = df_study_svc.loc[ind, 'estimator']\n",
    "    params = df_study_svc.loc[ind, 'params']\n",
    "    mean_test = df_study_svc.loc[ind, 'mean_test_score']\n",
    "    mean_train = df_study_svc.loc[ind, 'mean_train_score']\n",
    "    val_score = df_study_svc.loc[ind, 'val_score']\n",
    "    \n",
    "    print(\"Model: %s\\nMean test: %s\\nMean train: %s\\nVal score: %s \\nParams: %s\" % (estim,mean_test,mean_train,val_score,params))\n",
    "    \n",
    "    estimator = models[estim]\n",
    "    estimator.set_params(**params)\n",
    "    \n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "    \n",
    "    for key, value in dict_Validation[estim].items():\n",
    "        plot_validation_curve(estimator, estim, key, value, X_train, y_train, scoring='accuracy', cv=cv)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "svc_params = {'C': 0.8, 'degree': 2, 'gamma': 0.08, 'kernel': 'poly'}\n",
    "svc = SVC(**svc_params)\n",
    "svc.fit(data,target)\n",
    "svc_pred = svc.predict(test_data)\n",
    "Prediction['SVC'] = svc_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train & Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20,random_state = 6725,stratify=target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Classifier default parameters\n",
    "svc = SVC(probability=True)\n",
    "rfc = RandomForestClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Classifier Tunep parameters\n",
    "GBC_params = {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3, 'max_features': 10, 'min_samples_leaf': 7, 'min_samples_split': 5, 'n_estimators': 10}\n",
    "RF_params =  {'criterion': 'entropy', 'max_features': 4, 'min_samples_leaf': 8, 'min_samples_split': 9, 'n_estimators': 11}\n",
    "SVC_params = {'probability'= True}\n",
    "\n",
    "rfc_tp = RandomForestClassifier(**RF_params)\n",
    "gbc_tp = GradientBoostingClassifier(**GBC_params)\n",
    "svc_tp = SVC(**SVC_params)\n",
    "\n",
    "# Pipeline setup\n",
    "# Estimators must be filled during the creation of the classifier\n",
    "models = { \n",
    "    'VotingClassifier': VotingClassifier(estimators= [('svc_tp', svc_tp),('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)])\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params = {'VotingClassifier' : {'voting': ['soft','hard'] ,\n",
    "                                'estimators' : [\n",
    "                                    [('svc_tp', svc_tp),('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)],\n",
    "                                    [('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)],\n",
    "                                    [('svc', svc),('rfc', rfc), ('gbc', gbc)],\n",
    "                                    [('rfc', rfc), ('gbc', gbc)]\n",
    "                                    ]                   \n",
    "                               }\n",
    " }\n",
    "\n",
    "# Start grid search\n",
    "df_best_vc , dic_best_vc, d_res_vc = grid_search_global(dict_pip = models, dict_param = params, class_names = columns_name,\n",
    "                                            X_train = X_train ,y_train = y_train, X_test = X_test, y_test = y_test,\n",
    "                                            verbose = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "GBC_params = {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3, 'max_features': 10, 'min_samples_leaf': 7, 'min_samples_split': 5, 'n_estimators': 10}\n",
    "RF_params =  {'criterion': 'entropy', 'max_features': 4, 'min_samples_leaf': 8, 'min_samples_split': 9, 'n_estimators': 11}\n",
    "SVC_params = {'probability'= True,}\n",
    "\n",
    "rfc_tp = RandomForestClassifier(**RF_params)\n",
    "gbc_tp = GradientBoostingClassifier(**GBC_params)\n",
    "svc_tp = SVC(**SVC_params)\n",
    "\n",
    "VC_tp_soft = VotingClassifier(estimators=[('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)],   \n",
    "                                         voting='soft')\n",
    "VC_tp_soft.fit(X_train,y_train)\n",
    "Prediction['VC_tp_soft'] = VC_tp_soft.predict(Eval_OH_Std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[[back to top](#Table-of-contents)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Choose the prediction to submit \n",
    "#Predic = Prediction['GBC']\n",
    "#Predic = Prediction['RF']\n",
    "Predic = Prediction['SVC']\n",
    "#Predic = Prediction['VC_tp_soft']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save into a csv to submit\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": PassengerId,\n",
    "        \"Survived\": Predic\n",
    "    })\n",
    "submission.to_csv('titanic_SVC.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    " ### END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.79-0.81 with PassId_0.81 and without ticket and cabin and dropping 'Title_aggr_Royalty','Title_aggr_Officer','Name_Size_Medium','Embarked_Q'\n",
    "GBC_params = {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3, 'max_features': 10, 'min_samples_leaf': 7, 'min_samples_split': 6, 'n_estimators': 10}\n",
    "# 0.80 same conditions\n",
    "RF_params =  {'criterion': 'entropy', 'max_features': 10, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 30}\n",
    "#0.79\n",
    "VotingClassifier(estimators=[('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)],voting='soft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save X_train and y_train that generalize well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pass_Id = list(X_train.index)\n",
    "Pass_Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Res_gbc  =pd.DataFrame()\n",
    "Res_rf  =pd.DataFrame()\n",
    "\n",
    "for i in range(1,100) :\n",
    "    print('Step',i)\n",
    "    RS = np.random.randint(10000)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20,random_state = RS,stratify=target)\n",
    "\n",
    "    # Pipeline setup\n",
    "    model_gbc = { \n",
    "        'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    }\n",
    "\n",
    "    # Parameters setup\n",
    "    params_gbc = {\n",
    "        'GradientBoostingClassifier': { 'n_estimators': [5,10,15,20], \n",
    "                                       'learning_rate': [0.05,0.1,0.2],\n",
    "                                      'loss' : ['deviance','exponential'],\n",
    "                                      'max_depth' : [3],\n",
    "                                       'min_samples_split': [3,5,7],\n",
    "                                       'min_samples_leaf' : [3,5,7],\n",
    "                                       'max_features' : [2,4,6,8,10]\n",
    "                                      }\n",
    "    }\n",
    "\n",
    "    # Lancer la grid search\n",
    "    df_best_gbc, dic_best_gbc, d_res_gbc =grid_search_global(model_gbc,params_gbc,class_names=columns_name)\n",
    "\n",
    "    model_rf = { \n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    }\n",
    "\n",
    "    # Parameters setup\n",
    "    params_rf = {\n",
    "    # Il faut mettre 'ExtraTreesClassifier__n_estimators' dans 'ExtraTreesClassifier' car on est sur un pipeline \n",
    "    # il est donc possible de prciser des parametres pour chacune des tapes\n",
    "    'RandomForestClassifier': { 'n_estimators': [5,10,15,20,30],\n",
    "                               'criterion' : ['gini','entropy'],\n",
    "                               'max_depth' : [3,9,15,30],\n",
    "                               'max_features':[2,4,6,8],\n",
    "                               'min_samples_split': [3,5,7],\n",
    "                               'min_samples_leaf':  [3,5,7]\n",
    "                              }\n",
    "    }\n",
    "\n",
    "    # Lancer la grid search\n",
    "    df_best_rf, dic_best_rf, d_res_rf =grid_search_global(model_rf,params_rf,class_names=columns_name)\n",
    "\n",
    "    # Results dataframe\n",
    "    d_res_gbc['Random_state'] = RS\n",
    "    d_res_gbc.sort_values(by=['Val_Acc','std_test_score'],ascending=[False,True],inplace=True)\n",
    "    d_res_gbc_sort = d_res_gbc.loc[(d_res_gbc['Val_Acc'] > 0.80) \n",
    "                  & (d_res_gbc['Diff_test_val'] < 0.01) \n",
    "                  & (d_res_gbc['Diff_train_test'] < 0.01)  \n",
    "                  & (d_res_gbc['std_test_score'] < 0.01) \n",
    "                  & (d_res_gbc['std_train_score'] < 0.01)]\n",
    "    Res_gbc = Res_gbc.append(d_res_gbc_sort)\n",
    "    \n",
    "    # Results dataframe\n",
    "    d_res_rf['Random_state'] = RS\n",
    "    d_res_rf.sort_values(by=['Val_Acc','std_test_score'],ascending=[False,True],inplace=True)\n",
    "    d_res_rf_sort = d_res_rf.loc[(d_res_rf['Val_Acc'] > 0.80) \n",
    "                  & (d_res_rf['Diff_test_val'] < 0.01) \n",
    "                  & (d_res_rf['Diff_train_test'] < 0.01)  \n",
    "                  & (d_res_rf['std_test_score'] < 0.01) \n",
    "                  & (d_res_rf['std_train_score'] < 0.01)]\n",
    "    Res_rf = Res_rf.append(d_res_rf_sort)   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "GradientBoostingClassifier : {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3, 'max_features': 16, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 20}\t0.839888\t0.851827\n",
    "GradientBoostingClassifier : {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3, 'max_features': 16, 'min_samples_leaf': 7, 'min_samples_split': 4, 'n_estimators': 20}\t0.839888\t0.852178\n",
    "GradientBoostingClassifier : {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3, 'max_features': 10, 'min_samples_leaf': 7, 'min_samples_split': 6, 'n_estimators': 10}\t0.838483\t0.845508\n",
    "GradientBoostingClassifier : {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3, 'max_features': 10, 'min_samples_leaf': 7, 'min_samples_split': 6, 'n_estimators': 15}\t0.838483\t0.845155\n",
    "\n",
    "\n",
    "{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3, 'max_features': 10, 'min_samples_leaf': 7, 'min_samples_split': 6, 'n_estimators': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RF\n",
    "# data.drop(['Title_aggr_Royalty','Title_aggr_Officer','Name_Size_Medium','Embarked_Q'],axis=1,inplace=True)\n",
    "# {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 30}\n",
    "# Score 80.803 leader board, train with X_train or all data "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
