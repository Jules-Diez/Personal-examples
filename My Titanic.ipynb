{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Titanic: Machine Learning from Disaster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sinking of the RMS Titanic is one of the most infamous shipwrecks in history.  On April 15, 1912, during her maiden voyage, the Titanic sank after colliding with an iceberg, killing 1502 out of 2224 passengers and crew. This sensational tragedy shocked the international community and led to better safety regulations for ships."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predict what sorts of people were likely to survive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspiration:\n",
    "   - https://www.kaggle.com/omarelgabry/titanic/a-journey-through-titanic\n",
    "   - https://www.kaggle.com/poonaml/titanic/titanic-survival-prediction-end-to-end-ml-pipeline\n",
    "   - https://www.kaggle.com/helgejo/titanic/an-interactive-data-science-tutorial\n",
    "   - https://www.kaggle.com/arthurlu/titanic/exploratory-tutorial-titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "- [Description of the data set](#Description-of-the-data-set)\n",
    "- [First look at the data](#First-look-at-the-data)\n",
    "    - [Import Libraries](#Import-Libraries)\n",
    "    - [Load Data](#Load-Data)\n",
    "    - [Brief summaries](#Brief-summaries)\n",
    "- [Visualization](#Visualization)\n",
    "    - [Basic insight of the data](#Basic-insight-of-the-data)\n",
    "    - [Focus on the mean of survival](#Focus-on-the-mean-of-survival)\n",
    "- [Missing Values](#Missing-Values)\n",
    "    - [Embarked](#Embarked)\n",
    "    - [Fare](#Fare)\n",
    "    - [Age with Median](#Age-with-median)\n",
    "- [Features engineering](#Features-engineering)\n",
    "    - [Name](#Name)\n",
    "    - [Family](#Family)\n",
    "    - [Name](#Name)\n",
    "- [Visualization new Features](#Visualization-new-features)\n",
    "    - [Visualization Name](#Visualization-Name)\n",
    "    - [Visualization Family](#Visualization-Family)\n",
    "- [Features Encoding](#Features-Encoding)\n",
    "    - [Categorial features encoding](#Categorial features encoding)\n",
    "        - [Label Encoding](#Label-Encoding)\n",
    "        - [One Hot Encoding](#One-Hot-Encodingn)   \n",
    "    - [Feature Scalling](#Feature-Scalling)\n",
    "    - [Data Preparation](#Data-Preparation)\n",
    "- [Features Importance](#Features-Importance)\n",
    "    - [Correlation - Numerical label](#Correlation---Numerical-label)\n",
    "    - [Correlation - One Hot Encoder](#Correlation---One-Hot-Encoder)\n",
    "    - [LDA](#LDA)\n",
    "    - [Select K Best](#Select-K-Best)\n",
    "- [Model Selection](#Model-Selection)\n",
    "    - [Helper function](#Helper-function)\n",
    "    - [Gradient Boosting Classifier](#Gradient-Boosting-Classifier)\n",
    "    - [Random Forest Classifier](#Random-Forest-Classifier)\n",
    "    - [Adaboost](#Adaboost)\n",
    "    - [SVC](#SVC)\n",
    "    - [Logistic Regression](#Logistic-Regression)\n",
    "    - [Voting Classifier](#Voting-Classifier)\n",
    "- [Submission](#Submission)\n",
    "\n",
    "\n",
    "\n",
    "- [Feature Selection](#Feature-selection)\n",
    "- [Feature Selection](#Feature-selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description of the data set"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "VARIABLE DESCRIPTIONS:\n",
    "survival        Survival\n",
    "                (0 = No; 1 = Yes)\n",
    "pclass          Passenger Class\n",
    "                (1 = 1st; 2 = 2nd; 3 = 3rd)\n",
    "name            Name\n",
    "sex             Sex\n",
    "age             Age\n",
    "sibsp           Number of Siblings/Spouses Aboard\n",
    "parch           Number of Parents/Children Aboard\n",
    "ticket          Ticket Number\n",
    "fare            Passenger Fare\n",
    "cabin           Cabin\n",
    "embarked        Port of Embarkation\n",
    "                (C = Cherbourg; Q = Queenstown; S = Southampton)\n",
    "\n",
    "SPECIAL NOTES:\n",
    "Pclass is a proxy for socio-economic status (SES)\n",
    " 1st ~ Upper; 2nd ~ Middle; 3rd ~ Lower\n",
    "\n",
    "Age is in Years; Fractional if Age less than One (1)\n",
    " If the Age is Estimated, it is in the form xx.5\n",
    "\n",
    "With respect to the family relation variables (i.e. sibsp and parch)\n",
    "some relations were ignored.  The following are the definitions used\n",
    "for sibsp and parch.\n",
    "\n",
    "Sibling:  Brother, Sister, Stepbrother, or Stepsister of Passenger Aboard Titanic\n",
    "Spouse:   Husband or Wife of Passenger Aboard Titanic (Mistresses and Fiances Ignored)\n",
    "Parent:   Mother or Father of Passenger Aboard Titanic\n",
    "Child:    Son, Daughter, Stepson, or Stepdaughter of Passenger Aboard Titanic\n",
    "\n",
    "Other family relatives excluded from this study include cousins,\n",
    "nephews/nieces, aunts/uncles, and in-laws.  Some children travelled\n",
    "only with a nanny, therefore parch=0 for them.  As well, some\n",
    "travelled with very close friends or neighbors in a village, however,\n",
    "the definitions do not support such relations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First look at the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jules/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# Dataframe\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "from IPython.display import display, HTML\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pprint import pprint\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "# Sklearn\n",
    "import sklearn as sk\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelEncoder,StandardScaler\n",
    "# Features and model selection\n",
    "from sklearn.cross_validation import KFold\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "# Metric\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "# Classifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import (ExtraTreesClassifier, RandomForestClassifier, \n",
    "                              AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier)\n",
    "\n",
    "# Warning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data directly into a dataframe\n",
    "df_train=pd.read_csv(\"Data/Titanic/train.csv\")\n",
    "df_test=pd.read_csv(\"Data/Titanic/test.csv\")\n",
    "\n",
    "# Get a look at the first rows\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable Description\n",
    "    - Survived: Survived (1) or died (0)\n",
    "    - Pclass: Passenger's class\n",
    "    - Name: Passenger's name\n",
    "    - Sex: Passenger's sex\n",
    "    - Age: Passenger's age\n",
    "    - SibSp: Number of siblings/spouses aboard\n",
    "    - Parch: Number of parents/children aboard\n",
    "    - Ticket: Ticket number\n",
    "    - Fare: Fare\n",
    "    - Cabin: Cabin\n",
    "    - Embarked: Port of embarkation\n",
    "    \n",
    "    Source of information : https://www.kaggle.com/c/titanic/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Brief summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------Informations for the training set----------------------------------\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      "PassengerId    891 non-null int64\n",
      "Survived       891 non-null int64\n",
      "Pclass         891 non-null int64\n",
      "Name           891 non-null object\n",
      "Sex            891 non-null object\n",
      "Age            714 non-null float64\n",
      "SibSp          891 non-null int64\n",
      "Parch          891 non-null int64\n",
      "Ticket         891 non-null object\n",
      "Fare           891 non-null float64\n",
      "Cabin          204 non-null object\n",
      "Embarked       889 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.6+ KB\n",
      "\n",
      " PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64\n",
      "\n",
      "----------------------------------Informations for the testing set ----------------------------------\n",
      "\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 11 columns):\n",
      "PassengerId    418 non-null int64\n",
      "Pclass         418 non-null int64\n",
      "Name           418 non-null object\n",
      "Sex            418 non-null object\n",
      "Age            332 non-null float64\n",
      "SibSp          418 non-null int64\n",
      "Parch          418 non-null int64\n",
      "Ticket         418 non-null object\n",
      "Fare           417 non-null float64\n",
      "Cabin          91 non-null object\n",
      "Embarked       418 non-null object\n",
      "dtypes: float64(2), int64(4), object(5)\n",
      "memory usage: 36.0+ KB\n",
      "\n",
      " PassengerId      0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age             86\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             1\n",
      "Cabin          327\n",
      "Embarked         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"----------------------------------Informations for the training set----------------------------------\\n\")\n",
    "df_train.info()\n",
    "print('\\n',df_train.isnull().sum())\n",
    "print(\"\\n----------------------------------Informations for the testing set ----------------------------------\\n\")\n",
    "df_test.info()\n",
    "print('\\n',df_test.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that:\n",
    "    - No Survived feature on the testing set\n",
    "    - Cabin feature is mostly null --> Will be dropped\n",
    "    - Embarked feature has a few missing values\n",
    "    - Some Ages are missing --> Will need to be completed or drop the missing rows\n",
    "    - Survived and Pclass should be treated as object because they are qualitative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Dropping Cabin, Ticket and PassengerId\n",
    "df_train=df_train.drop(['Cabin','PassengerId','Ticket'], axis=1)\n",
    "\n",
    "df_test=df_test.drop(['Cabin','Ticket'], axis=1)\n",
    "PassengerId = df_test['PassengerId']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Changing the type of Pclass and Survived \n",
    "df_train['Pclass']=df_train['Pclass'].astype(object)\n",
    "df_train['Survived']=df_train['Survived'].astype(object)\n",
    "\n",
    "df_test['Pclass']=df_test['Pclass'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------Informations for the training set----------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age       SibSp       Parch        Fare\n",
       "count  714.000000  891.000000  891.000000  891.000000\n",
       "mean    29.699118    0.523008    0.381594   32.204208\n",
       "std     14.526497    1.102743    0.806057   49.693429\n",
       "min      0.420000    0.000000    0.000000    0.000000\n",
       "25%     20.125000    0.000000    0.000000    7.910400\n",
       "50%     28.000000    0.000000    0.000000   14.454200\n",
       "75%     38.000000    1.000000    0.000000   31.000000\n",
       "max     80.000000    8.000000    6.000000  512.329200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>891</td>\n",
       "      <td>889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>891</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Newell, Mr. Arthur Webster</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>549</td>\n",
       "      <td>491</td>\n",
       "      <td>1</td>\n",
       "      <td>577</td>\n",
       "      <td>644</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Survived  Pclass                        Name   Sex Embarked\n",
       "count        891     891                         891   891      889\n",
       "unique         2       3                         891     2        3\n",
       "top            0       3  Newell, Mr. Arthur Webster  male        S\n",
       "freq         549     491                           1   577      644"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------Informations for the testing set----------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418.000000</td>\n",
       "      <td>332.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>418.000000</td>\n",
       "      <td>417.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>30.272590</td>\n",
       "      <td>0.447368</td>\n",
       "      <td>0.392344</td>\n",
       "      <td>35.627188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>120.810458</td>\n",
       "      <td>14.181209</td>\n",
       "      <td>0.896760</td>\n",
       "      <td>0.981429</td>\n",
       "      <td>55.907576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>892.000000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>996.250000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1100.500000</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1204.750000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1309.000000</td>\n",
       "      <td>76.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId         Age       SibSp       Parch        Fare\n",
       "count   418.000000  332.000000  418.000000  418.000000  417.000000\n",
       "mean   1100.500000   30.272590    0.447368    0.392344   35.627188\n",
       "std     120.810458   14.181209    0.896760    0.981429   55.907576\n",
       "min     892.000000    0.170000    0.000000    0.000000    0.000000\n",
       "25%     996.250000   21.000000    0.000000    0.000000    7.895800\n",
       "50%    1100.500000   27.000000    0.000000    0.000000   14.454200\n",
       "75%    1204.750000   39.000000    1.000000    0.000000   31.500000\n",
       "max    1309.000000   76.000000    8.000000    9.000000  512.329200"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>418</td>\n",
       "      <td>418</td>\n",
       "      <td>418</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3</td>\n",
       "      <td>418</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>3</td>\n",
       "      <td>Caram, Mr. Joseph</td>\n",
       "      <td>male</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>218</td>\n",
       "      <td>1</td>\n",
       "      <td>266</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Pclass               Name   Sex Embarked\n",
       "count      418                418   418      418\n",
       "unique       3                418     2        3\n",
       "top          3  Caram, Mr. Joseph  male        S\n",
       "freq       218                  1   266      270"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Basic statistical information about quantitative and qualitative columns\n",
    "\n",
    "print(\"----------------------------------Informations for the training set----------------------------------\\n\")\n",
    "# Quantitative\n",
    "display(df_train.describe())\n",
    "# Qualitative\n",
    "display(df_train.describe(include=['object']))\n",
    "print(\"----------------------------------Informations for the testing set----------------------------------\\n\")\n",
    "# Quantitative\n",
    "display(df_test.describe())\n",
    "# Qualitative\n",
    "display(df_test.describe(include=['object']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic insight of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Qualitative Data : [Survived, Sex, Embarked, Pclass] \n",
    "fig, (axis1,axis2,axis3,axis4) = plt.subplots(1,4,figsize=(15,5))\n",
    "sns.countplot(x='Survived', data=df_train, ax=axis1)\n",
    "sns.countplot(x='Sex', data=df_train, ax=axis2)\n",
    "sns.countplot(x='Embarked', data=df_train, ax=axis3)\n",
    "sns.countplot(x='Pclass', data=df_train, ax=axis4)\n",
    "fig.suptitle(\"Basic representation of Qualitative data with count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Discrete Quantitative Data : [SibSp, Parch] \n",
    "fig2, (axis1,axis2) = plt.subplots(1,2,figsize=(15,5))\n",
    "sns.countplot(df_train['SibSp'],ax=axis1)\n",
    "sns.countplot(df_train['Parch'],ax=axis2)\n",
    "fig2.suptitle(\"Basic representation of Discrete Quantitative data with count\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Continuous Quantitative Data : [Age, Fare]\n",
    "fig3, (axis1,axis2) = plt.subplots(2,1,figsize=(15,10))\n",
    "sns.distplot(df_train['Age'].dropna(), bins=80, ax=axis1)\n",
    "sns.distplot(df_train['Fare'], ax=axis2)\n",
    "fig3.suptitle(\"Basic representation of Continuous Quantitative data with probability\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Age distribution within Sex and Pclass\n",
    "fig3, ((axis1),(axis2),(axis3)) = plt.subplots(3,1,figsize=(15,15))\n",
    "\n",
    "# Age distribution\n",
    "df_train.Age.plot(kind='kde',ax=axis1)\n",
    "axis1.set_xlabel(\"Age\")    \n",
    "axis1.set_title(\"Age Distribution\")\n",
    "\n",
    "# Age distribution within Sex\n",
    "df_train.Age[df_train.Sex == 'male'].plot(kind='kde',ax=axis2,)    \n",
    "df_train.Age[df_train.Sex == 'female'].plot(kind='kde',ax=axis2)\n",
    "axis2.set_xlabel(\"Age\")    \n",
    "axis2.set_title(\"Age Distribution within Sex\")\n",
    "axis2.legend(('Male', 'Female'))\n",
    "\n",
    "# Age distribution within Pclass\n",
    "df_train.Age[df_train.Pclass == 1].plot(kind='kde',ax=axis3)    \n",
    "df_train.Age[df_train.Pclass == 2].plot(kind='kde',ax=axis3)\n",
    "df_train.Age[df_train.Pclass == 3].plot(kind='kde',ax=axis3)\n",
    "axis3.set_xlabel(\"Age\")    \n",
    "axis3.set_title(\"Age Distribution within Classes\")\n",
    "axis3.legend(('1st Class', '2nd Class','3rd Class'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Focus on the mean of survival"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [Sex, Pclass, Embarked] by mean of survival\n",
    "fig4, (axis1,axis2,axis3) = plt.subplots(1,3,figsize=(15,5))\n",
    "sns.barplot(x='Sex',y='Survived', data=df_train, ax=axis1)\n",
    "sns.barplot(x='Embarked',y='Survived', data=df_train, ax=axis2)\n",
    "sns.barplot(x='Pclass',y='Survived', data=df_train, ax=axis3)\n",
    "fig4.suptitle(\"Representation of features linked to the target : Survived \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# [SibSp, Parch] by mean of survival\n",
    "fig6, (axis1,axis2) = plt.subplots(1,2,figsize=(15,5))\n",
    "sns.barplot(x='SibSp',y='Survived', data=df_train, ax=axis1)\n",
    "sns.barplot(x='Parch',y='Survived', data=df_train, ax=axis2)\n",
    "fig6.suptitle(\"Representation of features linked to the target : Survived \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross relation betwen [Sex, Pclass, Embarked] by mean of survival\n",
    "fig5, ((axis1,axis2),(axis3,axis4),(axis5,axis6)) = plt.subplots(3,2,figsize=(15,15))\n",
    "sns.barplot(x='Sex',y='Survived',hue='Pclass', data=df_train, ax=axis1)\n",
    "sns.barplot(x='Sex',y='Survived',hue='Embarked', data=df_train, ax=axis2)\n",
    "\n",
    "sns.barplot(x='Pclass',y='Survived',hue='Sex', data=df_train, ax=axis3)\n",
    "sns.barplot(x='Pclass',y='Survived',hue='Embarked', data=df_train, ax=axis4)\n",
    "\n",
    "sns.barplot(x='Embarked',y='Survived',hue='Sex', data=df_train, ax=axis5)\n",
    "sns.barplot(x='Embarked',y='Survived',hue='Pclass', data=df_train, ax=axis6)\n",
    "\n",
    "fig5.suptitle(\"Cross Representation of the features linked to the target : Survived\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Age by mean of survival\n",
    "fig=sns.barplot(x='Age', y='Survived', data=df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Age\n",
    "\n",
    "# Kernel density of survivor and non survivor by Age\n",
    "g1 = sns.FacetGrid( df_train , hue='Survived' , aspect=4)\n",
    "g1.map( sns.kdeplot , 'Age' , shade= True )\n",
    "g1.add_legend()\n",
    "\n",
    "# Kernel density of survivor and non survivor by Age and Sex \n",
    "g2 = sns.FacetGrid( df_train , hue='Survived' , aspect=4 , row = 'Sex')\n",
    "g2.map( sns.kdeplot , 'Age' , shade= True )\n",
    "g2.add_legend()\n",
    "\n",
    "# Kernel density of survivor and non survivor by Age and Pclass\n",
    "g3 = sns.FacetGrid( df_train , hue='Survived' , aspect=4 , row = 'Pclass')\n",
    "g3.map( sns.kdeplot , 'Age' , shade= True )\n",
    "g3.add_legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fare\n",
    "\n",
    "# Scatterplot Fare & Age\n",
    "g = sns.FacetGrid(df_train, hue=\"Survived\", size=6)\n",
    "g=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\n",
    "g.add_legend()\n",
    "g.set(xlim=(0, 550))\n",
    "\n",
    "# Scatterplot Fare & Age by Sex\n",
    "g = sns.FacetGrid(df_train, hue=\"Survived\", col=\"Sex\", margin_titles=True,\n",
    "                palette=\"Set1\",hue_kws=dict(marker=[\"^\", \"v\"]),size=6)\n",
    "g=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\n",
    "g.add_legend()\n",
    "g.set(xlim=(0, 300))\n",
    "\n",
    "# Scatterplot Fare & Age by Pclass\n",
    "g = sns.FacetGrid(df_train, col=\"Pclass\", hue=\"Survived\", size=4)\n",
    "g=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\n",
    "g.add_legend()\n",
    "g.set(xlim=(0, 300))\n",
    "\n",
    "# Scatterplot Fare & Age by Pclass & Sex\n",
    "g = sns.FacetGrid(df_train, hue=\"Survived\", col=\"Pclass\", row=\"Sex\" ,margin_titles=True,\n",
    "                  palette={1:\"red\", 0:\"grey\"},size=5)\n",
    "g=g.map(plt.scatter, \"Fare\", \"Age\",edgecolor=\"w\").add_legend()\n",
    "g.set(xlim=(0, 300))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creation of a dataframe with train and test for Feature Engineering\n",
    "def get_combined_data():\n",
    "    # reading train data\n",
    "    train = pd.read_csv(\"Data/Titanic/train.csv\")\n",
    "    \n",
    "    # reading test data\n",
    "    test = pd.read_csv(\"Data/Titanic/test.csv\")\n",
    "\n",
    "    # extracting and then removing the targets from the training data \n",
    "    targets = train.Survived\n",
    "    #train.drop('Survived',axis=1,inplace=True)\n",
    "\n",
    "    # merging train data and test data for future feature engineering\n",
    "    combined = train.append(test)\n",
    "    combined.reset_index(inplace=True)\n",
    "    combined.drop('index',axis=1,inplace=True)\n",
    "    \n",
    "    return combined\n",
    "\n",
    "def recover_train_test_target(combined):\n",
    "    \n",
    "    train0 = pd.read_csv(\"Data/Titanic/train.csv\")\n",
    "    \n",
    "    targets = train0.Survived\n",
    "    train = combined.ix[0:890]\n",
    "    test = combined.ix[891:]\n",
    "    \n",
    "    return train,test,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "combined = get_combined_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Name\n",
    "\n",
    "#Create feature for the length of name \n",
    "combined[\"Name_Length\"] = combined[\"Name\"].apply(lambda x: len(x))\n",
    "\n",
    "# Create a categorical feature Name_Size\n",
    "combined['Name_Size']=pd.cut(combined['Name_Length']\n",
    "                            ,bins=[0,20,40,60,90]\n",
    "                            ,labels=[\"Short\",\"Medium\",\"Long\",\"Very Long\"])\n",
    "\n",
    "# Extract the title from each name\n",
    "combined['Title'] = combined['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n",
    "\n",
    "# Map for aggregated titles\n",
    "Title_Dictionary = {\n",
    "                    \"Mme\":        \"Mrs\",\n",
    "                    \"Mlle\":       \"Miss\",\n",
    "                    \"Ms\":         \"Mrs\",\n",
    "                    \"Mr\" :        \"Mr\",\n",
    "                    \"Mrs\" :       \"Mrs\",\n",
    "                    \"Miss\" :      \"Miss\",\n",
    "                    \"Capt\":       \"Officer\",\n",
    "                    \"Col\":        \"Officer\",\n",
    "                    \"Major\":      \"Officer\",\n",
    "                    \"Dr\":         \"Officer\",\n",
    "                    \"Rev\":        \"Officer\",\n",
    "                    \"Master\" :    \"Master\",\n",
    "                    \"Lady\" :      \"Royalty\",\n",
    "                    \"Jonkheer\":   \"Royalty\",\n",
    "                    \"Don\":        \"Royalty\",\n",
    "                    \"Sir\" :       \"Royalty\",\n",
    "                    \"Dona\":       \"Royalty\",\n",
    "                    \"the Countess\":\"Royalty\"\n",
    "                    }\n",
    "    \n",
    "# Mapping\n",
    "combined['Title_aggr'] = combined.Title.map(Title_Dictionary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Family\n",
    "\n",
    "# Creation of a feature Number_of_relatives = SibSp + Parch\n",
    "combined['Number_of_relatives']=combined['SibSp']+combined['Parch']\n",
    "\n",
    "# Creation of a categorical feature Size_Family\n",
    "combined.loc[combined['Number_of_relatives'] == 0, 'Size_Family'] = 'Alone'\n",
    "combined.loc[ (combined['Number_of_relatives'] > 0) \n",
    "            & (combined['Number_of_relatives'] < 4), 'Size_Family'] = 'Small'\n",
    "combined.loc[combined['Number_of_relatives'] > 3, 'Size_Family'] = 'Big'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can create 3 categories : \n",
    "    - Alone = 0\n",
    "    - Small = [1,2,3]\n",
    "    - Big = > 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cabin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1014"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Mostly NaN values\n",
    "combined.Cabin.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a category Unknown\n",
    "combined['Cabin'] = combined.Cabin.fillna( 'U' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Deck\n",
       "U    1014\n",
       "C    94  \n",
       "B    65  \n",
       "D    46  \n",
       "E    41  \n",
       "A    22  \n",
       "F    21  \n",
       "G    5   \n",
       "T    1   \n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get the first letter\n",
    "combined[\"Deck\"]=combined.Cabin.str[0]\n",
    "Sort_Deck=combined.groupby('Deck').size()\n",
    "Sort_Deck.sort_values(ascending=False,inplace=True)\n",
    "display(Sort_Deck)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f086b933278>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUk1ZACSppiwAklRTFgBJqikLgCTV1P8HESHyqaAqy/gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f086b80ad30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(x='Deck', y='Survived', data=combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f0868176320>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEGCAYAAABsLkJ6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUk2ZACSppv4/artkQc1DmjsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f086b8f0f98>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creation of 4 categories\n",
    "Deck_Dictionary = {\n",
    "                    \"E\":        \"C1\",\n",
    "                    \"D\":       \"C1\",\n",
    "                    \"B\":         \"C1\",\n",
    "                    \"C\" :        \"C2\",\n",
    "                    \"F\" :       \"C2\",\n",
    "                    \"G\" :      \"C3\",\n",
    "                    \"A\":       \"C3\",\n",
    "                    \"U\":        \"U\"\n",
    "                    }\n",
    "\n",
    "# Mapping\n",
    "combined['Deck_aggr'] = combined.Deck.map(Deck_Dictionary)\n",
    "\n",
    "sns.barplot(x='Deck_aggr', y='Survived', data=combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticket\n",
       "CA. 2343             11\n",
       "1601                 8 \n",
       "CA 2144              8 \n",
       "S.O.C. 14879         7 \n",
       "PC 17608             7 \n",
       "347082               7 \n",
       "347077               7 \n",
       "3101295              7 \n",
       "382652               6 \n",
       "19950                6 \n",
       "347088               6 \n",
       "113781               6 \n",
       "4133                 5 \n",
       "PC 17757             5 \n",
       "113503               5 \n",
       "W./C. 6608           5 \n",
       "16966                5 \n",
       "220845               5 \n",
       "349909               5 \n",
       "C.A. 34651           4 \n",
       "C.A. 33112           4 \n",
       "113760               4 \n",
       "SC/Paris 2123        4 \n",
       "2666                 4 \n",
       "C.A. 2315            4 \n",
       "36928                4 \n",
       "W./C. 6607           4 \n",
       "PC 17483             4 \n",
       "LINE                 4 \n",
       "230136               4 \n",
       "                    .. \n",
       "349223               1 \n",
       "349222               1 \n",
       "349221               1 \n",
       "349220               1 \n",
       "349219               1 \n",
       "349241               1 \n",
       "349242               1 \n",
       "349243               1 \n",
       "349255               1 \n",
       "350035               1 \n",
       "350034               1 \n",
       "350033               1 \n",
       "350029               1 \n",
       "350025               1 \n",
       "349912               1 \n",
       "349911               1 \n",
       "SOTON/O.Q. 392078    1 \n",
       "349257               1 \n",
       "349254               1 \n",
       "349244               1 \n",
       "349253               1 \n",
       "349252               1 \n",
       "349251               1 \n",
       "349250               1 \n",
       "349249               1 \n",
       "349248               1 \n",
       "349247               1 \n",
       "349246               1 \n",
       "349245               1 \n",
       "345769               1 \n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sort_Ticket=combined.groupby('Ticket').size()\n",
    "Sort_Ticket.sort_values(ascending=False,inplace=True)\n",
    "display(Sort_Ticket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'int' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-71-111ceded5edd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcombined\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ticket'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'int' object is not callable"
     ]
    }
   ],
   "source": [
    "combined['Ticket'].unique().size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# a function that extracts each prefix of the ticket, returns 'XXX' if no prefix (i.e the ticket is a digit)\n",
    "def cleanTicket( ticket ):\n",
    "    ticket = ticket.replace( '.' , '' )\n",
    "    ticket = ticket.replace( '/' , '' )\n",
    "    ticket = ticket.split()\n",
    "    ticket = map( lambda t : t.strip() , ticket )\n",
    "    ticket = list(filter( lambda t : not t.isdigit() , ticket ))\n",
    "    if len( ticket ) > 0:\n",
    "        return ticket[0]\n",
    "    else: \n",
    "        return 'XXX'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ticket_clean\n",
       "XXX        957\n",
       "PC         92 \n",
       "CA         68 \n",
       "A5         28 \n",
       "SOTONOQ    24 \n",
       "WC         15 \n",
       "SCPARIS    14 \n",
       "STONO      14 \n",
       "A4         10 \n",
       "FCC        9  \n",
       "C          8  \n",
       "SOC        8  \n",
       "SOPP       7  \n",
       "STONO2     7  \n",
       "SCParis    5  \n",
       "SCAH       5  \n",
       "PP         4  \n",
       "LINE       4  \n",
       "WEP        4  \n",
       "FC         3  \n",
       "SOTONO2    3  \n",
       "PPP        2  \n",
       "SC         2  \n",
       "SWPP       2  \n",
       "SCA4       2  \n",
       "AS         1  \n",
       "AQ4        1  \n",
       "AQ3        1  \n",
       "SCA3       1  \n",
       "CASOTON    1  \n",
       "Fa         1  \n",
       "LP         1  \n",
       "SCOW       1  \n",
       "SOP        1  \n",
       "SP         1  \n",
       "STONOQ     1  \n",
       "A          1  \n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ticket = pd.DataFrame()\n",
    "# Extracting dummy variables from tickets:\n",
    "combined[ 'Ticket_clean' ] = combined[ 'Ticket' ].map( cleanTicket )\n",
    "\n",
    "\n",
    "Sort_Clean_Ticket=combined.groupby('Ticket_clean').size()\n",
    "Sort_Clean_Ticket.sort_values(ascending=False,inplace=True)\n",
    "display(Sort_Clean_Ticket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABI0AAAJNCAYAAAC88IW6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBHX8P9zIap6h5Z7RAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0853887710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "g = plt.figure(figsize=(20,10)) \n",
    "g = sns.barplot(x='Ticket_clean',data=combined, y='Survived',order=['XXX','PC','CA','A5','SOTONOQ','WC','SCPARIS','STONO','A4','FCC','C','SOC','SOPP','STONO2','SCParis','SCAH','PP','LINE','WEP','FC','SOTONO2','PPP','SC','SWPP','SCA4','AS','AQ4','AQ3','SCA3','CASOTON','Fa','LP','SCOW','SOP','SP','STONOQ','A'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Creation of 4 categories\n",
    "Ticket_Dictionary = {\n",
    "                    \"E\":        \"C1\",\n",
    "                    \"D\":       \"C1\",\n",
    "                    \"B\":         \"C1\",\n",
    "                    \"C\" :        \"C2\",\n",
    "                    \"F\" :       \"C2\",\n",
    "                    \"G\" :      \"C3\",\n",
    "                    \"A\":       \"C3\",\n",
    "                    \"U\":        \"U\"\n",
    "                    }\n",
    "\n",
    "# Mapping\n",
    "combined['Ticket_aggr'] = combined.Deck.map(Ticket_Dictionary)\n",
    "\n",
    "sns.barplot(x='Ticket_aggr', y='Survived', data=combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing Values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embarked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>829</th>\n",
       "      <td>80.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Fare  Pclass Embarked\n",
       "61   80.0       1      NaN\n",
       "829  80.0       1      NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfMAAAGTCAYAAAA8+/sRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlySpcP8fR8Rsd/AUvawAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f086fab57b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Embarked\n",
    "\n",
    "# Get the null rows where Embarked is null\n",
    "display(combined[combined.Embarked.isnull()][['Fare', 'Pclass', 'Embarked']])\n",
    "\n",
    "# Embarked missing values\n",
    "combined.boxplot(column='Fare', by=['Embarked','Pclass'], figsize=(8,6))\n",
    "plt.axhline(y=80, color='blue')\n",
    "\n",
    "# Remplace null values by C because most people who are Pclass 1 and Fare 80 has Embarked from C\n",
    "combined = combined.set_value(combined.Embarked.isnull(), 'Embarked', 'C')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeQAAAFlCAYAAAA6QpuEAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWXDEAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f086b9846d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fare\n",
    "\n",
    "# Visualization of the fare which is missing\n",
    "combined[combined.Fare.isnull()][['Pclass', 'Fare', 'Embarked']]\n",
    "#df_test[(df_test.Pclass==3)&(df_test.Embarked=='S')].Fare.hist(bins=100)\n",
    "combined.loc[(combined['Pclass']==3) & (combined['Embarked']=='S')].Fare.hist(bins=100,figsize=(8,6))\n",
    "\n",
    "# Get and affect the median to the missing value\n",
    "Fare_median=combined[(combined.Pclass==3) & (combined.Embarked=='S')].Fare.median()\n",
    "#df_test = df_test.set_value(df_test.Fare.isnull(), 'Fare', Fare_median)\n",
    "combined[\"Fare\"].fillna(Fare_median, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Age with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sex     Pclass  Title_aggr\n",
       "female  1       Miss          30.0\n",
       "                Mrs           45.0\n",
       "                Officer       49.0\n",
       "                Royalty       39.0\n",
       "        2       Miss          20.0\n",
       "                Mrs           30.0\n",
       "        3       Miss          18.0\n",
       "                Mrs           31.0\n",
       "male    1       Master         6.0\n",
       "                Mr            41.5\n",
       "                Officer       52.0\n",
       "                Royalty       40.0\n",
       "        2       Master         2.0\n",
       "                Mr            30.0\n",
       "                Officer       41.5\n",
       "        3       Master         6.0\n",
       "                Mr            26.0\n",
       "Name: Age, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Simply fill the nan values with median using Sex, Pclass and Title\n",
    "grouped = combined.groupby(['Sex','Pclass','Title_aggr'])\n",
    "age_median = grouped['Age'].median()\n",
    "display(age_median)\n",
    "combined[\"Age\"] = combined.groupby(['Sex','Pclass','Title_aggr'])['Age'].transform(lambda x: x.fillna(x.median()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verification of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age                       0\n",
       "Cabin                  1014\n",
       "Embarked                  0\n",
       "Fare                      0\n",
       "Name                      0\n",
       "Parch                     0\n",
       "PassengerId               0\n",
       "Pclass                    0\n",
       "Sex                       0\n",
       "SibSp                     0\n",
       "Survived                418\n",
       "Ticket                    0\n",
       "Name_Length               0\n",
       "Name_Size                 0\n",
       "Title                     0\n",
       "Title_aggr                0\n",
       "Number_of_relatives       0\n",
       "Size_Family               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Split for visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split\n",
    "df_train, df_test, targets = recover_train_test_target(combined)\n",
    "\n",
    "# Dropping Cabin, Ticket and PassengerId\n",
    "df_train = df_train.drop(['Cabin','PassengerId','Ticket'], axis=1)\n",
    "df_test = df_test.drop(['Cabin','Ticket'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 15)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Age', 'Embarked', 'Fare', 'Name', 'Parch', 'Pclass', 'Sex', 'SibSp',\n",
       "       'Survived', 'Name_Length', 'Name_Size', 'Title', 'Title_aggr',\n",
       "       'Number_of_relatives', 'Size_Family'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization new Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vrack v1 a faire marcher\n",
    "fig5, ((axis1,axis2),(axis3,axis4),(axis5,axis6),(axis7,axis8)) = plt.subplots(4,2,figsize=(15,15))\n",
    "\n",
    "# Plot Name_Length\n",
    "sns.countplot(x='Name_Length', data=df_train, ax=axis1)\n",
    "\n",
    "# Plot Name_Length by mean of survival\n",
    "sns.barplot(x='Name_Length', y='Survived', data=df_train, ax=axis2)\n",
    "\n",
    "# Plot Name_Size by mean of survival\n",
    "sns.barplot(x='Name_Size', data=df_train, order=[\"Short\",\"Medium\",\"Long\",\"Very Long\"], ax=axis3)\n",
    "\n",
    "# Plot Name_Size by mean of survival\n",
    "sns.barplot(x='Name_Size',y='Survived', data=df_train, order=[\"Short\",\"Medium\",\"Long\",\"Very Long\"], ax=axis4)\n",
    "\n",
    "# Plot Title aggregate\n",
    "sns.barplot(x='Title_aggr', data=df_train, ax=axis5)\n",
    "\n",
    "# Display Title aggregate by mean of survival\n",
    "sns.barplot(x='Title_aggr',y='Survived', data=df_train, ax=axis6)\n",
    "\n",
    "# Display Title aggregate and Name Size by mean of survival\n",
    "sns.barplot(x='Title_aggr',y='Survived', hue='Name_Size', data=df_train, ax=axis7)\n",
    "\n",
    "# Display Title aggregate and Name Size by mean of survival\n",
    "sns.barplot(x='Name_Size',y='Survived', hue='Title_aggr', data=df_train, ax=axis8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Vrack v2 a faire marcher\n",
    "fig = plt.figure(figsize=(15, 5))\n",
    "fig=sns.countplot(x='Name_Length', data=df_train)\n",
    "\n",
    "fig=sns.barplot(x='Name_Length', y='Survived', data=df_train)\n",
    "\n",
    "sns.barplot(x='Name_Size',y='Survived', data=df_train, order=[\"Short\",\"Medium\",\"Long\",\"Very Long\"])\n",
    "\n",
    "# Display aggregate title by survived probability\n",
    "fig1 = plt.figure(figsize=(15, 5))\n",
    "fig1=sns.barplot(x='Title_aggr',y='Survived', data=df_train)\n",
    "\n",
    "# Display aggregate title and Name Size by survived probability\n",
    "fig2 = plt.figure(figsize=(15, 5))\n",
    "fig2=sns.barplot(x='Title_aggr',y='Survived', hue='Name_Size', data=df_train)\n",
    "\n",
    "# Display aggregate title and Name Size by survived probability\n",
    "fig3 = plt.figure(figsize=(15, 5))\n",
    "fig3=sns.barplot(x='Name_Size',y='Survived', hue='Title_aggr', data=df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization Family"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# A afficher correctrement\n",
    "fig1 = plt.figure(figsize=(15, 5))\n",
    "fig1 = sns.countplot(x='Number_of_relatives', data=df_train)\n",
    "\n",
    "fig2 = plt.figure(figsize=(15, 5))\n",
    "fig2 = sns.barplot(x='Number_of_relatives',y='Survived', data=df_train)\n",
    "\n",
    "sns.barplot(x='Size_Family',y='Survived', data=df_train, order=['Alone', 'Small', 'Big'])\n",
    "\n",
    "# Number_of_relatives with Pclass, Sex, Embarked by mean of survival\n",
    "fig7, ((axis1),(axis2),(axis3)) = plt.subplots(3,1,figsize=(20,20))\n",
    "sns.barplot(x='Number_of_relatives',y='Survived',hue='Pclass', data=df_train, ax=axis1)\n",
    "sns.barplot(x='Number_of_relatives',y='Survived',hue='Sex', data=df_train, ax=axis2)\n",
    "sns.barplot(x='Number_of_relatives',y='Survived',hue='Embarked', data=df_train, ax=axis3)\n",
    "fig7.suptitle(\"Cross Representation of the features linked to the target : Survived\")\n",
    "\n",
    "# Size_Family with Pclass, Sex, Embarked by mean of survival\n",
    "fig8, ((axis1),(axis2),(axis3)) = plt.subplots(3,1,figsize=(20,20))\n",
    "sns.barplot(x='Size_Family',y='Survived',hue='Pclass', data=df_train, order=['Alone', 'Small', 'Big'], ax=axis1,)\n",
    "sns.barplot(x='Size_Family',y='Survived',hue='Sex', data=df_train, order=['Alone', 'Small', 'Big'], ax=axis2)\n",
    "sns.barplot(x='Size_Family',y='Survived',hue='Embarked', data=df_train, order=['Alone', 'Small', 'Big'], ax=axis3)\n",
    "fig8.suptitle(\"Cross Representation of the features linked to the target : Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "display(combined.columns)\n",
    "display(combined.isnull().sum())\n",
    "display(combined.shape)\n",
    "display(combined[[\"Embarked\",\"Sex\",\"Title_aggr\",\"Size_Family\",\"Name_Size\",\"Pclass\"]].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Categorial features encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Dataframe with numerical categorical feature\n",
    "combined_num_cat = pd.DataFrame()\n",
    "\n",
    "# LabelEncoder\n",
    "labelEnc = LabelEncoder()\n",
    "\n",
    "# Columns to apply\n",
    "cat_vars=[\"Embarked\",\"Sex\",\"Title_aggr\",\"Size_Family\",\"Name_Size\"]\n",
    "\n",
    "for col in cat_vars:\n",
    "    labelEnc.fit(np.unique(list(combined[col].values)))\n",
    "    combined_num_cat[col]=labelEnc.transform(combined[col].astype('str'))\n",
    "    \n",
    "labelEnc.fit(np.unique(list(combined[\"Pclass\"].values)))\n",
    "combined_num_cat[\"Pclass\"]=labelEnc.transform(combined[\"Pclass\"].astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Title_aggr</th>\n",
       "      <th>Size_Family</th>\n",
       "      <th>Name_Size</th>\n",
       "      <th>Pclass</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Embarked  Sex  Title_aggr  Size_Family  Name_Size  Pclass\n",
       "0         2    1           2            2          1       2\n",
       "1         0    0           3            2          0       0\n",
       "2         2    0           1            0          1       2\n",
       "3         2    0           3            2          0       0\n",
       "4         2    1           2            0          1       2"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_num_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### One Hot  Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def one_hot(df_in, cols):\n",
    "    df_out = pd.DataFrame()\n",
    "    for each in cols:\n",
    "        dummies = pd.get_dummies(df_in[each], prefix=each, drop_first=False)\n",
    "        df_out = pd.concat([df_out, dummies], axis=1)\n",
    "    return df_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Dataframe with binary categorical feature\n",
    "\n",
    "# Columns to apply\n",
    "cat_vars=['Embarked','Sex',\"Title_aggr\",\"Size_Family\",\"Name_Size\",\"Pclass\"]\n",
    "combined_One_Hot_Cat = one_hot(combined,cat_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Title_aggr_Master</th>\n",
       "      <th>Title_aggr_Miss</th>\n",
       "      <th>Title_aggr_Mr</th>\n",
       "      <th>Title_aggr_Mrs</th>\n",
       "      <th>Title_aggr_Officer</th>\n",
       "      <th>...</th>\n",
       "      <th>Size_Family_Alone</th>\n",
       "      <th>Size_Family_Big</th>\n",
       "      <th>Size_Family_Small</th>\n",
       "      <th>Name_Size_Short</th>\n",
       "      <th>Name_Size_Medium</th>\n",
       "      <th>Name_Size_Long</th>\n",
       "      <th>Name_Size_Very Long</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Embarked_C  Embarked_Q  Embarked_S  Sex_female  Sex_male  \\\n",
       "0           0           0           1           0         1   \n",
       "1           1           0           0           1         0   \n",
       "2           0           0           1           1         0   \n",
       "3           0           0           1           1         0   \n",
       "4           0           0           1           0         1   \n",
       "\n",
       "   Title_aggr_Master  Title_aggr_Miss  Title_aggr_Mr  Title_aggr_Mrs  \\\n",
       "0                  0                0              1               0   \n",
       "1                  0                0              0               1   \n",
       "2                  0                1              0               0   \n",
       "3                  0                0              0               1   \n",
       "4                  0                0              1               0   \n",
       "\n",
       "   Title_aggr_Officer    ...     Size_Family_Alone  Size_Family_Big  \\\n",
       "0                   0    ...                     0                0   \n",
       "1                   0    ...                     0                0   \n",
       "2                   0    ...                     1                0   \n",
       "3                   0    ...                     0                0   \n",
       "4                   0    ...                     1                0   \n",
       "\n",
       "   Size_Family_Small  Name_Size_Short  Name_Size_Medium  Name_Size_Long  \\\n",
       "0                  1                0                 1               0   \n",
       "1                  1                0                 0               1   \n",
       "2                  0                0                 1               0   \n",
       "3                  1                0                 0               1   \n",
       "4                  0                0                 1               0   \n",
       "\n",
       "   Name_Size_Very Long  Pclass_1  Pclass_2  Pclass_3  \n",
       "0                    0         0         0         1  \n",
       "1                    0         1         0         0  \n",
       "2                    0         0         0         1  \n",
       "3                    0         1         0         0  \n",
       "4                    0         0         0         1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_One_Hot_Cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Scalling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age</th>\n",
       "      <th>Name_Length</th>\n",
       "      <th>Number_of_relatives</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.2500</td>\n",
       "      <td>22.0</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>71.2833</td>\n",
       "      <td>38.0</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.9250</td>\n",
       "      <td>26.0</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53.1000</td>\n",
       "      <td>35.0</td>\n",
       "      <td>44</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8.0500</td>\n",
       "      <td>35.0</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Fare   Age  Name_Length  Number_of_relatives\n",
       "0   7.2500  22.0           23                    1\n",
       "1  71.2833  38.0           51                    1\n",
       "2   7.9250  26.0           22                    0\n",
       "3  53.1000  35.0           44                    1\n",
       "4   8.0500  35.0           24                    0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[['Fare','Age','Name_Length','Number_of_relatives']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fare</th>\n",
       "      <th>Age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.503176</td>\n",
       "      <td>-0.541471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.734809</td>\n",
       "      <td>0.648868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.490126</td>\n",
       "      <td>-0.243886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.383263</td>\n",
       "      <td>0.425680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.487709</td>\n",
       "      <td>0.425680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Fare       Age\n",
       "0 -0.503176 -0.541471\n",
       "1  0.734809  0.648868\n",
       "2 -0.490126 -0.243886\n",
       "3  0.383263  0.425680\n",
       "4 -0.487709  0.425680"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "std_columns = ['Fare','Age']\n",
    "\n",
    "combined_num_std = pd.DataFrame(combined[std_columns])\n",
    "\n",
    "# StandardScaller process\n",
    "std_scale = preprocessing.StandardScaler()\n",
    "combined_num_std[std_columns] = std_scale.fit_transform(combined[std_columns].astype(float))\n",
    "\n",
    "combined_num_std[std_columns].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Available :\n",
    "combined_num_std\n",
    "combined_One_Hot_Cat\n",
    "combined_num_cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Concat\n",
    "combined_OH_Std = pd.concat([combined_num_std,combined_One_Hot_Cat],axis=1)\n",
    "combined_Num_Std = pd.concat([combined_num_std,combined_num_cat],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 23)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1309, 8)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display shape\n",
    "display(combined_OH_Std.shape)\n",
    "display(combined_Num_Std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split into Train and Eval\n",
    "Train_OH_Std, Eval_OH_Std, Target_OH_Std = recover_train_test_target(combined_OH_Std)\n",
    "Train_Num_Std, Eval_Num_Std, Target_Num_Std = recover_train_test_target(combined_Num_Std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 23)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(418, 23)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(891,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Display shape\n",
    "display(Train_OH_Std.shape)\n",
    "display(Eval_OH_Std.shape)\n",
    "display(Target_OH_Std.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Select Data\n",
    "data = Train_OH_Std\n",
    "test_data = Eval_OH_Std\n",
    "target = Target_OH_Std\n",
    "columns_name = list(Train_OH_Std)\n",
    "\n",
    "# Train & Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20)\n",
    "\n",
    "# Dataframe of prediction\n",
    "Prediction = pd.DataFrame()\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features Importance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation - Numerical label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.257307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Size_Family</th>\n",
       "      <td>0.249714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.059594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_aggr</th>\n",
       "      <td>-0.062916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked</th>\n",
       "      <td>-0.174199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name_Size</th>\n",
       "      <td>-0.261576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass</th>\n",
       "      <td>-0.338481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex</th>\n",
       "      <td>-0.543351</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Corr\n",
       "Survived     1.000000\n",
       "Fare         0.257307\n",
       "Size_Family  0.249714\n",
       "Age         -0.059594\n",
       "Title_aggr  -0.062916\n",
       "Embarked    -0.174199\n",
       "Name_Size   -0.261576\n",
       "Pclass      -0.338481\n",
       "Sex         -0.543351"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concant data and target\n",
    "Features_with_target = pd.concat([Train_Num_Std,target],axis=1)\n",
    "# Correlation with target\n",
    "Corr = pd.DataFrame()\n",
    "Corr['Corr'] = Features_with_target.corr()[\"Survived\"]\n",
    "Corr.sort_values('Corr',ascending=False,inplace=True)\n",
    "display(Corr)\n",
    "# A réfléchir au sens en regardant la formule de corr pour les catégories le numerical label ordinales et non ordinales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation - One Hot Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Survived</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_female</th>\n",
       "      <td>0.543351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_aggr_Mrs</th>\n",
       "      <td>0.344935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_aggr_Miss</th>\n",
       "      <td>0.332795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass_1</th>\n",
       "      <td>0.285904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Size_Family_Small</th>\n",
       "      <td>0.279855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name_Size_Long</th>\n",
       "      <td>0.273448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fare</th>\n",
       "      <td>0.257307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_C</th>\n",
       "      <td>0.174718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass_2</th>\n",
       "      <td>0.093349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_aggr_Master</th>\n",
       "      <td>0.085221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name_Size_Very Long</th>\n",
       "      <td>0.085083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_aggr_Royalty</th>\n",
       "      <td>0.033391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_Q</th>\n",
       "      <td>0.003650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name_Size_Medium</th>\n",
       "      <td>-0.000867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_aggr_Officer</th>\n",
       "      <td>-0.031316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-0.059594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Size_Family_Big</th>\n",
       "      <td>-0.125147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Embarked_S</th>\n",
       "      <td>-0.155660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Name_Size_Short</th>\n",
       "      <td>-0.193143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Size_Family_Alone</th>\n",
       "      <td>-0.203367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Pclass_3</th>\n",
       "      <td>-0.322308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sex_male</th>\n",
       "      <td>-0.543351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Title_aggr_Mr</th>\n",
       "      <td>-0.549199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Corr\n",
       "Survived             1.000000\n",
       "Sex_female           0.543351\n",
       "Title_aggr_Mrs       0.344935\n",
       "Title_aggr_Miss      0.332795\n",
       "Pclass_1             0.285904\n",
       "Size_Family_Small    0.279855\n",
       "Name_Size_Long       0.273448\n",
       "Fare                 0.257307\n",
       "Embarked_C           0.174718\n",
       "Pclass_2             0.093349\n",
       "Title_aggr_Master    0.085221\n",
       "Name_Size_Very Long  0.085083\n",
       "Title_aggr_Royalty   0.033391\n",
       "Embarked_Q           0.003650\n",
       "Name_Size_Medium    -0.000867\n",
       "Title_aggr_Officer  -0.031316\n",
       "Age                 -0.059594\n",
       "Size_Family_Big     -0.125147\n",
       "Embarked_S          -0.155660\n",
       "Name_Size_Short     -0.193143\n",
       "Size_Family_Alone   -0.203367\n",
       "Pclass_3            -0.322308\n",
       "Sex_male            -0.543351\n",
       "Title_aggr_Mr       -0.549199"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Concant data and target\n",
    "Features_with_target = pd.concat([Train_OH_Std,target],axis=1)\n",
    "# Correlation with target\n",
    "Corr = pd.DataFrame()\n",
    "Corr['Corr'] = Features_with_target.corr()[\"Survived\"]\n",
    "Corr.sort_values('Corr',ascending=False,inplace=True)\n",
    "display(Corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set\n",
      "LDA Accuracy : 0.830056179775\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.89      0.86       430\n",
      "          1       0.82      0.73      0.77       282\n",
      "\n",
      "avg / total       0.83      0.83      0.83       712\n",
      "\n",
      "Confusion Matrix :\n",
      " [[384  46]\n",
      " [ 75 207]]\n",
      "Balance of classes [ 0.60393258  0.39606742]\n",
      "-----------------------------------------------------------------------------\n",
      "Testing set\n",
      "LDA Accuracy : 0.837988826816\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.88      0.87      0.88       119\n",
      "          1       0.75      0.77      0.76        60\n",
      "\n",
      "avg / total       0.84      0.84      0.84       179\n",
      "\n",
      "Confusion Matrix :\n",
      " [[104  15]\n",
      " [ 14  46]]\n",
      "Balance of classes [ 0.60393258  0.39606742]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jules/anaconda3/lib/python3.6/site-packages/sklearn/discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>Coef</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Title_aggr_Master</td>\n",
       "      <td>3.313311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Title_aggr_Royalty</td>\n",
       "      <td>1.478327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sex_female</td>\n",
       "      <td>1.386251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pclass_1</td>\n",
       "      <td>1.228448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Title_aggr_Mrs</td>\n",
       "      <td>0.668010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Name_Size_Very Long</td>\n",
       "      <td>0.664855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Size_Family_Alone</td>\n",
       "      <td>0.664218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Name_Size_Long</td>\n",
       "      <td>0.425577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>0.202758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fare</td>\n",
       "      <td>0.181362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Size_Family_Small</td>\n",
       "      <td>0.165531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>0.087486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Title_aggr_Miss</td>\n",
       "      <td>0.065140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Name_Size_Medium</td>\n",
       "      <td>0.035859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.007083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>-0.158526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Name_Size_Short</td>\n",
       "      <td>-0.238440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>-0.407379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Title_aggr_Officer</td>\n",
       "      <td>-0.933163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>-1.010432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Title_aggr_Mr</td>\n",
       "      <td>-1.239380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sex_male</td>\n",
       "      <td>-1.386251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Size_Family_Big</td>\n",
       "      <td>-3.276004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Features      Coef\n",
       "7   Title_aggr_Master    3.313311\n",
       "12  Title_aggr_Royalty   1.478327\n",
       "5   Sex_female           1.386251\n",
       "20  Pclass_1             1.228448\n",
       "10  Title_aggr_Mrs       0.668010\n",
       "19  Name_Size_Very Long  0.664855\n",
       "13  Size_Family_Alone    0.664218\n",
       "18  Name_Size_Long       0.425577\n",
       "2   Embarked_C           0.202758\n",
       "0   Fare                 0.181362\n",
       "15  Size_Family_Small    0.165531\n",
       "21  Pclass_2             0.087486\n",
       "8   Title_aggr_Miss      0.065140\n",
       "17  Name_Size_Medium     0.035859\n",
       "3   Embarked_Q           0.007083\n",
       "4   Embarked_S          -0.158526\n",
       "16  Name_Size_Short     -0.238440\n",
       "1   Age                 -0.407379\n",
       "11  Title_aggr_Officer  -0.933163\n",
       "22  Pclass_3            -1.010432\n",
       "9   Title_aggr_Mr       -1.239380\n",
       "6   Sex_male            -1.386251\n",
       "14  Size_Family_Big     -3.276004"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# LDA\n",
    "# LDA with n = 2 solver svd --> score : 0.78947\n",
    "lda = LinearDiscriminantAnalysis(n_components = 2, solver='svd')\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred_lda = lda.predict(X_train)\n",
    "y_test_pred_lda = lda.predict(X_test)\n",
    "\n",
    "lda_acc = accuracy_score(y_test, y_test_pred_lda)\n",
    "lda_cr= classification_report(y_test, y_test_pred_lda)\n",
    "lda_cm = confusion_matrix(y_test, y_test_pred_lda)\n",
    "\n",
    "lda_acc_train = accuracy_score(y_train, y_train_pred_lda)\n",
    "lda_cr_train = classification_report(y_train, y_train_pred_lda)\n",
    "lda_cm_train = confusion_matrix(y_train, y_train_pred_lda)\n",
    "\n",
    "print(\"Training set\")\n",
    "print( \"LDA Accuracy :\", lda_acc_train)\n",
    "print(lda_cr_train)\n",
    "print(\"Confusion Matrix :\\n\",lda_cm_train)\n",
    "#print('Explained variance ratio :',lda.explained_variance_ratio_)\n",
    "print('Balance of classes',lda.priors_)\n",
    "\n",
    "print(\"-----------------------------------------------------------------------------\")\n",
    "print(\"Testing set\")\n",
    "print( \"LDA Accuracy :\", lda_acc)\n",
    "print(lda_cr)\n",
    "print(\"Confusion Matrix :\\n\",lda_cm)\n",
    "#print('Explained variance ratio :',lda.explained_variance_ratio_)\n",
    "print('Balance of classes',lda.priors_)\n",
    "\n",
    "\n",
    "\n",
    "Prediction['LDA'] = lda.predict(Eval_OH_Std)\n",
    "\n",
    "\n",
    "Coef = pd.DataFrame()\n",
    "Coef['Features'] = list(X_train.columns)\n",
    "Coef['Coef'] = lda.coef_.transpose()\n",
    "Coef.sort_values('Coef',ascending=False,inplace=True)\n",
    "Coef"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features importance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Fare',\n",
       " 'Age',\n",
       " 'Embarked_C',\n",
       " 'Embarked_Q',\n",
       " 'Embarked_S',\n",
       " 'Sex_female',\n",
       " 'Sex_male',\n",
       " 'Title_aggr_Master',\n",
       " 'Title_aggr_Miss',\n",
       " 'Title_aggr_Mr',\n",
       " 'Title_aggr_Mrs',\n",
       " 'Title_aggr_Officer',\n",
       " 'Title_aggr_Royalty',\n",
       " 'Size_Family_Alone',\n",
       " 'Size_Family_Big',\n",
       " 'Size_Family_Small',\n",
       " 'Name_Size_Short',\n",
       " 'Name_Size_Medium',\n",
       " 'Name_Size_Long',\n",
       " 'Name_Size_Very Long',\n",
       " 'Pclass_1',\n",
       " 'Pclass_2',\n",
       " 'Pclass_3']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Anova"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SelectKBest(k='all', score_func=<function f_classif at 0x7f08718f1d08>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select K Best \n",
    "from sklearn.feature_selection import SelectKBest,f_classif,chi2,SelectFpr,SelectFdr\n",
    "\n",
    "# Perform feature selection\n",
    "selector_anova = SelectKBest(f_classif, k=\"all\")\n",
    "#selector_chi2 = SelectKBest(chi2, k=\"all\")\n",
    "\n",
    "selector_anova.fit(data, target)\n",
    "#selector_chi2.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>Anova score</th>\n",
       "      <th>Anova pval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Title_aggr_Mr</td>\n",
       "      <td>383.945495</td>\n",
       "      <td>2.428783e-71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Sex_female</td>\n",
       "      <td>372.405724</td>\n",
       "      <td>1.406066e-69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Sex_male</td>\n",
       "      <td>372.405724</td>\n",
       "      <td>1.406066e-69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Title_aggr_Mrs</td>\n",
       "      <td>120.057834</td>\n",
       "      <td>2.705436e-26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Title_aggr_Miss</td>\n",
       "      <td>110.722014</td>\n",
       "      <td>1.745276e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Pclass_3</td>\n",
       "      <td>103.057599</td>\n",
       "      <td>5.510281e-23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Pclass_1</td>\n",
       "      <td>79.136403</td>\n",
       "      <td>3.190582e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Size_Family_Small</td>\n",
       "      <td>75.541509</td>\n",
       "      <td>1.702390e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Name_Size_Long</td>\n",
       "      <td>71.845856</td>\n",
       "      <td>9.592044e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fare</td>\n",
       "      <td>63.030764</td>\n",
       "      <td>6.120189e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Size_Family_Alone</td>\n",
       "      <td>38.353651</td>\n",
       "      <td>9.009490e-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Name_Size_Short</td>\n",
       "      <td>34.448532</td>\n",
       "      <td>6.174467e-09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Embarked_C</td>\n",
       "      <td>27.992306</td>\n",
       "      <td>1.534670e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Embarked_S</td>\n",
       "      <td>22.075469</td>\n",
       "      <td>3.036111e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Size_Family_Big</td>\n",
       "      <td>14.144877</td>\n",
       "      <td>1.803342e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pclass_2</td>\n",
       "      <td>7.814805</td>\n",
       "      <td>5.293655e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Title_aggr_Master</td>\n",
       "      <td>6.503635</td>\n",
       "      <td>1.093211e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Name_Size_Very Long</td>\n",
       "      <td>6.482458</td>\n",
       "      <td>1.106214e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Age</td>\n",
       "      <td>3.168504</td>\n",
       "      <td>7.541267e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Title_aggr_Royalty</td>\n",
       "      <td>0.992285</td>\n",
       "      <td>3.194555e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Title_aggr_Officer</td>\n",
       "      <td>0.872673</td>\n",
       "      <td>3.504702e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Embarked_Q</td>\n",
       "      <td>0.011846</td>\n",
       "      <td>9.133532e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Name_Size_Medium</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>9.793749e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                feature  Anova score    Anova pval\n",
       "9   Title_aggr_Mr        383.945495   2.428783e-71\n",
       "5   Sex_female           372.405724   1.406066e-69\n",
       "6   Sex_male             372.405724   1.406066e-69\n",
       "10  Title_aggr_Mrs       120.057834   2.705436e-26\n",
       "8   Title_aggr_Miss      110.722014   1.745276e-24\n",
       "22  Pclass_3             103.057599   5.510281e-23\n",
       "20  Pclass_1             79.136403    3.190582e-18\n",
       "15  Size_Family_Small    75.541509    1.702390e-17\n",
       "18  Name_Size_Long       71.845856    9.592044e-17\n",
       "0   Fare                 63.030764    6.120189e-15\n",
       "13  Size_Family_Alone    38.353651    9.009490e-10\n",
       "16  Name_Size_Short      34.448532    6.174467e-09\n",
       "2   Embarked_C           27.992306    1.534670e-07\n",
       "4   Embarked_S           22.075469    3.036111e-06\n",
       "14  Size_Family_Big      14.144877    1.803342e-04\n",
       "21  Pclass_2             7.814805     5.293655e-03\n",
       "7   Title_aggr_Master    6.503635     1.093211e-02\n",
       "19  Name_Size_Very Long  6.482458     1.106214e-02\n",
       "1   Age                  3.168504     7.541267e-02\n",
       "12  Title_aggr_Royalty   0.992285     3.194555e-01\n",
       "11  Title_aggr_Officer   0.872673     3.504702e-01\n",
       "3   Embarked_Q           0.011846     9.133532e-01\n",
       "17  Name_Size_Medium     0.000669     9.793749e-01"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get and display result\n",
    "result_selector = pd.DataFrame()\n",
    "result_selector['feature'] = list(data.columns)\n",
    "result_selector['Anova score'] = selector_anova.scores_\n",
    "result_selector['Anova pval'] = selector_anova.pvalues_\n",
    "result_selector.sort_values('Anova score',ascending=False,inplace=True)\n",
    "result_selector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop some features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jules/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/jules/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "data.drop(['Title_aggr_Royalty','Title_aggr_Officer','Name_Size_Medium','Embarked_Q'],axis=1,inplace=True)\n",
    "test_data.drop(['Title_aggr_Royalty','Title_aggr_Officer','Name_Size_Medium','Embarked_Q'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891, 19)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(418, 19)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(data.shape)\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train & Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========================\n",
      "Plotting Learning Curves\n",
      "========================\n",
      "On the left side the learning curve of a naive Bayes classifier is shown for\n",
      "the digits dataset. Note that the training score and the cross-validation score\n",
      "are both not very good at the end. However, the shape of the curve can be found\n",
      "in more complex datasets very often: the training score is very high at the\n",
      "beginning and decreases and the cross-validation score is very low at the\n",
      "beginning and increases. On the right side we see the learning curve of an SVM\n",
      "with RBF kernel. We can see clearly that the training score is still around\n",
      "the maximum and the validation score could be increased with more training\n",
      "samples.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Helper function to analyse and get result\n",
    "\n",
    "# Plot the confusion matrice \n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "\n",
    "# Grid Score into a Pandas Dataframe\n",
    "def cv_results_to_df(cv_results):\n",
    "    \"\"\"\n",
    "    Convert a sklearn.model_selection.GridSearchCV.cv_results_ attribute to a tidy\n",
    "    pandas DataFrame where the output is filtered with only mean std and params.\n",
    "    \"\"\"\n",
    "    df=pd.DataFrame.from_dict(cv_results)\n",
    "    df=df[['mean_test_score', 'std_test_score', 'mean_train_score', 'std_train_score', 'params']]\n",
    "    df.sort_values('mean_test_score',ascending=False,inplace=True)\n",
    "    return df\n",
    "\n",
    "# Helper function for gridseach\n",
    "def grid_search_global(clas_reg, dict_pip, dict_param, class_names):\n",
    "\n",
    "    dict_of_res={}\n",
    "    dict_of_best={}\n",
    "    df_results_global=pd.DataFrame()\n",
    "    \n",
    "    print (\"Starting Gridsearch\")\n",
    "    \n",
    "    for key in dict_param.keys():\n",
    "        gs = GridSearchCV(dict_pip[key], dict_param[key], verbose=0, refit=True, n_jobs=-1, cv=5)\n",
    "        gs = gs.fit(X_train, y_train)\n",
    "        dict_of_res[key]=gs.grid_scores_\n",
    "        \n",
    "        print('\\n-------------------------------------------------------------------------------------------------------')\n",
    "        print (\"Gridsearch for %s \\n\" % dict_param[key])\n",
    "        print (\"Best score :\", gs.best_score_)\n",
    "        print (\"Best params :\",gs.best_params_)\n",
    "        dict_of_best[key]=[gs.best_score_,gs.best_params_]\n",
    "        \n",
    "        y_train_pred=gs.predict(X_train)\n",
    "        y_test_pred=gs.predict(X_test)\n",
    "        \n",
    "        if (clas_reg=='clas'):\n",
    "            \n",
    "            # Classification report\n",
    "            print('\\nClassification report on training set')\n",
    "            print(classification_report(y_train, y_train_pred))\n",
    "            print('\\nClassification report on testing set')\n",
    "            print(classification_report(y_test, y_test_pred))\n",
    "            \n",
    "            # Compute confusion matrix\n",
    "            #cnf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "            #np.set_printoptions(precision=2)\n",
    "\n",
    "            # Plot non-normalized confusion matrix\n",
    "            #plt.figure()\n",
    "            #plot_confusion_matrix(cnf_matrix, classes=class_names,\n",
    "            #                      title='Confusion matrix, without normalization')\n",
    "            \n",
    "            # Plot normalized confusion matrix\n",
    "            #plt.figure()\n",
    "            #plot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True,\n",
    "            #                      title='Normalized confusion matrix')\n",
    "            \n",
    "            #plt.show()\n",
    "        \n",
    "        # Resultats deja présent dans : Grid Score #cv_results_ alégé\n",
    "        #print('\\nGrid Score #grid_scores_')\n",
    "        #pprint(gs.grid_scores_)\n",
    "        \n",
    "        # Obtention des résultats avec selection et réarrangement des attributs puis stockage\n",
    "        df_results=cv_results_to_df(gs.cv_results_)\n",
    "        df_results['Algo']=key\n",
    "        df_results=df_results[['Algo','mean_test_score', 'std_test_score', 'mean_train_score', 'std_train_score', 'params']]\n",
    "        df_results_global=df_results_global.append(df_results)\n",
    "        print(\"\\nGrid Score #cv_results_ alégé\")\n",
    "        display(df_results)\n",
    "        \n",
    "\n",
    "        \n",
    "    # Transformation de dict_of_best en dataframe\n",
    "    df_best=pd.DataFrame.from_dict(dict_of_best,'index')\n",
    "    df_best.columns=['Scores','Parameters']\n",
    "    df_best.sort_values('Scores',ascending=False,inplace=True)  \n",
    "\n",
    "    print('\\n -------------------------------------------------------------------------------------------------------')\n",
    "    print('\\nList of best score and parameters by pipeline')\n",
    "    display(df_best)\n",
    "    print('\\nSummary')\n",
    "    display(df_results_global)\n",
    "    print (\"Gridsearch Finished\")\n",
    "    print('\\n -------------------------------------------------------------------------------------------------------')    \n",
    "    return df_best, dict_of_best, df_results_global\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "========================\n",
    "Plotting Learning Curves\n",
    "========================\n",
    "On the left side the learning curve of a naive Bayes classifier is shown for\n",
    "the digits dataset. Note that the training score and the cross-validation score\n",
    "are both not very good at the end. However, the shape of the curve can be found\n",
    "in more complex datasets very often: the training score is very high at the\n",
    "beginning and decreases and the cross-validation score is very low at the\n",
    "beginning and increases. On the right side we see the learning curve of an SVM\n",
    "with RBF kernel. We can see clearly that the training score is still around\n",
    "the maximum and the validation score could be increased with more training\n",
    "samples.\n",
    "\"\"\"\n",
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "\n",
    "\n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.1, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and training learning curve.\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "    cv : int, cross-validation generator or an iterable, optional\n",
    "        Determines the cross-validation splitting strategy.\n",
    "        Possible inputs for cv are:\n",
    "          - None, to use the default 3-fold cross-validation,\n",
    "          - integer, to specify the number of folds.\n",
    "          - An object to be used as a cross-validation generator.\n",
    "          - An iterable yielding train/test splits.\n",
    "        For integer/None inputs, if ``y`` is binary or multiclass,\n",
    "        :class:`StratifiedKFold` used. If the estimator is not a classifier\n",
    "        or if ``y`` is neither binary nor multiclass, :class:`KFold` is used.\n",
    "        Refer :ref:`User Guide <cross_validation>` for the various\n",
    "        cross-validators that can be used here.\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(0.7, 1)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.model_selection import validation_curve\n",
    "\n",
    "def plot_validation_curve(estimator, estimator_name, param_name, param_range, X, y, cv,\n",
    "    scoring='accuracy', scale='classic' , n_jobs=-1):\n",
    "    \n",
    "    train_scores, test_scores = validation_curve(\n",
    "        estimator, X, y, param_name=param_name, param_range=param_range,\n",
    "        cv=cv, scoring=scoring, n_jobs=n_jobs)\n",
    "\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    \n",
    "    title_fig='Validation Curve with %s' % estimator_name\n",
    "    plt.title(title_fig)\n",
    "    plt.xlabel(param_name)\n",
    "    plt.ylabel(\"Score : %s\" % scoring)\n",
    "    plt.ylim(0.7, 1)\n",
    "    lw = 2\n",
    "    \n",
    "    if (scale=='semilog'):\n",
    "        plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "                     color=\"darkorange\", lw=lw)\n",
    "        plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                         color=\"darkorange\", lw=lw)\n",
    "        plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                     color=\"navy\", lw=lw)\n",
    "        plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                         color=\"navy\", lw=lw)\n",
    "    else :\n",
    "        plt.plot(param_range, train_scores_mean, label=\"Training score\",\n",
    "                     color=\"darkorange\", lw=lw)\n",
    "        plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                         train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                         color=\"darkorange\", lw=lw)\n",
    "        plt.plot(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "                     color=\"navy\", lw=lw)\n",
    "        plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                         test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                         color=\"navy\", lw=lw) \n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multipes Algo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pipeline setup\n",
    "models = { \n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "    'SVC': SVC()\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params = {\n",
    "    # Il faut mettre 'ExtraTreesClassifier__n_estimators' dans 'ExtraTreesClassifier' car on est sur un pipeline \n",
    "    # il est donc possible de préciser des parametres pour chacune des étapes\n",
    "    'RandomForestClassifier': { 'n_estimators': [5, 10, 15, 20, 25, 30, 35] },\n",
    "    'GradientBoostingClassifier': { 'n_estimators': [5, 10, 15, 20, 25, 30, 35], 'learning_rate': [0.8, 1.0] },\n",
    "    'SVC': [\n",
    "        {'kernel': ['linear'], 'C': [1, 10]},\n",
    "        {'kernel': ['rbf'], 'C': [1, 10], 'gamma': [0.001, 0.0001]},\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Lancer la grid search\n",
    "df_best, dic_best, d_res =grid_search_global('clas',models,params,class_names=columns_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train & Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Gridsearch\n",
      "\n",
      "-------------------------------------------------------------------------------------------------------\n",
      "Gridsearch for {'n_estimators': [5, 10, 15, 20, 25, 30, 35, 40], 'learning_rate': [0.01, 0.03, 0.1, 0.2, 0.3], 'loss': ['deviance', 'exponential'], 'max_depth': [2, 3, 4]} \n",
      "\n",
      "Best score : 0.845505617978\n",
      "Best params : {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 40}\n",
      "\n",
      "Classification report on training set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.98      0.95       433\n",
      "          1       0.96      0.89      0.92       279\n",
      "\n",
      "avg / total       0.94      0.94      0.94       712\n",
      "\n",
      "\n",
      "Classification report on testing set\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.88      0.85       116\n",
      "          1       0.75      0.65      0.69        63\n",
      "\n",
      "avg / total       0.80      0.80      0.80       179\n",
      "\n",
      "\n",
      "Grid Score #cv_results_ alégé\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.845506</td>\n",
       "      <td>0.027068</td>\n",
       "      <td>0.936795</td>\n",
       "      <td>0.004488</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.845506</td>\n",
       "      <td>0.034211</td>\n",
       "      <td>0.950848</td>\n",
       "      <td>0.003614</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.844101</td>\n",
       "      <td>0.034065</td>\n",
       "      <td>0.873955</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 35}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.844101</td>\n",
       "      <td>0.028505</td>\n",
       "      <td>0.934689</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>{'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.844101</td>\n",
       "      <td>0.033609</td>\n",
       "      <td>0.887638</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.023450</td>\n",
       "      <td>0.930122</td>\n",
       "      <td>0.006069</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 35}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.033841</td>\n",
       "      <td>0.930484</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.031450</td>\n",
       "      <td>0.876054</td>\n",
       "      <td>0.007974</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.027395</td>\n",
       "      <td>0.900641</td>\n",
       "      <td>0.008758</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.029013</td>\n",
       "      <td>0.943114</td>\n",
       "      <td>0.005768</td>\n",
       "      <td>{'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.034817</td>\n",
       "      <td>0.904496</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.030297</td>\n",
       "      <td>0.878163</td>\n",
       "      <td>0.011914</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.032399</td>\n",
       "      <td>0.876406</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 35}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.918894</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>{'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.031972</td>\n",
       "      <td>0.871143</td>\n",
       "      <td>0.007805</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.030615</td>\n",
       "      <td>0.895719</td>\n",
       "      <td>0.008686</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.035240</td>\n",
       "      <td>0.896070</td>\n",
       "      <td>0.007616</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.873251</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.037341</td>\n",
       "      <td>0.873602</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.030345</td>\n",
       "      <td>0.898872</td>\n",
       "      <td>0.006014</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.035598</td>\n",
       "      <td>0.881317</td>\n",
       "      <td>0.009508</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.030773</td>\n",
       "      <td>0.866235</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.018759</td>\n",
       "      <td>0.953302</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>{'learning_rate': 0.3, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.892560</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.037088</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.027399</td>\n",
       "      <td>0.954702</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>{'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.033817</td>\n",
       "      <td>0.917837</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.033627</td>\n",
       "      <td>0.946282</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 35}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.031618</td>\n",
       "      <td>0.872198</td>\n",
       "      <td>0.009021</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.036165</td>\n",
       "      <td>0.937153</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.641854</td>\n",
       "      <td>0.066283</td>\n",
       "      <td>0.642883</td>\n",
       "      <td>0.069787</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.612360</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>0.610607</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Algo  mean_test_score  std_test_score  \\\n",
       "191  GradientBoostingClassifier  0.845506         0.027068         \n",
       "167  GradientBoostingClassifier  0.845506         0.034211         \n",
       "94   GradientBoostingClassifier  0.844101         0.034065         \n",
       "236  GradientBoostingClassifier  0.844101         0.028505         \n",
       "115  GradientBoostingClassifier  0.844101         0.033609         \n",
       "190  GradientBoostingClassifier  0.842697         0.023450         \n",
       "164  GradientBoostingClassifier  0.842697         0.033841         \n",
       "71   GradientBoostingClassifier  0.842697         0.031450         \n",
       "183  GradientBoostingClassifier  0.841292         0.027395         \n",
       "237  GradientBoostingClassifier  0.841292         0.029013         \n",
       "162  GradientBoostingClassifier  0.841292         0.034817         \n",
       "95   GradientBoostingClassifier  0.841292         0.030297         \n",
       "70   GradientBoostingClassifier  0.841292         0.032399         \n",
       "231  GradientBoostingClassifier  0.839888         0.028540         \n",
       "93   GradientBoostingClassifier  0.839888         0.031972         \n",
       "141  GradientBoostingClassifier  0.839888         0.030615         \n",
       "116  GradientBoostingClassifier  0.839888         0.035240         \n",
       "137  GradientBoostingClassifier  0.839888         0.035800         \n",
       "113  GradientBoostingClassifier  0.839888         0.037341         \n",
       "186  GradientBoostingClassifier  0.839888         0.030345         \n",
       "114  GradientBoostingClassifier  0.839888         0.035598         \n",
       "68   GradientBoostingClassifier  0.839888         0.030773         \n",
       "212  GradientBoostingClassifier  0.839888         0.018759         \n",
       "156  GradientBoostingClassifier  0.838483         0.024900         \n",
       "117  GradientBoostingClassifier  0.838483         0.037088         \n",
       "239  GradientBoostingClassifier  0.838483         0.027399         \n",
       "163  GradientBoostingClassifier  0.838483         0.033817         \n",
       "166  GradientBoostingClassifier  0.838483         0.033627         \n",
       "69   GradientBoostingClassifier  0.838483         0.031618         \n",
       "165  GradientBoostingClassifier  0.838483         0.036165         \n",
       "..                          ...       ...              ...         \n",
       "28   GradientBoostingClassifier  0.641854         0.066283         \n",
       "11   GradientBoostingClassifier  0.612360         0.005945         \n",
       "8    GradientBoostingClassifier  0.608146         0.001387         \n",
       "9    GradientBoostingClassifier  0.608146         0.001387         \n",
       "3    GradientBoostingClassifier  0.608146         0.001387         \n",
       "10   GradientBoostingClassifier  0.608146         0.001387         \n",
       "27   GradientBoostingClassifier  0.608146         0.001387         \n",
       "16   GradientBoostingClassifier  0.608146         0.001387         \n",
       "17   GradientBoostingClassifier  0.608146         0.001387         \n",
       "18   GradientBoostingClassifier  0.608146         0.001387         \n",
       "2    GradientBoostingClassifier  0.608146         0.001387         \n",
       "24   GradientBoostingClassifier  0.608146         0.001387         \n",
       "25   GradientBoostingClassifier  0.608146         0.001387         \n",
       "26   GradientBoostingClassifier  0.608146         0.001387         \n",
       "1    GradientBoostingClassifier  0.608146         0.001387         \n",
       "32   GradientBoostingClassifier  0.608146         0.001387         \n",
       "33   GradientBoostingClassifier  0.608146         0.001387         \n",
       "34   GradientBoostingClassifier  0.608146         0.001387         \n",
       "35   GradientBoostingClassifier  0.608146         0.001387         \n",
       "40   GradientBoostingClassifier  0.608146         0.001387         \n",
       "41   GradientBoostingClassifier  0.608146         0.001387         \n",
       "42   GradientBoostingClassifier  0.608146         0.001387         \n",
       "43   GradientBoostingClassifier  0.608146         0.001387         \n",
       "48   GradientBoostingClassifier  0.608146         0.001387         \n",
       "56   GradientBoostingClassifier  0.608146         0.001387         \n",
       "64   GradientBoostingClassifier  0.608146         0.001387         \n",
       "72   GradientBoostingClassifier  0.608146         0.001387         \n",
       "80   GradientBoostingClassifier  0.608146         0.001387         \n",
       "88   GradientBoostingClassifier  0.608146         0.001387         \n",
       "0    GradientBoostingClassifier  0.608146         0.001387         \n",
       "\n",
       "     mean_train_score  std_train_score  \\\n",
       "191  0.936795          0.004488          \n",
       "167  0.950848          0.003614          \n",
       "94   0.873955          0.010638          \n",
       "236  0.934689          0.002623          \n",
       "115  0.887638          0.007327          \n",
       "190  0.930122          0.006069          \n",
       "164  0.930484          0.006739          \n",
       "71   0.876054          0.007974          \n",
       "183  0.900641          0.008758          \n",
       "237  0.943114          0.005768          \n",
       "162  0.904496          0.006319          \n",
       "95   0.878163          0.011914          \n",
       "70   0.876406          0.008979          \n",
       "231  0.918894          0.007113          \n",
       "93   0.871143          0.007805          \n",
       "141  0.895719          0.008686          \n",
       "116  0.896070          0.007616          \n",
       "137  0.873251          0.009091          \n",
       "113  0.873602          0.008999          \n",
       "186  0.898872          0.006014          \n",
       "114  0.881317          0.009508          \n",
       "68   0.866235          0.012183          \n",
       "212  0.953302          0.004084          \n",
       "156  0.892560          0.003280          \n",
       "117  0.906250          0.004237          \n",
       "239  0.954702          0.002635          \n",
       "163  0.917837          0.005256          \n",
       "166  0.946282          0.004472          \n",
       "69   0.872198          0.009021          \n",
       "165  0.937153          0.006757          \n",
       "..        ...               ...          \n",
       "28   0.642883          0.069787          \n",
       "11   0.610607          0.003034          \n",
       "8    0.608146          0.000346          \n",
       "9    0.608146          0.000346          \n",
       "3    0.608146          0.000346          \n",
       "10   0.608146          0.000346          \n",
       "27   0.608146          0.000346          \n",
       "16   0.608146          0.000346          \n",
       "17   0.608146          0.000346          \n",
       "18   0.608146          0.000346          \n",
       "2    0.608146          0.000346          \n",
       "24   0.608146          0.000346          \n",
       "25   0.608146          0.000346          \n",
       "26   0.608146          0.000346          \n",
       "1    0.608146          0.000346          \n",
       "32   0.608146          0.000346          \n",
       "33   0.608146          0.000346          \n",
       "34   0.608146          0.000346          \n",
       "35   0.608146          0.000346          \n",
       "40   0.608146          0.000346          \n",
       "41   0.608146          0.000346          \n",
       "42   0.608146          0.000346          \n",
       "43   0.608146          0.000346          \n",
       "48   0.608146          0.000346          \n",
       "56   0.608146          0.000346          \n",
       "64   0.608146          0.000346          \n",
       "72   0.608146          0.000346          \n",
       "80   0.608146          0.000346          \n",
       "88   0.608146          0.000346          \n",
       "0    0.608146          0.000346          \n",
       "\n",
       "                                                                                 params  \n",
       "191  {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 40}   \n",
       "167  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 40}      \n",
       "94   {'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 35}  \n",
       "236  {'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 25}   \n",
       "115  {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 20}      \n",
       "190  {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 35}   \n",
       "164  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}      \n",
       "71   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 40}     \n",
       "183  {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 40}   \n",
       "237  {'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 30}   \n",
       "162  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 15}      \n",
       "95   {'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 40}  \n",
       "70   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 35}     \n",
       "231  {'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 40}   \n",
       "93   {'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 30}  \n",
       "141  {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 30}   \n",
       "116  {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}      \n",
       "137  {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 10}   \n",
       "113  {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 10}      \n",
       "186  {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 15}   \n",
       "114  {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 15}      \n",
       "68   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}     \n",
       "212  {'learning_rate': 0.3, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}      \n",
       "156  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 25}      \n",
       "117  {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 30}      \n",
       "239  {'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 40}   \n",
       "163  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 20}      \n",
       "166  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 35}      \n",
       "69   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 30}     \n",
       "165  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 30}      \n",
       "..                                                                              ...      \n",
       "28   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 25}  \n",
       "11   {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 20}     \n",
       "8    {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 5}      \n",
       "9    {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 10}     \n",
       "3    {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 20}     \n",
       "10   {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 15}     \n",
       "27   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 20}  \n",
       "16   {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 5}      \n",
       "17   {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 10}     \n",
       "18   {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 15}     \n",
       "2    {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 15}     \n",
       "24   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 5}   \n",
       "25   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 10}  \n",
       "26   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 15}  \n",
       "1    {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 10}     \n",
       "32   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 5}   \n",
       "33   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 10}  \n",
       "34   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 15}  \n",
       "35   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 20}  \n",
       "40   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 5}   \n",
       "41   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 10}  \n",
       "42   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 15}  \n",
       "43   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 20}  \n",
       "48   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 5}      \n",
       "56   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 5}      \n",
       "64   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 5}      \n",
       "72   {'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 5}   \n",
       "80   {'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 5}   \n",
       "88   {'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 5}   \n",
       "0    {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 5}      \n",
       "\n",
       "[240 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " -------------------------------------------------------------------------------------------------------\n",
      "\n",
      "List of best score and parameters by pipeline\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Scores</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GradientBoostingClassifier</th>\n",
       "      <td>0.845506</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Scores  \\\n",
       "GradientBoostingClassifier  0.845506   \n",
       "\n",
       "                                                                                                Parameters  \n",
       "GradientBoostingClassifier  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 40}  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.845506</td>\n",
       "      <td>0.027068</td>\n",
       "      <td>0.936795</td>\n",
       "      <td>0.004488</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.845506</td>\n",
       "      <td>0.034211</td>\n",
       "      <td>0.950848</td>\n",
       "      <td>0.003614</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.844101</td>\n",
       "      <td>0.034065</td>\n",
       "      <td>0.873955</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 35}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.844101</td>\n",
       "      <td>0.028505</td>\n",
       "      <td>0.934689</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>{'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.844101</td>\n",
       "      <td>0.033609</td>\n",
       "      <td>0.887638</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.023450</td>\n",
       "      <td>0.930122</td>\n",
       "      <td>0.006069</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 35}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.033841</td>\n",
       "      <td>0.930484</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.031450</td>\n",
       "      <td>0.876054</td>\n",
       "      <td>0.007974</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.027395</td>\n",
       "      <td>0.900641</td>\n",
       "      <td>0.008758</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.029013</td>\n",
       "      <td>0.943114</td>\n",
       "      <td>0.005768</td>\n",
       "      <td>{'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.034817</td>\n",
       "      <td>0.904496</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.030297</td>\n",
       "      <td>0.878163</td>\n",
       "      <td>0.011914</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.032399</td>\n",
       "      <td>0.876406</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 35}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.918894</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>{'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.031972</td>\n",
       "      <td>0.871143</td>\n",
       "      <td>0.007805</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.030615</td>\n",
       "      <td>0.895719</td>\n",
       "      <td>0.008686</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.035240</td>\n",
       "      <td>0.896070</td>\n",
       "      <td>0.007616</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.873251</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.037341</td>\n",
       "      <td>0.873602</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.030345</td>\n",
       "      <td>0.898872</td>\n",
       "      <td>0.006014</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.035598</td>\n",
       "      <td>0.881317</td>\n",
       "      <td>0.009508</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.030773</td>\n",
       "      <td>0.866235</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.018759</td>\n",
       "      <td>0.953302</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>{'learning_rate': 0.3, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.892560</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.037088</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.027399</td>\n",
       "      <td>0.954702</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>{'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.033817</td>\n",
       "      <td>0.917837</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.033627</td>\n",
       "      <td>0.946282</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 35}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.031618</td>\n",
       "      <td>0.872198</td>\n",
       "      <td>0.009021</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.036165</td>\n",
       "      <td>0.937153</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.641854</td>\n",
       "      <td>0.066283</td>\n",
       "      <td>0.642883</td>\n",
       "      <td>0.069787</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.612360</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>0.610607</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Algo  mean_test_score  std_test_score  \\\n",
       "191  GradientBoostingClassifier  0.845506         0.027068         \n",
       "167  GradientBoostingClassifier  0.845506         0.034211         \n",
       "94   GradientBoostingClassifier  0.844101         0.034065         \n",
       "236  GradientBoostingClassifier  0.844101         0.028505         \n",
       "115  GradientBoostingClassifier  0.844101         0.033609         \n",
       "190  GradientBoostingClassifier  0.842697         0.023450         \n",
       "164  GradientBoostingClassifier  0.842697         0.033841         \n",
       "71   GradientBoostingClassifier  0.842697         0.031450         \n",
       "183  GradientBoostingClassifier  0.841292         0.027395         \n",
       "237  GradientBoostingClassifier  0.841292         0.029013         \n",
       "162  GradientBoostingClassifier  0.841292         0.034817         \n",
       "95   GradientBoostingClassifier  0.841292         0.030297         \n",
       "70   GradientBoostingClassifier  0.841292         0.032399         \n",
       "231  GradientBoostingClassifier  0.839888         0.028540         \n",
       "93   GradientBoostingClassifier  0.839888         0.031972         \n",
       "141  GradientBoostingClassifier  0.839888         0.030615         \n",
       "116  GradientBoostingClassifier  0.839888         0.035240         \n",
       "137  GradientBoostingClassifier  0.839888         0.035800         \n",
       "113  GradientBoostingClassifier  0.839888         0.037341         \n",
       "186  GradientBoostingClassifier  0.839888         0.030345         \n",
       "114  GradientBoostingClassifier  0.839888         0.035598         \n",
       "68   GradientBoostingClassifier  0.839888         0.030773         \n",
       "212  GradientBoostingClassifier  0.839888         0.018759         \n",
       "156  GradientBoostingClassifier  0.838483         0.024900         \n",
       "117  GradientBoostingClassifier  0.838483         0.037088         \n",
       "239  GradientBoostingClassifier  0.838483         0.027399         \n",
       "163  GradientBoostingClassifier  0.838483         0.033817         \n",
       "166  GradientBoostingClassifier  0.838483         0.033627         \n",
       "69   GradientBoostingClassifier  0.838483         0.031618         \n",
       "165  GradientBoostingClassifier  0.838483         0.036165         \n",
       "..                          ...       ...              ...         \n",
       "28   GradientBoostingClassifier  0.641854         0.066283         \n",
       "11   GradientBoostingClassifier  0.612360         0.005945         \n",
       "8    GradientBoostingClassifier  0.608146         0.001387         \n",
       "9    GradientBoostingClassifier  0.608146         0.001387         \n",
       "3    GradientBoostingClassifier  0.608146         0.001387         \n",
       "10   GradientBoostingClassifier  0.608146         0.001387         \n",
       "27   GradientBoostingClassifier  0.608146         0.001387         \n",
       "16   GradientBoostingClassifier  0.608146         0.001387         \n",
       "17   GradientBoostingClassifier  0.608146         0.001387         \n",
       "18   GradientBoostingClassifier  0.608146         0.001387         \n",
       "2    GradientBoostingClassifier  0.608146         0.001387         \n",
       "24   GradientBoostingClassifier  0.608146         0.001387         \n",
       "25   GradientBoostingClassifier  0.608146         0.001387         \n",
       "26   GradientBoostingClassifier  0.608146         0.001387         \n",
       "1    GradientBoostingClassifier  0.608146         0.001387         \n",
       "32   GradientBoostingClassifier  0.608146         0.001387         \n",
       "33   GradientBoostingClassifier  0.608146         0.001387         \n",
       "34   GradientBoostingClassifier  0.608146         0.001387         \n",
       "35   GradientBoostingClassifier  0.608146         0.001387         \n",
       "40   GradientBoostingClassifier  0.608146         0.001387         \n",
       "41   GradientBoostingClassifier  0.608146         0.001387         \n",
       "42   GradientBoostingClassifier  0.608146         0.001387         \n",
       "43   GradientBoostingClassifier  0.608146         0.001387         \n",
       "48   GradientBoostingClassifier  0.608146         0.001387         \n",
       "56   GradientBoostingClassifier  0.608146         0.001387         \n",
       "64   GradientBoostingClassifier  0.608146         0.001387         \n",
       "72   GradientBoostingClassifier  0.608146         0.001387         \n",
       "80   GradientBoostingClassifier  0.608146         0.001387         \n",
       "88   GradientBoostingClassifier  0.608146         0.001387         \n",
       "0    GradientBoostingClassifier  0.608146         0.001387         \n",
       "\n",
       "     mean_train_score  std_train_score  \\\n",
       "191  0.936795          0.004488          \n",
       "167  0.950848          0.003614          \n",
       "94   0.873955          0.010638          \n",
       "236  0.934689          0.002623          \n",
       "115  0.887638          0.007327          \n",
       "190  0.930122          0.006069          \n",
       "164  0.930484          0.006739          \n",
       "71   0.876054          0.007974          \n",
       "183  0.900641          0.008758          \n",
       "237  0.943114          0.005768          \n",
       "162  0.904496          0.006319          \n",
       "95   0.878163          0.011914          \n",
       "70   0.876406          0.008979          \n",
       "231  0.918894          0.007113          \n",
       "93   0.871143          0.007805          \n",
       "141  0.895719          0.008686          \n",
       "116  0.896070          0.007616          \n",
       "137  0.873251          0.009091          \n",
       "113  0.873602          0.008999          \n",
       "186  0.898872          0.006014          \n",
       "114  0.881317          0.009508          \n",
       "68   0.866235          0.012183          \n",
       "212  0.953302          0.004084          \n",
       "156  0.892560          0.003280          \n",
       "117  0.906250          0.004237          \n",
       "239  0.954702          0.002635          \n",
       "163  0.917837          0.005256          \n",
       "166  0.946282          0.004472          \n",
       "69   0.872198          0.009021          \n",
       "165  0.937153          0.006757          \n",
       "..        ...               ...          \n",
       "28   0.642883          0.069787          \n",
       "11   0.610607          0.003034          \n",
       "8    0.608146          0.000346          \n",
       "9    0.608146          0.000346          \n",
       "3    0.608146          0.000346          \n",
       "10   0.608146          0.000346          \n",
       "27   0.608146          0.000346          \n",
       "16   0.608146          0.000346          \n",
       "17   0.608146          0.000346          \n",
       "18   0.608146          0.000346          \n",
       "2    0.608146          0.000346          \n",
       "24   0.608146          0.000346          \n",
       "25   0.608146          0.000346          \n",
       "26   0.608146          0.000346          \n",
       "1    0.608146          0.000346          \n",
       "32   0.608146          0.000346          \n",
       "33   0.608146          0.000346          \n",
       "34   0.608146          0.000346          \n",
       "35   0.608146          0.000346          \n",
       "40   0.608146          0.000346          \n",
       "41   0.608146          0.000346          \n",
       "42   0.608146          0.000346          \n",
       "43   0.608146          0.000346          \n",
       "48   0.608146          0.000346          \n",
       "56   0.608146          0.000346          \n",
       "64   0.608146          0.000346          \n",
       "72   0.608146          0.000346          \n",
       "80   0.608146          0.000346          \n",
       "88   0.608146          0.000346          \n",
       "0    0.608146          0.000346          \n",
       "\n",
       "                                                                                 params  \n",
       "191  {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 40}   \n",
       "167  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 40}      \n",
       "94   {'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 35}  \n",
       "236  {'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 25}   \n",
       "115  {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 20}      \n",
       "190  {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 35}   \n",
       "164  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}      \n",
       "71   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 40}     \n",
       "183  {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 40}   \n",
       "237  {'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 30}   \n",
       "162  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 15}      \n",
       "95   {'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 40}  \n",
       "70   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 35}     \n",
       "231  {'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 40}   \n",
       "93   {'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 30}  \n",
       "141  {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 30}   \n",
       "116  {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}      \n",
       "137  {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 10}   \n",
       "113  {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 10}      \n",
       "186  {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 15}   \n",
       "114  {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 15}      \n",
       "68   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}     \n",
       "212  {'learning_rate': 0.3, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}      \n",
       "156  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 25}      \n",
       "117  {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 30}      \n",
       "239  {'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 40}   \n",
       "163  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 20}      \n",
       "166  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 35}      \n",
       "69   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 30}     \n",
       "165  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 30}      \n",
       "..                                                                              ...      \n",
       "28   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 25}  \n",
       "11   {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 20}     \n",
       "8    {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 5}      \n",
       "9    {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 10}     \n",
       "3    {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 20}     \n",
       "10   {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 15}     \n",
       "27   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 20}  \n",
       "16   {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 5}      \n",
       "17   {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 10}     \n",
       "18   {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 15}     \n",
       "2    {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 15}     \n",
       "24   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 5}   \n",
       "25   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 10}  \n",
       "26   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 15}  \n",
       "1    {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 10}     \n",
       "32   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 5}   \n",
       "33   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 10}  \n",
       "34   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 15}  \n",
       "35   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 20}  \n",
       "40   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 5}   \n",
       "41   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 10}  \n",
       "42   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 15}  \n",
       "43   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 20}  \n",
       "48   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 5}      \n",
       "56   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 5}      \n",
       "64   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 5}      \n",
       "72   {'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 5}   \n",
       "80   {'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 5}   \n",
       "88   {'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 5}   \n",
       "0    {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 5}      \n",
       "\n",
       "[240 rows x 6 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gridsearch Finished\n",
      "\n",
      " -------------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Pipeline setup\n",
    "models = { \n",
    "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params = {\n",
    "    'GradientBoostingClassifier': { 'n_estimators': [ 5,10,15,20,25,30,35,40], \n",
    "                                   'learning_rate': [0.01,0.03,0.1,0.2,0.3,0.4,0.5,0.6,0.7],\n",
    "                                  'loss' : ['deviance','exponential'],\n",
    "                                  'max_depth' : [3,4,5,6,7,8,9],\n",
    "                                   'min_samples_split': [2,3,4,5,6,7,8,9],\n",
    "                                   'min_samples_leaf' : [1,2,3,4,5,6],\n",
    "                                   'max_features' : np.range(4,19,2)\n",
    "                                  }\n",
    "}\n",
    "\n",
    "# Lancer la grid search\n",
    "df_best, dic_best, d_res =grid_search_global('clas',models,params,class_names=columns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algo</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "      <th>params</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.845506</td>\n",
       "      <td>0.027068</td>\n",
       "      <td>0.936795</td>\n",
       "      <td>0.004488</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.845506</td>\n",
       "      <td>0.034211</td>\n",
       "      <td>0.950848</td>\n",
       "      <td>0.003614</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.844101</td>\n",
       "      <td>0.034065</td>\n",
       "      <td>0.873955</td>\n",
       "      <td>0.010638</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 35}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.844101</td>\n",
       "      <td>0.028505</td>\n",
       "      <td>0.934689</td>\n",
       "      <td>0.002623</td>\n",
       "      <td>{'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.844101</td>\n",
       "      <td>0.033609</td>\n",
       "      <td>0.887638</td>\n",
       "      <td>0.007327</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.023450</td>\n",
       "      <td>0.930122</td>\n",
       "      <td>0.006069</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 35}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.033841</td>\n",
       "      <td>0.930484</td>\n",
       "      <td>0.006739</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.842697</td>\n",
       "      <td>0.031450</td>\n",
       "      <td>0.876054</td>\n",
       "      <td>0.007974</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.027395</td>\n",
       "      <td>0.900641</td>\n",
       "      <td>0.008758</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.029013</td>\n",
       "      <td>0.943114</td>\n",
       "      <td>0.005768</td>\n",
       "      <td>{'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.034817</td>\n",
       "      <td>0.904496</td>\n",
       "      <td>0.006319</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.030297</td>\n",
       "      <td>0.878163</td>\n",
       "      <td>0.011914</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.841292</td>\n",
       "      <td>0.032399</td>\n",
       "      <td>0.876406</td>\n",
       "      <td>0.008979</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 35}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.028540</td>\n",
       "      <td>0.918894</td>\n",
       "      <td>0.007113</td>\n",
       "      <td>{'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.031972</td>\n",
       "      <td>0.871143</td>\n",
       "      <td>0.007805</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>141</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.030615</td>\n",
       "      <td>0.895719</td>\n",
       "      <td>0.008686</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.035240</td>\n",
       "      <td>0.896070</td>\n",
       "      <td>0.007616</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.035800</td>\n",
       "      <td>0.873251</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.037341</td>\n",
       "      <td>0.873602</td>\n",
       "      <td>0.008999</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.030345</td>\n",
       "      <td>0.898872</td>\n",
       "      <td>0.006014</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.035598</td>\n",
       "      <td>0.881317</td>\n",
       "      <td>0.009508</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.030773</td>\n",
       "      <td>0.866235</td>\n",
       "      <td>0.012183</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.018759</td>\n",
       "      <td>0.953302</td>\n",
       "      <td>0.004084</td>\n",
       "      <td>{'learning_rate': 0.3, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.024900</td>\n",
       "      <td>0.892560</td>\n",
       "      <td>0.003280</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.037088</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0.004237</td>\n",
       "      <td>{'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.027399</td>\n",
       "      <td>0.954702</td>\n",
       "      <td>0.002635</td>\n",
       "      <td>{'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 40}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.033817</td>\n",
       "      <td>0.917837</td>\n",
       "      <td>0.005256</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.033627</td>\n",
       "      <td>0.946282</td>\n",
       "      <td>0.004472</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 35}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.031618</td>\n",
       "      <td>0.872198</td>\n",
       "      <td>0.009021</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.838483</td>\n",
       "      <td>0.036165</td>\n",
       "      <td>0.937153</td>\n",
       "      <td>0.006757</td>\n",
       "      <td>{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 30}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.641854</td>\n",
       "      <td>0.066283</td>\n",
       "      <td>0.642883</td>\n",
       "      <td>0.069787</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 25}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.612360</td>\n",
       "      <td>0.005945</td>\n",
       "      <td>0.610607</td>\n",
       "      <td>0.003034</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 10}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 15}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 20}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GradientBoostingClassifier</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.001387</td>\n",
       "      <td>0.608146</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>{'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 5}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Algo  mean_test_score  std_test_score  \\\n",
       "191  GradientBoostingClassifier  0.845506         0.027068         \n",
       "167  GradientBoostingClassifier  0.845506         0.034211         \n",
       "94   GradientBoostingClassifier  0.844101         0.034065         \n",
       "236  GradientBoostingClassifier  0.844101         0.028505         \n",
       "115  GradientBoostingClassifier  0.844101         0.033609         \n",
       "190  GradientBoostingClassifier  0.842697         0.023450         \n",
       "164  GradientBoostingClassifier  0.842697         0.033841         \n",
       "71   GradientBoostingClassifier  0.842697         0.031450         \n",
       "183  GradientBoostingClassifier  0.841292         0.027395         \n",
       "237  GradientBoostingClassifier  0.841292         0.029013         \n",
       "162  GradientBoostingClassifier  0.841292         0.034817         \n",
       "95   GradientBoostingClassifier  0.841292         0.030297         \n",
       "70   GradientBoostingClassifier  0.841292         0.032399         \n",
       "231  GradientBoostingClassifier  0.839888         0.028540         \n",
       "93   GradientBoostingClassifier  0.839888         0.031972         \n",
       "141  GradientBoostingClassifier  0.839888         0.030615         \n",
       "116  GradientBoostingClassifier  0.839888         0.035240         \n",
       "137  GradientBoostingClassifier  0.839888         0.035800         \n",
       "113  GradientBoostingClassifier  0.839888         0.037341         \n",
       "186  GradientBoostingClassifier  0.839888         0.030345         \n",
       "114  GradientBoostingClassifier  0.839888         0.035598         \n",
       "68   GradientBoostingClassifier  0.839888         0.030773         \n",
       "212  GradientBoostingClassifier  0.839888         0.018759         \n",
       "156  GradientBoostingClassifier  0.838483         0.024900         \n",
       "117  GradientBoostingClassifier  0.838483         0.037088         \n",
       "239  GradientBoostingClassifier  0.838483         0.027399         \n",
       "163  GradientBoostingClassifier  0.838483         0.033817         \n",
       "166  GradientBoostingClassifier  0.838483         0.033627         \n",
       "69   GradientBoostingClassifier  0.838483         0.031618         \n",
       "165  GradientBoostingClassifier  0.838483         0.036165         \n",
       "..                          ...       ...              ...         \n",
       "28   GradientBoostingClassifier  0.641854         0.066283         \n",
       "11   GradientBoostingClassifier  0.612360         0.005945         \n",
       "8    GradientBoostingClassifier  0.608146         0.001387         \n",
       "9    GradientBoostingClassifier  0.608146         0.001387         \n",
       "3    GradientBoostingClassifier  0.608146         0.001387         \n",
       "10   GradientBoostingClassifier  0.608146         0.001387         \n",
       "27   GradientBoostingClassifier  0.608146         0.001387         \n",
       "16   GradientBoostingClassifier  0.608146         0.001387         \n",
       "17   GradientBoostingClassifier  0.608146         0.001387         \n",
       "18   GradientBoostingClassifier  0.608146         0.001387         \n",
       "2    GradientBoostingClassifier  0.608146         0.001387         \n",
       "24   GradientBoostingClassifier  0.608146         0.001387         \n",
       "25   GradientBoostingClassifier  0.608146         0.001387         \n",
       "26   GradientBoostingClassifier  0.608146         0.001387         \n",
       "1    GradientBoostingClassifier  0.608146         0.001387         \n",
       "32   GradientBoostingClassifier  0.608146         0.001387         \n",
       "33   GradientBoostingClassifier  0.608146         0.001387         \n",
       "34   GradientBoostingClassifier  0.608146         0.001387         \n",
       "35   GradientBoostingClassifier  0.608146         0.001387         \n",
       "40   GradientBoostingClassifier  0.608146         0.001387         \n",
       "41   GradientBoostingClassifier  0.608146         0.001387         \n",
       "42   GradientBoostingClassifier  0.608146         0.001387         \n",
       "43   GradientBoostingClassifier  0.608146         0.001387         \n",
       "48   GradientBoostingClassifier  0.608146         0.001387         \n",
       "56   GradientBoostingClassifier  0.608146         0.001387         \n",
       "64   GradientBoostingClassifier  0.608146         0.001387         \n",
       "72   GradientBoostingClassifier  0.608146         0.001387         \n",
       "80   GradientBoostingClassifier  0.608146         0.001387         \n",
       "88   GradientBoostingClassifier  0.608146         0.001387         \n",
       "0    GradientBoostingClassifier  0.608146         0.001387         \n",
       "\n",
       "     mean_train_score  std_train_score  \\\n",
       "191  0.936795          0.004488          \n",
       "167  0.950848          0.003614          \n",
       "94   0.873955          0.010638          \n",
       "236  0.934689          0.002623          \n",
       "115  0.887638          0.007327          \n",
       "190  0.930122          0.006069          \n",
       "164  0.930484          0.006739          \n",
       "71   0.876054          0.007974          \n",
       "183  0.900641          0.008758          \n",
       "237  0.943114          0.005768          \n",
       "162  0.904496          0.006319          \n",
       "95   0.878163          0.011914          \n",
       "70   0.876406          0.008979          \n",
       "231  0.918894          0.007113          \n",
       "93   0.871143          0.007805          \n",
       "141  0.895719          0.008686          \n",
       "116  0.896070          0.007616          \n",
       "137  0.873251          0.009091          \n",
       "113  0.873602          0.008999          \n",
       "186  0.898872          0.006014          \n",
       "114  0.881317          0.009508          \n",
       "68   0.866235          0.012183          \n",
       "212  0.953302          0.004084          \n",
       "156  0.892560          0.003280          \n",
       "117  0.906250          0.004237          \n",
       "239  0.954702          0.002635          \n",
       "163  0.917837          0.005256          \n",
       "166  0.946282          0.004472          \n",
       "69   0.872198          0.009021          \n",
       "165  0.937153          0.006757          \n",
       "..        ...               ...          \n",
       "28   0.642883          0.069787          \n",
       "11   0.610607          0.003034          \n",
       "8    0.608146          0.000346          \n",
       "9    0.608146          0.000346          \n",
       "3    0.608146          0.000346          \n",
       "10   0.608146          0.000346          \n",
       "27   0.608146          0.000346          \n",
       "16   0.608146          0.000346          \n",
       "17   0.608146          0.000346          \n",
       "18   0.608146          0.000346          \n",
       "2    0.608146          0.000346          \n",
       "24   0.608146          0.000346          \n",
       "25   0.608146          0.000346          \n",
       "26   0.608146          0.000346          \n",
       "1    0.608146          0.000346          \n",
       "32   0.608146          0.000346          \n",
       "33   0.608146          0.000346          \n",
       "34   0.608146          0.000346          \n",
       "35   0.608146          0.000346          \n",
       "40   0.608146          0.000346          \n",
       "41   0.608146          0.000346          \n",
       "42   0.608146          0.000346          \n",
       "43   0.608146          0.000346          \n",
       "48   0.608146          0.000346          \n",
       "56   0.608146          0.000346          \n",
       "64   0.608146          0.000346          \n",
       "72   0.608146          0.000346          \n",
       "80   0.608146          0.000346          \n",
       "88   0.608146          0.000346          \n",
       "0    0.608146          0.000346          \n",
       "\n",
       "                                                                                 params  \n",
       "191  {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 40}   \n",
       "167  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 40}      \n",
       "94   {'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 35}  \n",
       "236  {'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 25}   \n",
       "115  {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 20}      \n",
       "190  {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 35}   \n",
       "164  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}      \n",
       "71   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 40}     \n",
       "183  {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 40}   \n",
       "237  {'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 30}   \n",
       "162  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 15}      \n",
       "95   {'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 40}  \n",
       "70   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 35}     \n",
       "231  {'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 40}   \n",
       "93   {'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 30}  \n",
       "141  {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 30}   \n",
       "116  {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}      \n",
       "137  {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 10}   \n",
       "113  {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 10}      \n",
       "186  {'learning_rate': 0.2, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 15}   \n",
       "114  {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 15}      \n",
       "68   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}     \n",
       "212  {'learning_rate': 0.3, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 25}      \n",
       "156  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 25}      \n",
       "117  {'learning_rate': 0.1, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 30}      \n",
       "239  {'learning_rate': 0.3, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 40}   \n",
       "163  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 20}      \n",
       "166  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 35}      \n",
       "69   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 30}     \n",
       "165  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 30}      \n",
       "..                                                                              ...      \n",
       "28   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 25}  \n",
       "11   {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 20}     \n",
       "8    {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 5}      \n",
       "9    {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 10}     \n",
       "3    {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 20}     \n",
       "10   {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 15}     \n",
       "27   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 20}  \n",
       "16   {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 5}      \n",
       "17   {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 10}     \n",
       "18   {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 15}     \n",
       "2    {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 15}     \n",
       "24   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 5}   \n",
       "25   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 10}  \n",
       "26   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 15}  \n",
       "1    {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 10}     \n",
       "32   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 5}   \n",
       "33   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 10}  \n",
       "34   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 15}  \n",
       "35   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 20}  \n",
       "40   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 5}   \n",
       "41   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 10}  \n",
       "42   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 15}  \n",
       "43   {'learning_rate': 0.01, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 20}  \n",
       "48   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 5}      \n",
       "56   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 3, 'n_estimators': 5}      \n",
       "64   {'learning_rate': 0.03, 'loss': 'deviance', 'max_depth': 4, 'n_estimators': 5}      \n",
       "72   {'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 2, 'n_estimators': 5}   \n",
       "80   {'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 3, 'n_estimators': 5}   \n",
       "88   {'learning_rate': 0.03, 'loss': 'exponential', 'max_depth': 4, 'n_estimators': 5}   \n",
       "0    {'learning_rate': 0.01, 'loss': 'deviance', 'max_depth': 2, 'n_estimators': 5}      \n",
       "\n",
       "[240 rows x 6 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Results dataframe\n",
    "d_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "GradientBoostingClassifier : {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3, 'max_features': 16, 'min_samples_leaf': 3, 'min_samples_split': 2, 'n_estimators': 20}\t0.839888\t0.851827\n",
    "GradientBoostingClassifier : {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3, 'max_features': 16, 'min_samples_leaf': 7, 'min_samples_split': 4, 'n_estimators': 20}\t0.839888\t0.852178\n",
    "GradientBoostingClassifier : {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3, 'max_features': 10, 'min_samples_leaf': 7, 'min_samples_split': 6, 'n_estimators': 10}\t0.838483\t0.845508\n",
    "GradientBoostingClassifier : {'learning_rate': 0.1, 'loss': 'exponential', 'max_depth': 3, 'max_features': 10, 'min_samples_leaf': 7, 'min_samples_split': 6, 'n_estimators': 15}\t0.838483\t0.845155\n",
    "\n",
    "\n",
    "{'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3, 'max_features': 10, 'min_samples_leaf': 7, 'min_samples_split': 6, 'n_estimators': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Selection of the parameters to study\n",
    "index_selection = [177,130,106,63,87,86]\n",
    "df_study = d_res.loc[index_selection,['Algo','params','mean_test_score','mean_train_score']]\n",
    "df_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Learning curve\n",
    "index = list(df_study.index)\n",
    "for ind in index :\n",
    "    algo = df_study.loc[ind, 'Algo']\n",
    "    params = df_study.loc[ind, 'params']\n",
    "    mean_test = df_study.loc[ind, 'mean_test_score']\n",
    "    mean_train = df_study.loc[ind, 'mean_train_score']\n",
    "    title = \"Learning Curves for the estimator %s which results are \\n mean test:%s \\n mean train %s \\n with parameters %s)\" % (algo,mean_test,mean_train,params)\n",
    "    cv = ShuffleSplit(n_splits=50, test_size=0.2, random_state=0)\n",
    "    estimator = models[algo]\n",
    "    estimator.set_params(**params)\n",
    "    plot_learning_curve(estimator, title, data, target, (0.3, 1.01), cv=cv, n_jobs=-1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-87-531ad1080a43>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-87-531ad1080a43>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    for ind in index :\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Validation parameters setup\n",
    "dict_Validation = { \n",
    "    'GradientBoostingClassifier':  { 'n_estimators': range(5,100,5), \n",
    "                                   'learning_rate': [0.01,0.03,0.1,0.2,0.3,0.4,0.5,0.6,0.7],\n",
    "                                  'max_depth' : range(2,10,1),\n",
    "                                   'min_samples_split': range(2,10,1),\n",
    "                                   'min_samples_leaf' : range(2,10,1),\n",
    "                                   'max_features' : range(2,19,1)\n",
    "                                  } \n",
    "}\n",
    "\n",
    "for ind in index :\n",
    "    algo = df_study.loc[ind, 'Algo']\n",
    "    params = df_study.loc[ind, 'params']\n",
    "    mean_test = df_study.loc[ind, 'mean_test_score']\n",
    "    mean_train = df_study.loc[ind, 'mean_train_score']\n",
    "    print(\"Model: %s\\nMean test: %s\\nMean train: %s\\nParams: %s\" % (algo,mean_test,mean_train,params))\n",
    "    estimator = models[algo]\n",
    "    estimator.set_params(**params)\n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "    for key, value in dict_Validation[algo].items():\n",
    "        plot_validation_curve(estimator, clef, key, value, X_train, y_train, scoring='accuracy', cv=cv)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prediction \n",
    "GBC_params =  {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3, 'max_features': 10, 'min_samples_leaf': 7, 'min_samples_split': 6, 'n_estimators': 10}\n",
    "gbc = GradientBoostingClassifier(**GBC_params)\n",
    "gbc.fit(X_train,y_train)\n",
    "gbc_pred = gbc.predict(test_data)\n",
    "Prediction['GBC'] = gbc_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pipeline setup\n",
    "# data.drop(['Title_aggr_Royalty','Title_aggr_Officer','Name_Size_Medium','Embarked_Q'],axis=1,inplace=True)\n",
    "# {'criterion': 'gini', 'max_features': 'sqrt', 'min_samples_leaf': 8, 'min_samples_split': 2, 'n_estimators': 30}\n",
    "# Score 80.803 leader board, train with X_train or all data \n",
    "\n",
    "models = { \n",
    "    'RandomForestClassifier': RandomForestClassifier(),\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params = {\n",
    "    # Il faut mettre 'ExtraTreesClassifier__n_estimators' dans 'ExtraTreesClassifier' car on est sur un pipeline \n",
    "    # il est donc possible de préciser des parametres pour chacune des étapes\n",
    "    'RandomForestClassifier': { 'n_estimators': [10, 20, 30, 40, 50, 60],\n",
    "                               'criterion' : ['gini','entropy'],\n",
    "                               'max_features':[6,8,10,12],\n",
    "                               'min_samples_split': [2,3,6,8,10],\n",
    "                               'min_samples_leaf':  [1,3,5,8,10]\n",
    "                              }\n",
    "}\n",
    "\n",
    "# Lancer la grid search\n",
    "df_best, dic_best, d_res =grid_search_global('clas',models,params,class_names=columns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Results dataframe\n",
    "d_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Selection of the parameters to study\n",
    "index_selection = [707,102,199,1031]\n",
    "df_study = d_res.loc[index_selection,['Algo','params','mean_test_score','mean_train_score']]\n",
    "df_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Learning curve\n",
    "index = list(df_study.index)\n",
    "for ind in index :\n",
    "    algo = df_study.loc[ind, 'Algo']\n",
    "    params = df_study.loc[ind, 'params']\n",
    "    mean_test = df_study.loc[ind, 'mean_test_score']\n",
    "    mean_train = df_study.loc[ind, 'mean_train_score']\n",
    "    title = \"Learning Curves for the estimator %s which results are \\n mean test:%s \\n mean train %s \\n with parameters %s)\" % (algo,mean_test,mean_train,params)\n",
    "    cv = ShuffleSplit(n_splits=50, test_size=0.2, random_state=0)\n",
    "    estimator = models[algo]\n",
    "    estimator.set_params(**params)\n",
    "    plot_learning_curve(estimator, title, data, target, (0.3, 1.01), cv=cv, n_jobs=-1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Validation parameters setup\n",
    "dict_Validation = { \n",
    "    'RandomForestClassifier': {'n_estimators': range(1,50,2),\n",
    "                                  'min_samples_split': range(2,10,1),\n",
    "                                  'min_samples_leaf': range(2,10,1)}  \n",
    "}\n",
    "\n",
    "for ind in index :\n",
    "    algo = df_study.loc[ind, 'Algo']\n",
    "    params = df_study.loc[ind, 'params']\n",
    "    mean_test = df_study.loc[ind, 'mean_test_score']\n",
    "    mean_train = df_study.loc[ind, 'mean_train_score']\n",
    "    print(\"Model: %s\\nMean test: %s\\nMean train: %s\\nParams: %s\" % (algo,mean_test,mean_train,params))\n",
    "    estimator = models[algo]\n",
    "    estimator.set_params(**params)\n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "    for key, value in dict_Validation[algo].items():\n",
    "        plot_validation_curve(estimator, algo, key, value, X_train, y_train, scoring='accuracy', cv=cv)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prediction \n",
    "RF_params =  {'criterion': 'entropy', 'max_features': 12, 'min_samples_leaf': 1, 'min_samples_split': 8, 'n_estimators': 10}\n",
    "rf = RandomForestClassifier(**RF_params)\n",
    "rf.fit(X_train,y_train)\n",
    "rf_pred = rf.predict(test_data)\n",
    "Prediction['RF'] = rf_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get and display result\n",
    "Rf_feat_imp = pd.DataFrame()\n",
    "Rf_feat_imp['Feature'] = list(data.columns)\n",
    "Rf_feat_imp['Importance'] = rf.feature_importances_\n",
    "Rf_feat_imp.sort_values('Importance',ascending=False,inplace=True)\n",
    "Rf_feat_imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# From Random Forest\n",
    "importances=rf.feature_importances_\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.title(\"Feature Importances By Random Forest Model\")\n",
    "plt.bar(range(np.size(importances)), importances, align=\"center\")\n",
    "plt.xticks(range(np.size(importances)),list(data.columns),rotation='vertical')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adaboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Pipeline setup\n",
    "models = { \n",
    "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params = {\n",
    "    # Il faut mettre 'ExtraTreesClassifier__n_estimators' dans 'ExtraTreesClassifier' car on est sur un pipeline \n",
    "    # il est donc possible de préciser des parametres pour chacune des étapes\n",
    "    'AdaBoostClassifier': { 'n_estimators': [5, 10, 20, 30, 40, 50 ,100, 500 ],\n",
    "                               'learning_rate' : [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1],\n",
    "                              }\n",
    "}\n",
    "\n",
    "# Lancer la grid search\n",
    "df_best, dic_best, d_res =grid_search_global('clas',models,params,class_names=columns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "ab_params = {'learning_rate': 0.3, 'n_estimators': 20}\n",
    "ab = AdaBoostClassifier(**ab_params)\n",
    "ab.fit(X_train,y_train)\n",
    "ab_pred = ab.predict(test_data)\n",
    "Prediction['AB'] = ab_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pipeline setup\n",
    "models = { \n",
    "    'SVC': SVC()\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params = {\n",
    "    'SVC': [\n",
    "        {'kernel': ['poly'], 'C': [0.3,0.4,0.5,0.6,0.7,0.8,0.9,1], \n",
    "                            'gamma': [0.08,0.09,0.1,0.11,0.12],\n",
    "                            'degree': [2,3]}]}\n",
    "\n",
    "# Lancer la grid search\n",
    "df_best_svc , dic_best_svc, d_res_svc = grid_search_global('clas',models,params,class_names=columns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Results dataframe\n",
    "d_res_svc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Selection of the parameters to study\n",
    "index_selection = [14,32,41,50]\n",
    "svc_study = d_res_svc.loc[index_selection,['Algo','params','mean_test_score','mean_train_score']]\n",
    "svc_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Learning curve\n",
    "df_study = svc_study\n",
    "index = list(df_study.index)\n",
    "for ind in index :\n",
    "    algo = df_study.loc[ind, 'Algo']\n",
    "    params = df_study.loc[ind, 'params']\n",
    "    mean_test = df_study.loc[ind, 'mean_test_score']\n",
    "    mean_train = df_study.loc[ind, 'mean_train_score']\n",
    "    title = \"Learning Curves for the estimator %s which results are \\n mean test:%s \\n mean train %s \\n with parameters %s)\" % (algo,mean_test,mean_train,params)\n",
    "    cv = ShuffleSplit(n_splits=50, test_size=0.2, random_state=0)\n",
    "    estimator = models[algo]\n",
    "    estimator.set_params(**params)\n",
    "    plot_learning_curve(estimator, title, data, target, (0.3, 1.01), cv=cv, n_jobs=-1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validation parameters setup\n",
    "dict_Validation = { \n",
    "    'SVC': { 'C': np.linspace(0.01,1,20),\n",
    "              'gamma': np.linspace(0.01,0.4,20),\n",
    "              'degree': [2,3]}  \n",
    "    }\n",
    "\n",
    "for ind in index :\n",
    "    algo = df_study.loc[ind, 'Algo']\n",
    "    params = df_study.loc[ind, 'params']\n",
    "    mean_test = df_study.loc[ind, 'mean_test_score']\n",
    "    mean_train = df_study.loc[ind, 'mean_train_score']\n",
    "    print(\"Model: %s\\nMean test: %s\\nMean train: %s\\nParams: %s\" % (algo,mean_test,mean_train,params))\n",
    "    estimator = models[algo]\n",
    "    estimator.set_params(**params)\n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "    for key, value in dict_Validation[algo].items():\n",
    "        plot_validation_curve(estimator, algo, key, value, X_train, y_train, scoring='accuracy', cv=cv)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prediction\n",
    "svc_params = {'C': 0.8, 'degree': 2, 'gamma': 0.08, 'kernel': 'poly'}\n",
    "svc = SVC(**svc_params)\n",
    "svc.fit(data,target)\n",
    "svc_pred = svc.predict(test_data)\n",
    "Prediction['SVC'] = svc_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "# Pipeline setup\n",
    "models = { \n",
    "    'LogisticRegression': LogisticRegression()\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params = {'LogisticRegression' : { 'C': [0.1,0.2,0.3,0.4,0.5,0.6,0.8,0.9,1],\n",
    "           'penalty': ['l2'],\n",
    "           'solver': ['newton-cg','lbfgs','liblinear','sag'],\n",
    "           'max_iter': [100,250,500],\n",
    "           'tol':  [1e-4,3e-4,7e-4,1e-3,3e-3],\n",
    "          }\n",
    "         }\n",
    "\n",
    "# Lancer la grid search\n",
    "df_best_svc , dic_best_svc, d_res_svc = grid_search_global('clas',models,params,class_names=columns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Results dataframe\n",
    "d_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Selection of the parameters to study\n",
    "index_selection = [177,130,106,63,87,86]\n",
    "df_study = d_res.loc[index_selection,['Algo','params','mean_test_score','mean_train_score']]\n",
    "df_study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Learning curve\n",
    "index = list(df_study.index)\n",
    "for ind in index :\n",
    "    algo = df_study.loc[ind, 'Algo']\n",
    "    params = df_study.loc[ind, 'params']\n",
    "    mean_test = df_study.loc[ind, 'mean_test_score']\n",
    "    mean_train = df_study.loc[ind, 'mean_train_score']\n",
    "    title = \"Learning Curves for the estimator %s which results are \\n mean test:%s \\n mean train %s \\n with parameters %s)\" % (algo,mean_test,mean_train,params)\n",
    "    cv = ShuffleSplit(n_splits=50, test_size=0.2, random_state=0)\n",
    "    estimator = models[algo]\n",
    "    estimator.set_params(**params)\n",
    "    plot_learning_curve(estimator, title, data, target, (0.3, 1.01), cv=cv, n_jobs=-1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Validation parameters setup\n",
    "dict_Validation = { \n",
    "    'GradientBoostingClassifier': {'n_estimators': range(1,50,2),\n",
    "                                  'learning_rate': np.linspace(0.01,0.5,50),\n",
    "                                  'max_depth': range(1,5,1)}  \n",
    "}\n",
    "\n",
    "for ind in index :\n",
    "    algo = df_study.loc[ind, 'Algo']\n",
    "    params = df_study.loc[ind, 'params']\n",
    "    mean_test = df_study.loc[ind, 'mean_test_score']\n",
    "    mean_train = df_study.loc[ind, 'mean_train_score']\n",
    "    print(\"Model: %s\\nMean test: %s\\nMean train: %s\\nParams: %s\" % (algo,mean_test,mean_train,params))\n",
    "    estimator = models[algo]\n",
    "    estimator.set_params(**params)\n",
    "    cv = ShuffleSplit(n_splits=10, test_size=0.2, random_state=0)\n",
    "    for key, value in dict_Validation[algo].items():\n",
    "        plot_validation_curve(estimator, clef, key, value, X_train, y_train, scoring='accuracy', cv=cv)\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Prediction \n",
    "lr_parm = {'C': 1, 'max_iter': 100, 'penalty': 'l2', 'solver': 'newton-cg', 'tol': 0.0001}\n",
    "lr = LogisticRegression(**lr_parm)\n",
    "lr.fit(X_train,y_train)\n",
    "lr_pred = lr.predict(test_data)\n",
    "Prediction['LR'] = lr_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Voting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Train & Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Classifier default parameters\n",
    "abc = AdaBoostClassifier(learning_rate = 0.5, n_estimators = 20)        \n",
    "lda = LinearDiscriminantAnalysis(n_components = 2, solver='svd')\n",
    "lr = LogisticRegression()\n",
    "svc = SVC(probability=True)\n",
    "rfc = RandomForestClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "# Classifier Tunep parameters\n",
    "abc_tp = AdaBoostClassifier()  \n",
    "lda_tp = LinearDiscriminantAnalysis(n_components = 2, solver='svd')\n",
    "lr_tp = LogisticRegression(C = 0.2, max_iter = 10, n_jobs = -1, penalty = 'l2', solver = 'sag', tol = 0.001)\n",
    "svc_tp = SVC(C=0.5, gamma=0.10, kernel='poly', degree=3, probability= True)\n",
    "rfc_tp = RandomForestClassifier(criterion = 'gini', max_features = 12, min_samples_leaf = 10,\n",
    "                             min_samples_split = 5, n_estimators = 30)\n",
    "gbc_tp = GradientBoostingClassifier(learning_rate=0.25, loss='exponential', max_depth=4, n_estimators=60)\n",
    "\n",
    "models = { \n",
    "    'VotingClassifier': VotingClassifier(estimators=[ ('lr', lr),('lda', lda), ('svc', svc), ('rfc', rfc), ('gbc', gbc)])\n",
    "}\n",
    "\n",
    "# Parameters setup\n",
    "params = {'VotingClassifier' : { 'estimators' : [                                          \n",
    "                                          [('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)],\n",
    "                                          [('svc_tp', svc_tp), ('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)],\n",
    "                                          [('lr_tp', lr_tp), ('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)],\n",
    "                                          [('lda_tp', lda_tp), ('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)],\n",
    "                                          [('abc_tp', abc_tp), ('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)]\n",
    "                                          ],\n",
    "                                   'voting': ['soft']\n",
    "          }\n",
    "         }\n",
    "\n",
    "# Lancer la grid search\n",
    "df_best_svc , dic_best_svc, d_res_svc = grid_search_global('clas',models,params,class_names=columns_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Classifier Tunep parameters\n",
    "# Score 0.77\n",
    "abc_tp = AdaBoostClassifier(learning_rate = 0.5, n_estimators = 20)  \n",
    "lda_tp = LinearDiscriminantAnalysis(n_components = 2, solver='svd')\n",
    "lr_tp = LogisticRegression(C = 0.2, max_iter = 10, n_jobs = -1, penalty = 'l2', solver = 'sag', tol = 0.001)\n",
    "svc_tp = SVC(C=0.5, gamma=0.10, kernel='poly', degree=3, probability= True)\n",
    "rfc_tp = RandomForestClassifier(criterion = 'gini', max_features = 12, min_samples_leaf = 10,\n",
    "                             min_samples_split = 5, n_estimators = 30)\n",
    "gbc_tp = GradientBoostingClassifier(learning_rate=0.25, loss='exponential', max_depth=4, n_estimators=60)\n",
    "\n",
    "\n",
    "# [ ('lr_tp', lr_tp),('lda_tp', lda_tp), ('svc_tp', svc_tp), ('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)]\n",
    "VC_tp_soft = VotingClassifier(estimators=[\n",
    "                                          [('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)],\n",
    "                                          [('svc_tp', svc_tp), ('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)],\n",
    "                                          [('lr_tp', lr_tp)],, ('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp),\n",
    "                                          [('lda_tp', lda_tp), ('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp), ],\n",
    "                                          [('abc_tp', abc_tp), ('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp),]\n",
    "                                          \n",
    "                                          \n",
    "                                         voting=['soft','hard'])\n",
    "VC_tp_soft.fit(X_train,y_train)\n",
    "Prediction['VC_tp_soft'] = VC_tp_soft.predict(Eval_OH_Std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Classifier Not Tunep parameters\n",
    "# Score 0.77\n",
    "\n",
    "abc = AdaBoostClassifier(learning_rate = 0.5, n_estimators = 20)        \n",
    "lda = LinearDiscriminantAnalysis(n_components = 2, solver='svd')\n",
    "lr = LogisticRegression()\n",
    "svc = SVC(probability=True)\n",
    "rfc = RandomForestClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "\n",
    "\n",
    "\n",
    "VC_nottp_soft = VotingClassifier(estimators=[ ('lr_tp', lr_tp),('lda_tp', lda_tp), ('svc_tp', svc_tp), ('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)],\n",
    "                                         voting='soft')\n",
    "VC_nottp_soft.fit(data,target)\n",
    "Prediction['VC_nottp_soft'] = VC_nottp_soft.predict(Eval_OH_Std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Eval_OH_Std.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Prediction.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save best params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 0.79-0.81 with PassId_0.81 and without ticket and cabin and dropping 'Title_aggr_Royalty','Title_aggr_Officer','Name_Size_Medium','Embarked_Q'\n",
    "GBC_params = {'learning_rate': 0.2, 'loss': 'deviance', 'max_depth': 3, 'max_features': 10, 'min_samples_leaf': 7, 'min_samples_split': 6, 'n_estimators': 10}\n",
    "# 0.80 same conditions\n",
    "RF_params =  {'criterion': 'entropy', 'max_features': 10, 'min_samples_leaf': 10, 'min_samples_split': 3, 'n_estimators': 30}\n",
    "#0.79\n",
    "VotingClassifier(estimators=[('rfc_tp', rfc_tp), ('gbc_tp', gbc_tp)],voting='soft')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save X_train and y_train that generalize well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Pass_Id = list(X_train.index)\n",
    "Pass_Id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "PasId = pd.DataFrame({\n",
    "        \"PassengerId\": Pass_Id\n",
    "    })\n",
    "PasId.to_csv('PassId_0.81.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save Number of random state that are good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "estim = #  Remplir ici\n",
    "Prediction = estim.predict(Eval_OH_Std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Prediction = Prediction['GBC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": PassengerId,\n",
    "        \"Survived\": Prediction\n",
    "    })\n",
    "submission.to_csv('titanic_GBC2_pred.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
